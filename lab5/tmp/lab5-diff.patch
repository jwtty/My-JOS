diff --git a/GNUmakefile b/GNUmakefile
index 236688a..2b7ed87 100644
--- a/GNUmakefile
+++ b/GNUmakefile
@@ -308,7 +308,7 @@ warn:
 	echo "this is the 2016 6.828 lab"; \
 	echo "******* WARNING ********* [39m"; \
 	echo; \
-	false;
+	true;
 
 #handin-prep:
 #	@./handin-prep
diff --git a/boot/boot.S b/boot/boot.S
index 7a91ab1..959c072 100644
--- a/boot/boot.S
+++ b/boot/boot.S
@@ -52,6 +52,7 @@ seta20.2:
   
   # Jump to next instruction, but in 32-bit code segment.
   # Switches processor into 32-bit mode.
+  # Use ljmp to refresh instructions in CPU
   ljmp    $PROT_MODE_CSEG, $protcseg
 
   .code32                     # Assemble for 32-bit mode
diff --git a/conf/lab.mk b/conf/lab.mk
index f22923b..b854ca0 100644
--- a/conf/lab.mk
+++ b/conf/lab.mk
@@ -1,2 +1,3 @@
 LAB=5
 PACKAGEDATE=Thu Nov 3 09:15:49 EDT 2016
+
diff --git a/fs/bc.c b/fs/bc.c
index 1825555..3ac4fcc 100644
--- a/fs/bc.c
+++ b/fs/bc.c
@@ -48,6 +48,10 @@ bc_pgfault(struct UTrapframe *utf)
 	// the disk.
 	//
 	// LAB 5: you code here:
+	addr = (void *)ROUNDDOWN((uintptr_t)addr, PGSIZE);
+	if((r = sys_page_alloc(0, addr, PTE_P | PTE_U | PTE_W)) < 0)
+		panic("in bc_pgfault, sys_page_alloc: %e", r);
+	ide_read(blockno << 3, addr, 8);
 
 	// Clear the dirty bit for the disk block page since we just read the
 	// block from disk
@@ -59,6 +63,7 @@ bc_pgfault(struct UTrapframe *utf)
 	// in?)
 	if (bitmap && block_is_free(blockno))
 		panic("reading free block %08x\n", blockno);
+	//cprintf("lalala\n");
 }
 
 // Flush the contents of the block containing VA out to disk if
@@ -77,7 +82,15 @@ flush_block(void *addr)
 		panic("flush_block of bad va %08x", addr);
 
 	// LAB 5: Your code here.
-	panic("flush_block not implemented");
+	addr = (void *)ROUNDDOWN((uintptr_t)addr, PGSIZE);
+	int r;
+	if(va_is_mapped(addr) && va_is_dirty(addr))
+	{
+		ide_write(blockno << 3, addr, 8);
+		if((r = sys_page_map(0, addr, 0, addr, uvpt[PGNUM(addr)] & PTE_SYSCALL)) < 0)
+			panic("in fluch_block, sys_page_map: %e", r);
+	}
+	//panic("flush_block not implemented");
 }
 
 // Test that the block cache works, by smashing the superblock and
diff --git a/fs/fs.c b/fs/fs.c
index 45ecaf8..6322c30 100644
--- a/fs/fs.c
+++ b/fs/fs.c
@@ -60,9 +60,18 @@ alloc_block(void)
 	// The bitmap consists of one or more blocks.  A single bitmap block
 	// contains the in-use bits for BLKBITSIZE blocks.  There are
 	// super->s_nblocks blocks in the disk altogether.
-
 	// LAB 5: Your code here.
-	panic("alloc_block not implemented");
+	//panic("alloc_block not implemented");
+	uint32_t blockno;
+	for (blockno = 0; blockno < super->s_nblocks; ++blockno)
+	{
+		if(block_is_free(blockno))
+		{
+			bitmap[blockno / 32] ^= 1 << (blockno % 32);
+			flush_block((void *)bitmap);
+			return blockno;
+		}
+	}
 	return -E_NO_DISK;
 }
 
@@ -134,8 +143,33 @@ fs_init(void)
 static int
 file_block_walk(struct File *f, uint32_t filebno, uint32_t **ppdiskbno, bool alloc)
 {
-       // LAB 5: Your code here.
-       panic("file_block_walk not implemented");
+	// LAB 5: Your code here.
+	//panic("file_block_walk not implemented");
+	
+	int r;
+    uint32_t *ptr;
+    char *blk;
+
+    if(filebno < NDIRECT)
+		ptr = &f->f_direct[filebno];
+    else if(filebno < NDIRECT + NINDIRECT)
+    {
+		if(f->f_indirect == 0 && alloc == 0)
+	    	return -E_NOT_FOUND;
+		else if(f->f_indirect==0)
+		{
+	    	if((r = alloc_block()) < 0)
+				return -E_NO_DISK;
+	    	f->f_indirect = r;
+	    	memset(diskaddr(r), 0, BLKSIZE);
+	    	flush_block(diskaddr(r));
+		}
+		ptr = (uint32_t*)diskaddr(f->f_indirect) + filebno - NDIRECT;
+    }
+    else
+		return -E_INVAL;
+    *ppdiskbno = ptr;
+    return 0;
 }
 
 // Set *blk to the address in memory where the filebno'th
@@ -149,8 +183,23 @@ file_block_walk(struct File *f, uint32_t filebno, uint32_t **ppdiskbno, bool all
 int
 file_get_block(struct File *f, uint32_t filebno, char **blk)
 {
-       // LAB 5: Your code here.
-       panic("file_get_block not implemented");
+	// LAB 5: Your code here.
+	//panic("file_get_block not implemented");*/
+	int r;
+    uint32_t *ptr;
+
+    if ((r = file_block_walk(f, filebno, &ptr, 1)) < 0)
+		return r;
+    if (*ptr == 0) 
+    {
+		if((r = alloc_block())<0)
+	    	return -E_NO_DISK;
+		*ptr = r;
+		memset(diskaddr(r), 0, BLKSIZE);
+		flush_block(diskaddr(r));
+    }   
+    *blk = diskaddr(*ptr);
+    return 0;
 }
 
 // Try to find a file named "name" in dir.  If so, set *file to it.
@@ -170,12 +219,14 @@ dir_lookup(struct File *dir, const char *name, struct File **file)
 	// is always a multiple of the file system's block size.
 	assert((dir->f_size % BLKSIZE) == 0);
 	nblock = dir->f_size / BLKSIZE;
-	for (i = 0; i < nblock; i++) {
+	for (i = 0; i < nblock; i++) 
+	{
 		if ((r = file_get_block(dir, i, &blk)) < 0)
 			return r;
 		f = (struct File*) blk;
 		for (j = 0; j < BLKFILES; j++)
-			if (strcmp(f[j].f_name, name) == 0) {
+			if (strcmp(f[j].f_name, name) == 0) 
+			{
 				*file = &f[j];
 				return 0;
 			}
@@ -195,12 +246,14 @@ dir_alloc_file(struct File *dir, struct File **file)
 
 	assert((dir->f_size % BLKSIZE) == 0);
 	nblock = dir->f_size / BLKSIZE;
-	for (i = 0; i < nblock; i++) {
+	for (i = 0; i < nblock; i++) 
+	{
 		if ((r = file_get_block(dir, i, &blk)) < 0)
 			return r;
 		f = (struct File*) blk;
 		for (j = 0; j < BLKFILES; j++)
-			if (f[j].f_name[0] == '\0') {
+			if (f[j].f_name[0] == '\0') 
+			{
 				*file = &f[j];
 				return 0;
 			}
diff --git a/fs/serv.c b/fs/serv.c
index 76c1d99..355330a 100644
--- a/fs/serv.c
+++ b/fs/serv.c
@@ -214,7 +214,14 @@ serve_read(envid_t envid, union Fsipc *ipc)
 		cprintf("serve_read %08x %08x %08x\n", envid, req->req_fileid, req->req_n);
 
 	// Lab 5: Your code here:
-	return 0;
+	struct OpenFile *o;
+	int r;
+	if((r = openfile_lookup(envid, req->req_fileid, &o)) < 0)
+		return r;
+	if((r = file_read(o->o_file, ret->ret_buf, MIN(req->req_n, sizeof(ret->ret_buf)), o->o_fd->fd_offset)) < 0)
+		return r;
+	o->o_fd->fd_offset += r;
+	return r;
 }
 
 
@@ -229,7 +236,15 @@ serve_write(envid_t envid, struct Fsreq_write *req)
 		cprintf("serve_write %08x %08x %08x\n", envid, req->req_fileid, req->req_n);
 
 	// LAB 5: Your code here.
-	panic("serve_write not implemented");
+	struct OpenFile *o;
+	int r;
+	if((r = openfile_lookup(envid, req->req_fileid, &o)) < 0)
+		return r;
+	if((r = file_write(o->o_file, req->req_buf, MIN(req->req_n, sizeof(req->req_buf)), o->o_fd->fd_offset)) < 0)
+		return r;
+	o->o_fd->fd_offset += r;
+	return r;
+	//panic("serve_write not implemented");
 }
 
 // Stat ipc->stat.req_fileid.  Return the file's struct Stat to the
diff --git a/inc/COPYRIGHT b/inc/COPYRIGHT
old mode 100644
new mode 100755
diff --git a/inc/assert.h b/inc/assert.h
old mode 100644
new mode 100755
diff --git a/inc/color.h b/inc/color.h
new file mode 100755
index 0000000..ed09ec1
--- /dev/null
+++ b/inc/color.h
@@ -0,0 +1,3 @@
+int FG_COLOR;
+int BG_COLOR;
+int COLOR;
diff --git a/inc/elf.h b/inc/elf.h
old mode 100644
new mode 100755
diff --git a/inc/env.h b/inc/env.h
old mode 100644
new mode 100755
index ca0b326..851787b
--- a/inc/env.h
+++ b/inc/env.h
@@ -6,6 +6,7 @@
 #include <inc/types.h>
 #include <inc/trap.h>
 #include <inc/memlayout.h>
+#include <kern/spinlock.h>
 
 typedef int32_t envid_t;
 
@@ -66,6 +67,9 @@ struct Env {
 	uint32_t env_ipc_value;		// Data value sent to us
 	envid_t env_ipc_from;		// envid of the sender
 	int env_ipc_perm;		// Perm of page mapping received
+
+	struct spinlock lock;
+	bool env_in_kernel;
 };
 
 #endif // !JOS_INC_ENV_H
diff --git a/inc/error.h b/inc/error.h
old mode 100644
new mode 100755
diff --git a/inc/kbdreg.h b/inc/kbdreg.h
old mode 100644
new mode 100755
diff --git a/inc/lib.h b/inc/lib.h
old mode 100644
new mode 100755
index 88f7102..1a4015d
--- a/inc/lib.h
+++ b/inc/lib.h
@@ -57,6 +57,7 @@ int	sys_page_map(envid_t src_env, void *src_pg,
 int	sys_page_unmap(envid_t env, void *pg);
 int	sys_ipc_try_send(envid_t to_env, uint32_t value, void *pg, int perm);
 int	sys_ipc_recv(void *rcv_pg);
+int sys_exec(uint32_t eip, uint32_t esp, void *v_ph, uint32_t phnum);
 
 // This must be inlined.  Exercise for reader: why?
 static inline envid_t __attribute__((always_inline))
@@ -103,6 +104,8 @@ int	pageref(void *addr);
 // spawn.c
 envid_t	spawn(const char *program, const char **argv);
 envid_t	spawnl(const char *program, const char *arg0, ...);
+int exec(const char *prog, const char **argv);
+int execl(const char *program, const char *arg0, ...);
 
 // console.c
 void	cputchar(int c);
diff --git a/inc/memlayout.h b/inc/memlayout.h
old mode 100644
new mode 100755
index 9b4f3c4..e74835d
--- a/inc/memlayout.h
+++ b/inc/memlayout.h
@@ -47,7 +47,7 @@
  *                     |       Memory-mapped I/O      | RW/--  PTSIZE
  * ULIM, MMIOBASE -->  +------------------------------+ 0xef800000
  *                     |  Cur. Page Table (User R-)   | R-/R-  PTSIZE
- *    UVPT      ---->  +------------------------------+ 0xef400000
+ *    UVPT      ---->  +------------------------------+ show
  *                     |          RO PAGES            | R-/R-  PTSIZE
  *    UPAGES    ---->  +------------------------------+ 0xef000000
  *                     |           RO ENVS            | R-/R-  PTSIZE
@@ -56,7 +56,7 @@
  *                     +------------------------------+ 0xeebff000
  *                     |       Empty Memory (*)       | --/--  PGSIZE
  *    USTACKTOP  --->  +------------------------------+ 0xeebfe000
- *                     |      Normal User Stack       | RW/RW  PGSIZE
+ *                     |      Normal x Stack       | RW/RW  PGSIZE
  *                     +------------------------------+ 0xeebfd000
  *                     |                              |
  *                     |                              |
diff --git a/inc/mmu.h b/inc/mmu.h
old mode 100644
new mode 100755
diff --git a/inc/stab.h b/inc/stab.h
old mode 100644
new mode 100755
diff --git a/inc/stdarg.h b/inc/stdarg.h
old mode 100644
new mode 100755
diff --git a/inc/stdio.h b/inc/stdio.h
old mode 100644
new mode 100755
diff --git a/inc/string.h b/inc/string.h
old mode 100644
new mode 100755
diff --git a/inc/syscall.h b/inc/syscall.h
old mode 100644
new mode 100755
index 20c6433..0a33eb5
--- a/inc/syscall.h
+++ b/inc/syscall.h
@@ -17,6 +17,7 @@ enum {
 	SYS_yield,
 	SYS_ipc_try_send,
 	SYS_ipc_recv,
+	SYS_exec,
 	NSYSCALLS
 };
 
diff --git a/inc/trap.h b/inc/trap.h
old mode 100644
new mode 100755
index b36aae3..58c1af7
--- a/inc/trap.h
+++ b/inc/trap.h
@@ -88,4 +88,4 @@ struct UTrapframe {
 
 #endif /* !__ASSEMBLER__ */
 
-#endif /* !JOS_INC_TRAP_H */
+#endif /* !JOS_INC_TRAP_f */
diff --git a/inc/types.h b/inc/types.h
old mode 100644
new mode 100755
diff --git a/inc/x86.h b/inc/x86.h
old mode 100644
new mode 100755
diff --git a/kern.old/COPYRIGHT b/kern.old/COPYRIGHT
new file mode 100755
index 0000000..6a0270c
--- /dev/null
+++ b/kern.old/COPYRIGHT
@@ -0,0 +1,155 @@
+Most of the source files in this directory are derived from the Exokernel,
+which is:
+
+/*
+ * Copyright (C) 1997 Massachusetts Institute of Technology 
+ *
+ * This software is being provided by the copyright holders under the
+ * following license. By obtaining, using and/or copying this software,
+ * you agree that you have read, understood, and will comply with the
+ * following terms and conditions:
+ *
+ * Permission to use, copy, modify, distribute, and sell this software
+ * and its documentation for any purpose and without fee or royalty is
+ * hereby granted, provided that the full text of this NOTICE appears on
+ * ALL copies of the software and documentation or portions thereof,
+ * including modifications, that you make.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS," AND COPYRIGHT HOLDERS MAKE NO
+ * REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE,
+ * BUT NOT LIMITATION, COPYRIGHT HOLDERS MAKE NO REPRESENTATIONS OR
+ * WARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR
+ * THAT THE USE OF THE SOFTWARE OR DOCUMENTATION WILL NOT INFRINGE ANY
+ * THIRD PARTY PATENTS, COPYRIGHTS, TRADEMARKS OR OTHER RIGHTS. COPYRIGHT
+ * HOLDERS WILL BEAR NO LIABILITY FOR ANY USE OF THIS SOFTWARE OR
+ * DOCUMENTATION.
+ *
+ * The name and trademarks of copyright holders may NOT be used in
+ * advertising or publicity pertaining to the software without specific,
+ * written prior permission. Title to copyright in this software and any
+ * associated documentation will at all times remain with copyright
+ * holders. See the file AUTHORS which should have accompanied this software
+ * for a list of all copyright holders.
+ *
+ * This file may be derived from previously copyrighted software. This
+ * copyright applies only to those changes made by the copyright
+ * holders listed in the AUTHORS file. The rest of this file is covered by
+ * the copyright notices, if any, listed below.
+ */
+
+Console.c was created consulting the NetBSD pccons driver which is:
+
+/*-
+ * Copyright (c) 1993, 1994, 1995 Charles Hannum.  All rights reserved.
+ * Copyright (c) 1990 The Regents of the University of California.
+ * All rights reserved.
+ *
+ * This code is derived from software contributed to Berkeley by
+ * William Jolitz and Don Ahn.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. All advertising materials mentioning features or use of this software
+ *    must display the following acknowledgement:
+ *	This product includes software developed by the University of
+ *	California, Berkeley and its contributors.
+ * 4. Neither the name of the University nor the names of its contributors
+ *    may be used to endorse or promote products derived from this software
+ *    without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ */
+
+Kclock.h, sched.h, and printf.h are copyright:
+
+/*
+ * Copyright (C) 1998 Exotec, Inc.
+ *
+ * This software is being provided by the copyright holders under the
+ * following license. By obtaining, using and/or copying this software,
+ * you agree that you have read, understood, and will comply with the
+ * following terms and conditions:
+ *
+ * Permission to use, copy, modify, distribute, and sell this software
+ * and its documentation for any purpose and without fee or royalty is
+ * hereby granted, provided that the full text of this NOTICE appears on
+ * ALL copies of the software and documentation or portions thereof,
+ * including modifications, that you make.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS," AND COPYRIGHT HOLDERS MAKE NO
+ * REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE,
+ * BUT NOT LIMITATION, COPYRIGHT HOLDERS MAKE NO REPRESENTATIONS OR
+ * WARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR
+ * THAT THE USE OF THE SOFTWARE OR DOCUMENTATION WILL NOT INFRINGE ANY
+ * THIRD PARTY PATENTS, COPYRIGHTS, TRADEMARKS OR OTHER RIGHTS. COPYRIGHT
+ * HOLDERS WILL BEAR NO LIABILITY FOR ANY USE OF THIS SOFTWARE OR
+ * DOCUMENTATION.
+ *
+ * The name and trademarks of copyright holders may NOT be used in
+ * advertising or publicity pertaining to the software without specific,
+ * written prior permission. Title to copyright in this software and any
+ * associated documentation will at all times remain with Exotec, Inc..
+ *
+ * This file may be derived from previously copyrighted software. This
+ * copyright applies only to those changes made by Exotec, Inc. The rest
+ * of this file is covered by the copyright notices, if any, listed below.
+ */
+
+Printf.c is copyright:
+
+/*-
+ * Copyright (c) 1986, 1988, 1991, 1993
+ *	The Regents of the University of California.  All rights reserved.
+ * (c) UNIX System Laboratories, Inc.
+ * All or some portions of this file are derived from material licensed
+ * to the University of California by American Telephone and Telegraph
+ * Co. or Unix System Laboratories, Inc. and are reproduced herein with
+ * the permission of UNIX System Laboratories, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. All advertising materials mentioning features or use of this software
+ *    must display the following acknowledgement:
+ *	This product includes software developed by the University of
+ *	California, Berkeley and its contributors.
+ * 4. Neither the name of the University nor the names of its contributors
+ *    may be used to endorse or promote products derived from this software
+ *    without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ *	@(#)subr_prf.c	8.3 (Berkeley) 1/21/94
+ */
+
diff --git a/kern.old/Makefrag b/kern.old/Makefrag
new file mode 100755
index 0000000..b6974b2
--- /dev/null
+++ b/kern.old/Makefrag
@@ -0,0 +1,145 @@
+#
+# Makefile fragment for JOS kernel.
+# This is NOT a complete makefile;
+# you must run GNU make in the top-level directory
+# where the GNUmakefile is located.
+#
+
+OBJDIRS += kern
+
+KERN_LDFLAGS := $(LDFLAGS) -T kern/kernel.ld -nostdlib
+
+# entry.S must be first, so that it's the first code in the text segment!!!
+#
+# We also snatch the use of a couple handy source files
+# from the lib directory, to avoid gratuitous code duplication.
+KERN_SRCFILES :=	kern/entry.S \
+			kern/entrypgdir.c \
+			kern/init.c \
+			kern/console.c \
+			kern/monitor.c \
+			kern/pmap.c \
+			kern/env.c \
+			kern/kclock.c \
+			kern/picirq.c \
+			kern/printf.c \
+			kern/trap.c \
+			kern/trapentry.S \
+			kern/sched.c \
+			kern/syscall.c \
+			kern/kdebug.c \
+			lib/printfmt.c \
+			lib/readline.c \
+			lib/string.c
+
+# Source files for LAB4
+KERN_SRCFILES +=	kern/mpentry.S \
+			kern/mpconfig.c \
+			kern/lapic.c \
+			kern/spinlock.c
+
+# Only build files if they exist.
+KERN_SRCFILES := $(wildcard $(KERN_SRCFILES))
+
+# Binary program images to embed within the kernel.
+# Binary files for LAB3
+KERN_BINFILES :=	user/hello \
+			user/buggyhello \
+			user/buggyhello2 \
+			user/evilhello \
+			user/testbss \
+			user/divzero \
+			user/breakpoint \
+			user/softint \
+			user/badsegment \
+			user/faultread \
+			user/faultreadkernel \
+			user/faultwrite \
+			user/faultwritekernel
+
+# Binary files for LAB4
+KERN_BINFILES +=	user/idle \
+			user/yield \
+			user/dumbfork \
+			user/stresssched \
+			user/faultdie \
+			user/faultregs \
+			user/faultalloc \
+			user/faultallocbad \
+			user/faultnostack \
+			user/faultbadhandler \
+			user/faultevilhandler \
+			user/forktree \
+			user/sendpage \
+			user/spin \
+			user/fairness \
+			user/pingpong \
+			user/pingpongs \
+			user/primes
+# Binary files for LAB5
+KERN_BINFILES +=	user/faultio\
+	      		user/spawnfaultio\
+	      		user/testfile \
+			user/spawnhello \
+			user/icode \
+			fs/fs
+
+# Binary files for LAB5
+KERN_BINFILES +=	user/testpteshare \
+			user/testfdsharing \
+			user/testpipe \
+			user/testpiperace \
+			user/testpiperace2 \
+			user/primespipe \
+			user/testkbd \
+			user/testshell
+
+KERN_OBJFILES := $(patsubst %.c, $(OBJDIR)/%.o, $(KERN_SRCFILES))
+KERN_OBJFILES := $(patsubst %.S, $(OBJDIR)/%.o, $(KERN_OBJFILES))
+KERN_OBJFILES := $(patsubst $(OBJDIR)/lib/%, $(OBJDIR)/kern/%, $(KERN_OBJFILES))
+
+KERN_BINFILES := $(patsubst %, $(OBJDIR)/%, $(KERN_BINFILES))
+
+# How to build kernel object files
+$(OBJDIR)/kern/%.o: kern/%.c $(OBJDIR)/.vars.KERN_CFLAGS
+	@echo + cc $<
+	@mkdir -p $(@D)
+	$(V)$(CC) -nostdinc $(KERN_CFLAGS) -c -o $@ $<
+
+$(OBJDIR)/kern/%.o: kern/%.S $(OBJDIR)/.vars.KERN_CFLAGS
+	@echo + as $<
+	@mkdir -p $(@D)
+	$(V)$(CC) -nostdinc $(KERN_CFLAGS) -c -o $@ $<
+
+$(OBJDIR)/kern/%.o: lib/%.c $(OBJDIR)/.vars.KERN_CFLAGS
+	@echo + cc $<
+	@mkdir -p $(@D)
+	$(V)$(CC) -nostdinc $(KERN_CFLAGS) -c -o $@ $<
+
+# Special flags for kern/init
+$(OBJDIR)/kern/init.o: override KERN_CFLAGS+=$(INIT_CFLAGS)
+$(OBJDIR)/kern/init.o: $(OBJDIR)/.vars.INIT_CFLAGS
+
+# How to build the kernel itself
+$(OBJDIR)/kern/kernel: $(KERN_OBJFILES) $(KERN_BINFILES) kern/kernel.ld \
+	  $(OBJDIR)/.vars.KERN_LDFLAGS
+	@echo + ld $@
+	$(V)$(LD) -o $@ $(KERN_LDFLAGS) $(KERN_OBJFILES) $(GCC_LIB) -b binary $(KERN_BINFILES)
+	$(V)$(OBJDUMP) -S $@ > $@.asm
+	$(V)$(NM) -n $@ > $@.sym
+
+# How to build the kernel disk image
+$(OBJDIR)/kern/kernel.img: $(OBJDIR)/kern/kernel $(OBJDIR)/boot/boot
+	@echo + mk $@
+	$(V)dd if=/dev/zero of=$(OBJDIR)/kern/kernel.img~ count=10000 2>/dev/null
+	$(V)dd if=$(OBJDIR)/boot/boot of=$(OBJDIR)/kern/kernel.img~ conv=notrunc 2>/dev/null
+	$(V)dd if=$(OBJDIR)/kern/kernel of=$(OBJDIR)/kern/kernel.img~ seek=1 conv=notrunc 2>/dev/null
+	$(V)mv $(OBJDIR)/kern/kernel.img~ $(OBJDIR)/kern/kernel.img
+
+all: $(OBJDIR)/kern/kernel.img
+
+grub: $(OBJDIR)/jos-grub
+
+$(OBJDIR)/jos-grub: $(OBJDIR)/kern/kernel
+	@echo + oc $@
+	$(V)$(OBJCOPY) --adjust-vma=0x10000000 $^ $@
diff --git a/kern.old/console.c b/kern.old/console.c
new file mode 100755
index 0000000..c9b93d1
--- /dev/null
+++ b/kern.old/console.c
@@ -0,0 +1,485 @@
+/* See COPYRIGHT for copyright information. */
+
+#include <inc/x86.h>
+#include <inc/memlayout.h>
+#include <inc/kbdreg.h>
+#include <inc/string.h>
+#include <inc/assert.h>
+#include <inc/color.h>
+
+#include <kern/console.h>
+#include <kern/trap.h>
+#include <kern/picirq.h>
+#include <kern/spinlock.h>
+
+static void cons_intr(int (*proc)(void));
+static void cons_putc(int c);
+
+// Stupid I/O delay routine necessitated by historical PC design flaws
+static void
+delay(void)
+{
+	inb(0x84);
+	inb(0x84);
+	inb(0x84);
+	inb(0x84);
+}
+
+/***** Serial I/O code *****/
+
+#define COM1		0x3F8
+
+#define COM_RX		0	// In:	Receive buffer (DLAB=0)
+#define COM_TX		0	// Out: Transmit buffer (DLAB=0)
+#define COM_DLL		0	// Out: Divisor Latch Low (DLAB=1)
+#define COM_DLM		1	// Out: Divisor Latch High (DLAB=1)
+#define COM_IER		1	// Out: Interrupt Enable Register
+#define   COM_IER_RDI	0x01	//   Enable receiver data interrupt
+#define COM_IIR		2	// In:	Interrupt ID Register
+#define COM_FCR		2	// Out: FIFO Control Register
+#define COM_LCR		3	// Out: Line Control Register
+#define	  COM_LCR_DLAB	0x80	//   Divisor latch access bit
+#define	  COM_LCR_WLEN8	0x03	//   Wordlength: 8 bits
+#define COM_MCR		4	// Out: Modem Control Register
+#define	  COM_MCR_RTS	0x02	// RTS complement
+#define	  COM_MCR_DTR	0x01	// DTR complement
+#define	  COM_MCR_OUT2	0x08	// Out2 complement
+#define COM_LSR		5	// In:	Line Status Register
+#define   COM_LSR_DATA	0x01	//   Data available
+#define   COM_LSR_TXRDY	0x20	//   Transmit buffer avail
+#define   COM_LSR_TSRE	0x40	//   Transmitter off
+
+static bool serial_exists;
+
+static int
+serial_proc_data(void)
+{
+	if (!(inb(COM1+COM_LSR) & COM_LSR_DATA))
+		return -1;
+	return inb(COM1+COM_RX);
+}
+
+void
+serial_intr(void)
+{
+	if (serial_exists)
+		cons_intr(serial_proc_data);
+}
+
+static void
+serial_putc(int c)
+{
+	int i;
+
+	for (i = 0;
+	     !(inb(COM1 + COM_LSR) & COM_LSR_TXRDY) && i < 12800;
+	     i++)
+		delay();
+
+	outb(COM1 + COM_TX, c);
+}
+
+static void
+serial_init(void)
+{
+	// Turn off the FIFO
+	outb(COM1+COM_FCR, 0);
+
+	// Set speed; requires DLAB latch
+	outb(COM1+COM_LCR, COM_LCR_DLAB);
+	outb(COM1+COM_DLL, (uint8_t) (115200 / 9600));
+	outb(COM1+COM_DLM, 0);
+
+	// 8 data bits, 1 stop bit, parity off; turn off DLAB latch
+	outb(COM1+COM_LCR, COM_LCR_WLEN8 & ~COM_LCR_DLAB);
+
+	// No modem controls
+	outb(COM1+COM_MCR, 0);
+	// Enable rcv interrupts
+	outb(COM1+COM_IER, COM_IER_RDI);
+
+	// Clear any preexisting overrun indications and interrupts
+	// Serial port doesn't exist if COM_LSR returns 0xFF
+	serial_exists = (inb(COM1+COM_LSR) != 0xFF);
+	(void) inb(COM1+COM_IIR);
+	(void) inb(COM1+COM_RX);
+
+	// Enable serial interrupts
+	if (serial_exists)
+		irq_setmask_8259A(irq_mask_8259A & ~(1<<IRQ_SERIAL));
+}
+
+
+
+/***** Parallel port output code *****/
+// For information on PC parallel port programming, see the class References
+// page.
+
+static void
+lpt_putc(int c)
+{
+	int i;
+
+	for (i = 0; !(inb(0x378+1) & 0x80) && i < 12800; i++)
+		delay();
+	outb(0x378+0, c);
+	outb(0x378+2, 0x08|0x04|0x01);
+	outb(0x378+2, 0x08);
+}
+
+
+
+
+/***** Text-mode CGA/VGA display output *****/
+
+static unsigned addr_6845;
+static uint16_t *crt_buf;
+static uint16_t crt_pos;
+
+static void
+cga_init(void)
+{
+	volatile uint16_t *cp;
+	uint16_t was;
+	unsigned pos;
+
+	cp = (uint16_t*) (KERNBASE + CGA_BUF);
+	was = *cp;
+	*cp = (uint16_t) 0xA55A;
+	if (*cp != 0xA55A) {
+		cp = (uint16_t*) (KERNBASE + MONO_BUF);
+		addr_6845 = MONO_BASE;
+	} else {
+		*cp = was;
+		addr_6845 = CGA_BASE;
+	}
+
+	/* Extract cursor location */
+	outb(addr_6845, 14);
+	pos = inb(addr_6845 + 1) << 8;
+	outb(addr_6845, 15);
+	pos |= inb(addr_6845 + 1);
+
+	crt_buf = (uint16_t*) cp;
+	crt_pos = pos;
+}
+
+
+
+static void
+cga_putc(int c)
+{
+	// if no attribute given, then use black on white
+	if (!(c & ~0xFF))
+	   	c |= COLOR;
+	switch (c & 0xff) {
+	case '\b':
+		if (crt_pos > 0) {
+			crt_pos--;
+			crt_buf[crt_pos] = (c & ~0xff) | ' ';
+		}
+		break;
+	case '\n':
+		crt_pos += CRT_COLS;
+		/* fallthru */
+	case '\r':
+		crt_pos -= (crt_pos % CRT_COLS);
+		break;
+	case '\t':
+		cons_putc(' ');
+		cons_putc(' ');
+		cons_putc(' ');
+		cons_putc(' ');
+		cons_putc(' ');
+		break;
+	default:
+		crt_buf[crt_pos++] = c;		/* write the character */
+		break;
+	}
+
+	// What is the purpose of this? sol: lab 1 report P15
+	if (crt_pos >= CRT_SIZE) {
+		int i;
+
+		memmove(crt_buf, crt_buf + CRT_COLS, (CRT_SIZE - CRT_COLS) * sizeof(uint16_t));
+		for (i = CRT_SIZE - CRT_COLS; i < CRT_SIZE; i++)
+			crt_buf[i] = 0x0700 | ' ';
+		crt_pos -= CRT_COLS;
+	}
+
+	/* move that little blinky thing */
+	outb(addr_6845, 14);
+	outb(addr_6845 + 1, crt_pos >> 8);
+	outb(addr_6845, 15);
+	outb(addr_6845 + 1, crt_pos);
+}
+
+
+/***** Keyboard input code *****/
+
+#define NO		0
+
+#define SHIFT		(1<<0)
+#define CTL		(1<<1)
+#define ALT		(1<<2)
+
+#define CAPSLOCK	(1<<3)
+#define NUMLOCK		(1<<4)
+#define SCROLLLOCK	(1<<5)
+
+#define E0ESC		(1<<6)
+
+static uint8_t shiftcode[256] =
+{
+	[0x1D] = CTL,
+	[0x2A] = SHIFT,
+	[0x36] = SHIFT,
+	[0x38] = ALT,
+	[0x9D] = CTL,
+	[0xB8] = ALT
+};
+
+static uint8_t togglecode[256] =
+{
+	[0x3A] = CAPSLOCK,
+	[0x45] = NUMLOCK,
+	[0x46] = SCROLLLOCK
+};
+
+static uint8_t normalmap[256] =
+{
+	NO,   0x1B, '1',  '2',  '3',  '4',  '5',  '6',	// 0x00
+	'7',  '8',  '9',  '0',  '-',  '=',  '\b', '\t',
+	'q',  'w',  'e',  'r',  't',  'y',  'u',  'i',	// 0x10
+	'o',  'p',  '[',  ']',  '\n', NO,   'a',  's',
+	'd',  'f',  'g',  'h',  'j',  'k',  'l',  ';',	// 0x20
+	'\'', '`',  NO,   '\\', 'z',  'x',  'c',  'v',
+	'b',  'n',  'm',  ',',  '.',  '/',  NO,   '*',	// 0x30
+	NO,   ' ',  NO,   NO,   NO,   NO,   NO,   NO,
+	NO,   NO,   NO,   NO,   NO,   NO,   NO,   '7',	// 0x40
+	'8',  '9',  '-',  '4',  '5',  '6',  '+',  '1',
+	'2',  '3',  '0',  '.',  NO,   NO,   NO,   NO,	// 0x50
+	[0xC7] = KEY_HOME,	      [0x9C] = '\n' /*KP_Enter*/,
+	[0xB5] = '/' /*KP_Div*/,      [0xC8] = KEY_UP,
+	[0xC9] = KEY_PGUP,	      [0xCB] = KEY_LF,
+	[0xCD] = KEY_RT,	      [0xCF] = KEY_END,
+	[0xD0] = KEY_DN,	      [0xD1] = KEY_PGDN,
+	[0xD2] = KEY_INS,	      [0xD3] = KEY_DEL
+};
+
+static uint8_t shiftmap[256] =
+{
+	NO,   033,  '!',  '@',  '#',  '$',  '%',  '^',	// 0x00
+	'&',  '*',  '(',  ')',  '_',  '+',  '\b', '\t',
+	'Q',  'W',  'E',  'R',  'T',  'Y',  'U',  'I',	// 0x10
+	'O',  'P',  '{',  '}',  '\n', NO,   'A',  'S',
+	'D',  'F',  'G',  'H',  'J',  'K',  'L',  ':',	// 0x20
+	'"',  '~',  NO,   '|',  'Z',  'X',  'C',  'V',
+	'B',  'N',  'M',  '<',  '>',  '?',  NO,   '*',	// 0x30
+	NO,   ' ',  NO,   NO,   NO,   NO,   NO,   NO,
+	NO,   NO,   NO,   NO,   NO,   NO,   NO,   '7',	// 0x40
+	'8',  '9',  '-',  '4',  '5',  '6',  '+',  '1',
+	'2',  '3',  '0',  '.',  NO,   NO,   NO,   NO,	// 0x50
+	[0xC7] = KEY_HOME,	      [0x9C] = '\n' /*KP_Enter*/,
+	[0xB5] = '/' /*KP_Div*/,      [0xC8] = KEY_UP,
+	[0xC9] = KEY_PGUP,	      [0xCB] = KEY_LF,
+	[0xCD] = KEY_RT,	      [0xCF] = KEY_END,
+	[0xD0] = KEY_DN,	      [0xD1] = KEY_PGDN,
+	[0xD2] = KEY_INS,	      [0xD3] = KEY_DEL
+};
+
+#define C(x) (x - '@')
+
+static uint8_t ctlmap[256] =
+{
+	NO,      NO,      NO,      NO,      NO,      NO,      NO,      NO,
+	NO,      NO,      NO,      NO,      NO,      NO,      NO,      NO,
+	C('Q'),  C('W'),  C('E'),  C('R'),  C('T'),  C('Y'),  C('U'),  C('I'),
+	C('O'),  C('P'),  NO,      NO,      '\r',    NO,      C('A'),  C('S'),
+	C('D'),  C('F'),  C('G'),  C('H'),  C('J'),  C('K'),  C('L'),  NO,
+	NO,      NO,      NO,      C('\\'), C('Z'),  C('X'),  C('C'),  C('V'),
+	C('B'),  C('N'),  C('M'),  NO,      NO,      C('/'),  NO,      NO,
+	[0x97] = KEY_HOME,
+	[0xB5] = C('/'),		[0xC8] = KEY_UP,
+	[0xC9] = KEY_PGUP,		[0xCB] = KEY_LF,
+	[0xCD] = KEY_RT,		[0xCF] = KEY_END,
+	[0xD0] = KEY_DN,		[0xD1] = KEY_PGDN,
+	[0xD2] = KEY_INS,		[0xD3] = KEY_DEL
+};
+
+static uint8_t *charcode[4] = {
+	normalmap,
+	shiftmap,
+	ctlmap,
+	ctlmap
+};
+
+/*
+ * Get data from the keyboard.  If we finish a character, return it.  Else 0.
+ * Return -1 if no data.
+ */
+static int
+kbd_proc_data(void)
+{
+	int c;
+	uint8_t stat, data;
+	static uint32_t shift;
+
+	stat = inb(KBSTATP);
+	if ((stat & KBS_DIB) == 0)
+		return -1;
+	// Ignore data from mouse.
+	if (stat & KBS_TERR)
+		return -1;
+
+	data = inb(KBDATAP);
+
+	if (data == 0xE0) {
+		// E0 escape character
+		shift |= E0ESC;
+		return 0;
+	} else if (data & 0x80) {
+		// Key released
+		data = (shift & E0ESC ? data : data & 0x7F);
+		shift &= ~(shiftcode[data] | E0ESC);
+		return 0;
+	} else if (shift & E0ESC) {
+		// Last character was an E0 escape; or with 0x80
+		data |= 0x80;
+		shift &= ~E0ESC;
+	}
+
+	shift |= shiftcode[data];
+	shift ^= togglecode[data];
+
+	c = charcode[shift & (CTL | SHIFT)][data];
+	if (shift & CAPSLOCK) {
+		if ('a' <= c && c <= 'z')
+			c += 'A' - 'a';
+		else if ('A' <= c && c <= 'Z')
+			c += 'a' - 'A';
+	}
+
+	// Process special keys
+	// Ctrl-Alt-Del: reboot
+	if (!(~shift & (CTL | ALT)) && c == KEY_DEL) {
+		cprintf("Rebooting!\n");
+		outb(0x92, 0x3); // courtesy of Chris Frost
+	}
+
+	return c;
+}
+
+void
+kbd_intr(void)
+{
+	cons_intr(kbd_proc_data);
+}
+
+static void
+kbd_init(void)
+{
+	// Drain the kbd buffer so that QEMU generates interrupts.
+	kbd_intr();
+	irq_setmask_8259A(irq_mask_8259A & ~(1<<IRQ_KBD));
+}
+
+
+
+/***** General device-independent console code *****/
+// Here we manage the console input buffer,
+// where we stash characters received from the keyboard or serial port
+// whenever the corresponding interrupt occurs.
+
+#define CONSBUFSIZE 512
+
+static struct {
+	uint8_t buf[CONSBUFSIZE];
+	uint32_t rpos;
+	uint32_t wpos;
+} cons;
+
+// called by device interrupt routines to feed input characters
+// into the circular console input buffer.
+static void
+cons_intr(int (*proc)(void))
+{
+	int c;
+
+	while ((c = (*proc)()) != -1) {
+		if (c == 0)
+			continue;
+		cons.buf[cons.wpos++] = c;
+		if (cons.wpos == CONSBUFSIZE)
+			cons.wpos = 0;
+	}
+}
+
+// return the next input character from the console, or 0 if none waiting
+int
+cons_getc(void)
+{
+	int c;
+
+	// poll for any pending input characters,
+	// so that this function works even when interrupts are disabled
+	// (e.g., when called from the kernel monitor).
+	serial_intr();
+	kbd_intr();
+
+	// grab the next character from the input buffer.
+	if (cons.rpos != cons.wpos) {
+		c = cons.buf[cons.rpos++];
+		if (cons.rpos == CONSBUFSIZE)
+			cons.rpos = 0;
+		return c;
+	}
+	return 0;
+}
+
+// output a character to the console
+static void
+cons_putc(int c)
+{
+	serial_putc(c);
+	lpt_putc(c);
+	cga_putc(c);
+}
+
+// initialize the console devices
+void
+cons_init(void)
+{
+	cga_init();
+	kbd_init();
+	serial_init();
+
+	if (!serial_exists)
+		cprintf("Serial port does not exist!\n");
+}
+
+
+// `High'-level console I/O.  Used by readline and cprintf.
+
+void
+cputchar(int c)
+{
+    cons_putc(c);
+}
+
+int
+getchar(void)
+{
+    int c;
+
+    while ((c = cons_getc()) == 0)
+	/* do nothing */;
+    return c;
+}
+
+int
+iscons(int fdnum)
+{
+	// used by readline
+	return 1;
+}
diff --git a/kern.old/console.h b/kern.old/console.h
new file mode 100755
index 0000000..3668626
--- /dev/null
+++ b/kern.old/console.h
@@ -0,0 +1,26 @@
+/* See COPYRIGHT for copyright information. */
+
+#ifndef _CONSOLE_H_
+#define _CONSOLE_H_
+#ifndef JOS_KERNEL
+# error "This is a JOS kernel header; user programs should not #include it"
+#endif
+
+#include <inc/types.h>
+
+#define MONO_BASE	0x3B4
+#define MONO_BUF	0xB0000
+#define CGA_BASE	0x3D4
+#define CGA_BUF		0xB8000
+
+#define CRT_ROWS	25
+#define CRT_COLS	80
+#define CRT_SIZE	(CRT_ROWS * CRT_COLS)
+
+void cons_init(void);
+int cons_getc(void);
+
+void kbd_intr(void); // irq 1
+void serial_intr(void); // irq 4
+
+#endif /* _CONSOLE_H_ */
diff --git a/kern.old/cpu.h b/kern.old/cpu.h
new file mode 100755
index 0000000..c3c58c5
--- /dev/null
+++ b/kern.old/cpu.h
@@ -0,0 +1,46 @@
+
+#ifndef JOS_INC_CPU_H
+#define JOS_INC_CPU_H
+
+#include <inc/types.h>
+#include <inc/memlayout.h>
+#include <inc/mmu.h>
+#include <inc/env.h>
+
+// Maximum number of CPUs
+#define NCPU  8
+
+// Values of status in struct Cpu
+enum {
+	CPU_UNUSED = 0,
+	CPU_STARTED,
+	CPU_HALTED,
+};
+
+// Per-CPU state
+struct CpuInfo {
+	uint8_t cpu_id;                 // Local APIC ID; index into cpus[] below
+	volatile unsigned cpu_status;   // The status of the CPU
+	struct Env *cpu_env;            // The currently-running environment.
+	struct Taskstate cpu_ts;        // Used by x86 to find stack for interrupt
+};
+
+// Initialized in mpconfig.c
+extern struct CpuInfo cpus[NCPU];
+extern int ncpu;                    // Total number of CPUs in the system
+extern struct CpuInfo *bootcpu;     // The boot-strap processor (BSP)
+extern physaddr_t lapicaddr;        // Physical MMIO address of the local APIC
+
+// Per-CPU kernel stacks
+extern unsigned char percpu_kstacks[NCPU][KSTKSIZE];
+
+int cpunum(void);
+#define thiscpu (&cpus[cpunum()])
+
+void mp_init(void);
+void lapic_init(void);
+void lapic_startap(uint8_t apicid, uint32_t addr);
+void lapic_eoi(void);
+void lapic_ipi(int vector);
+
+#endif
diff --git a/kern.old/entry.S b/kern.old/entry.S
new file mode 100755
index 0000000..6ab9bad
--- /dev/null
+++ b/kern.old/entry.S
@@ -0,0 +1,97 @@
+/* See COPYRIGHT for copyright information. */
+
+#include <inc/mmu.h>
+#include <inc/memlayout.h>
+#include <inc/trap.h>
+
+# Shift Right Logical 
+#define SRL(val, shamt)		(((val) >> (shamt)) & ~(-1 << (32 - (shamt))))
+
+
+###################################################################
+# The kernel (this code) is linked at address ~(KERNBASE + 1 Meg), 
+# but the bootloader loads it at address ~1 Meg.
+#	
+# RELOC(x) maps a symbol x from its link address to its actual
+# location in physical memory (its load address).	 
+###################################################################
+
+#define	RELOC(x) ((x) - KERNBASE)
+
+#define MULTIBOOT_HEADER_MAGIC (0x1BADB002)
+#define MULTIBOOT_HEADER_FLAGS (0)
+#define CHECKSUM (-(MULTIBOOT_HEADER_MAGIC + MULTIBOOT_HEADER_FLAGS))
+
+###################################################################
+# entry point
+###################################################################
+
+.text
+
+# The Multiboot header
+.align 4
+.long MULTIBOOT_HEADER_MAGIC
+.long MULTIBOOT_HEADER_FLAGS
+.long CHECKSUM
+
+# '_start' specifies the ELF entry point.  Since we haven't set up
+# virtual memory when the bootloader enters this code, we need the
+# bootloader to jump to the *physical* address of the entry point.
+.globl		_start
+_start = RELOC(entry)
+
+.globl entry
+entry:
+	movw	$0x1234,0x472			# warm boot
+
+	# We haven't set up virtual memory yet, so we're running from
+	# the physical address the boot loader loaded the kernel at: 1MB
+	# (plus a few bytes).  However, the C code is linked to run at
+	# KERNBASE+1MB.  Hence, we set up a trivial page directory that
+	# translates virtual addresses [KERNBASE, KERNBASE+4MB) to
+	# physical addresses [0, 4MB).  This 4MB region will be
+	# sufficient until we set up our real page table in mem_init
+	# in lab 2.
+
+	# Load the physical address of entry_pgdir into cr3.  entry_pgdir
+	# is defined in entrypgdir.c.
+	movl	$(RELOC(entry_pgdir)), %eax
+	movl	%eax, %cr3
+	# Turn on paging.
+	movl	%cr0, %eax
+	orl	$(CR0_PE|CR0_PG|CR0_WP), %eax
+	movl	%eax, %cr0
+
+	# Now paging is enabled, but we're still running at a low EIP
+	# (why is this okay?).  Jump up above KERNBASE before entering
+	# C code.
+	mov	$relocated, %eax
+	jmp	*%eax
+relocated:
+
+	# Clear the frame pointer register (EBP)
+	# so that once we get into debugging C code,
+	# stack backtraces will be terminated properly.
+	movl	$0x0,%ebp			# nuke frame pointer
+
+	# Set the stack pointer
+	movl	$(bootstacktop),%esp
+
+	# now to C code
+	call	i386_init
+
+	# Should never get here, but in case we do, just spin.
+spin:	jmp	spin
+
+
+.data
+###################################################################
+# boot stack
+###################################################################
+	.p2align	PGSHIFT		# force page alignment
+	.globl		bootstack
+bootstack:
+	.space		KSTKSIZE
+	.globl		bootstacktop   
+bootstacktop:
+
diff --git a/kern.old/entrypgdir.c b/kern.old/entrypgdir.c
new file mode 100755
index 0000000..4f324d1
--- /dev/null
+++ b/kern.old/entrypgdir.c
@@ -0,0 +1,1059 @@
+#include <inc/mmu.h>
+#include <inc/memlayout.h>
+
+pte_t entry_pgtable[NPTENTRIES];
+
+// The entry.S page directory maps the first 4MB of physical memory
+// starting at virtual address KERNBASE (that is, it maps virtual
+// addresses [KERNBASE, KERNBASE+4MB) to physical addresses [0, 4MB)).
+// We choose 4MB because that's how much we can map with one page
+// table and it's enough to get us through early boot.  We also map
+// virtual addresses [0, 4MB) to physical addresses [0, 4MB); this
+// region is critical for a few instructions in entry.S and then we
+// never use it again.
+//
+// Page directories (and page tables), must start on a page boundary,
+// hence the "__aligned__" attribute.  Also, because of restrictions
+// related to linking and static initializers, we use "x + PTE_P"
+// here, rather than the more standard "x | PTE_P".  Everywhere else
+// you should use "|" to combine flags.
+__attribute__((__aligned__(PGSIZE)))
+pde_t entry_pgdir[NPDENTRIES] = {
+	// Map VA's [0, 4MB) to PA's [0, 4MB)
+	[0]
+		= ((uintptr_t)entry_pgtable - KERNBASE) + PTE_P,
+	// Map VA's [KERNBASE, KERNBASE+4MB) to PA's [0, 4MB)
+	[KERNBASE>>PDXSHIFT]
+		= ((uintptr_t)entry_pgtable - KERNBASE) + PTE_P + PTE_W
+};
+
+// Entry 0 of the page table maps to physical page 0, entry 1 to
+// physical page 1, etc.
+__attribute__((__aligned__(PGSIZE)))
+pte_t entry_pgtable[NPTENTRIES] = {
+	0x000000 | PTE_P | PTE_W,
+	0x001000 | PTE_P | PTE_W,
+	0x002000 | PTE_P | PTE_W,
+	0x003000 | PTE_P | PTE_W,
+	0x004000 | PTE_P | PTE_W,
+	0x005000 | PTE_P | PTE_W,
+	0x006000 | PTE_P | PTE_W,
+	0x007000 | PTE_P | PTE_W,
+	0x008000 | PTE_P | PTE_W,
+	0x009000 | PTE_P | PTE_W,
+	0x00a000 | PTE_P | PTE_W,
+	0x00b000 | PTE_P | PTE_W,
+	0x00c000 | PTE_P | PTE_W,
+	0x00d000 | PTE_P | PTE_W,
+	0x00e000 | PTE_P | PTE_W,
+	0x00f000 | PTE_P | PTE_W,
+	0x010000 | PTE_P | PTE_W,
+	0x011000 | PTE_P | PTE_W,
+	0x012000 | PTE_P | PTE_W,
+	0x013000 | PTE_P | PTE_W,
+	0x014000 | PTE_P | PTE_W,
+	0x015000 | PTE_P | PTE_W,
+	0x016000 | PTE_P | PTE_W,
+	0x017000 | PTE_P | PTE_W,
+	0x018000 | PTE_P | PTE_W,
+	0x019000 | PTE_P | PTE_W,
+	0x01a000 | PTE_P | PTE_W,
+	0x01b000 | PTE_P | PTE_W,
+	0x01c000 | PTE_P | PTE_W,
+	0x01d000 | PTE_P | PTE_W,
+	0x01e000 | PTE_P | PTE_W,
+	0x01f000 | PTE_P | PTE_W,
+	0x020000 | PTE_P | PTE_W,
+	0x021000 | PTE_P | PTE_W,
+	0x022000 | PTE_P | PTE_W,
+	0x023000 | PTE_P | PTE_W,
+	0x024000 | PTE_P | PTE_W,
+	0x025000 | PTE_P | PTE_W,
+	0x026000 | PTE_P | PTE_W,
+	0x027000 | PTE_P | PTE_W,
+	0x028000 | PTE_P | PTE_W,
+	0x029000 | PTE_P | PTE_W,
+	0x02a000 | PTE_P | PTE_W,
+	0x02b000 | PTE_P | PTE_W,
+	0x02c000 | PTE_P | PTE_W,
+	0x02d000 | PTE_P | PTE_W,
+	0x02e000 | PTE_P | PTE_W,
+	0x02f000 | PTE_P | PTE_W,
+	0x030000 | PTE_P | PTE_W,
+	0x031000 | PTE_P | PTE_W,
+	0x032000 | PTE_P | PTE_W,
+	0x033000 | PTE_P | PTE_W,
+	0x034000 | PTE_P | PTE_W,
+	0x035000 | PTE_P | PTE_W,
+	0x036000 | PTE_P | PTE_W,
+	0x037000 | PTE_P | PTE_W,
+	0x038000 | PTE_P | PTE_W,
+	0x039000 | PTE_P | PTE_W,
+	0x03a000 | PTE_P | PTE_W,
+	0x03b000 | PTE_P | PTE_W,
+	0x03c000 | PTE_P | PTE_W,
+	0x03d000 | PTE_P | PTE_W,
+	0x03e000 | PTE_P | PTE_W,
+	0x03f000 | PTE_P | PTE_W,
+	0x040000 | PTE_P | PTE_W,
+	0x041000 | PTE_P | PTE_W,
+	0x042000 | PTE_P | PTE_W,
+	0x043000 | PTE_P | PTE_W,
+	0x044000 | PTE_P | PTE_W,
+	0x045000 | PTE_P | PTE_W,
+	0x046000 | PTE_P | PTE_W,
+	0x047000 | PTE_P | PTE_W,
+	0x048000 | PTE_P | PTE_W,
+	0x049000 | PTE_P | PTE_W,
+	0x04a000 | PTE_P | PTE_W,
+	0x04b000 | PTE_P | PTE_W,
+	0x04c000 | PTE_P | PTE_W,
+	0x04d000 | PTE_P | PTE_W,
+	0x04e000 | PTE_P | PTE_W,
+	0x04f000 | PTE_P | PTE_W,
+	0x050000 | PTE_P | PTE_W,
+	0x051000 | PTE_P | PTE_W,
+	0x052000 | PTE_P | PTE_W,
+	0x053000 | PTE_P | PTE_W,
+	0x054000 | PTE_P | PTE_W,
+	0x055000 | PTE_P | PTE_W,
+	0x056000 | PTE_P | PTE_W,
+	0x057000 | PTE_P | PTE_W,
+	0x058000 | PTE_P | PTE_W,
+	0x059000 | PTE_P | PTE_W,
+	0x05a000 | PTE_P | PTE_W,
+	0x05b000 | PTE_P | PTE_W,
+	0x05c000 | PTE_P | PTE_W,
+	0x05d000 | PTE_P | PTE_W,
+	0x05e000 | PTE_P | PTE_W,
+	0x05f000 | PTE_P | PTE_W,
+	0x060000 | PTE_P | PTE_W,
+	0x061000 | PTE_P | PTE_W,
+	0x062000 | PTE_P | PTE_W,
+	0x063000 | PTE_P | PTE_W,
+	0x064000 | PTE_P | PTE_W,
+	0x065000 | PTE_P | PTE_W,
+	0x066000 | PTE_P | PTE_W,
+	0x067000 | PTE_P | PTE_W,
+	0x068000 | PTE_P | PTE_W,
+	0x069000 | PTE_P | PTE_W,
+	0x06a000 | PTE_P | PTE_W,
+	0x06b000 | PTE_P | PTE_W,
+	0x06c000 | PTE_P | PTE_W,
+	0x06d000 | PTE_P | PTE_W,
+	0x06e000 | PTE_P | PTE_W,
+	0x06f000 | PTE_P | PTE_W,
+	0x070000 | PTE_P | PTE_W,
+	0x071000 | PTE_P | PTE_W,
+	0x072000 | PTE_P | PTE_W,
+	0x073000 | PTE_P | PTE_W,
+	0x074000 | PTE_P | PTE_W,
+	0x075000 | PTE_P | PTE_W,
+	0x076000 | PTE_P | PTE_W,
+	0x077000 | PTE_P | PTE_W,
+	0x078000 | PTE_P | PTE_W,
+	0x079000 | PTE_P | PTE_W,
+	0x07a000 | PTE_P | PTE_W,
+	0x07b000 | PTE_P | PTE_W,
+	0x07c000 | PTE_P | PTE_W,
+	0x07d000 | PTE_P | PTE_W,
+	0x07e000 | PTE_P | PTE_W,
+	0x07f000 | PTE_P | PTE_W,
+	0x080000 | PTE_P | PTE_W,
+	0x081000 | PTE_P | PTE_W,
+	0x082000 | PTE_P | PTE_W,
+	0x083000 | PTE_P | PTE_W,
+	0x084000 | PTE_P | PTE_W,
+	0x085000 | PTE_P | PTE_W,
+	0x086000 | PTE_P | PTE_W,
+	0x087000 | PTE_P | PTE_W,
+	0x088000 | PTE_P | PTE_W,
+	0x089000 | PTE_P | PTE_W,
+	0x08a000 | PTE_P | PTE_W,
+	0x08b000 | PTE_P | PTE_W,
+	0x08c000 | PTE_P | PTE_W,
+	0x08d000 | PTE_P | PTE_W,
+	0x08e000 | PTE_P | PTE_W,
+	0x08f000 | PTE_P | PTE_W,
+	0x090000 | PTE_P | PTE_W,
+	0x091000 | PTE_P | PTE_W,
+	0x092000 | PTE_P | PTE_W,
+	0x093000 | PTE_P | PTE_W,
+	0x094000 | PTE_P | PTE_W,
+	0x095000 | PTE_P | PTE_W,
+	0x096000 | PTE_P | PTE_W,
+	0x097000 | PTE_P | PTE_W,
+	0x098000 | PTE_P | PTE_W,
+	0x099000 | PTE_P | PTE_W,
+	0x09a000 | PTE_P | PTE_W,
+	0x09b000 | PTE_P | PTE_W,
+	0x09c000 | PTE_P | PTE_W,
+	0x09d000 | PTE_P | PTE_W,
+	0x09e000 | PTE_P | PTE_W,
+	0x09f000 | PTE_P | PTE_W,
+	0x0a0000 | PTE_P | PTE_W,
+	0x0a1000 | PTE_P | PTE_W,
+	0x0a2000 | PTE_P | PTE_W,
+	0x0a3000 | PTE_P | PTE_W,
+	0x0a4000 | PTE_P | PTE_W,
+	0x0a5000 | PTE_P | PTE_W,
+	0x0a6000 | PTE_P | PTE_W,
+	0x0a7000 | PTE_P | PTE_W,
+	0x0a8000 | PTE_P | PTE_W,
+	0x0a9000 | PTE_P | PTE_W,
+	0x0aa000 | PTE_P | PTE_W,
+	0x0ab000 | PTE_P | PTE_W,
+	0x0ac000 | PTE_P | PTE_W,
+	0x0ad000 | PTE_P | PTE_W,
+	0x0ae000 | PTE_P | PTE_W,
+	0x0af000 | PTE_P | PTE_W,
+	0x0b0000 | PTE_P | PTE_W,
+	0x0b1000 | PTE_P | PTE_W,
+	0x0b2000 | PTE_P | PTE_W,
+	0x0b3000 | PTE_P | PTE_W,
+	0x0b4000 | PTE_P | PTE_W,
+	0x0b5000 | PTE_P | PTE_W,
+	0x0b6000 | PTE_P | PTE_W,
+	0x0b7000 | PTE_P | PTE_W,
+	0x0b8000 | PTE_P | PTE_W,
+	0x0b9000 | PTE_P | PTE_W,
+	0x0ba000 | PTE_P | PTE_W,
+	0x0bb000 | PTE_P | PTE_W,
+	0x0bc000 | PTE_P | PTE_W,
+	0x0bd000 | PTE_P | PTE_W,
+	0x0be000 | PTE_P | PTE_W,
+	0x0bf000 | PTE_P | PTE_W,
+	0x0c0000 | PTE_P | PTE_W,
+	0x0c1000 | PTE_P | PTE_W,
+	0x0c2000 | PTE_P | PTE_W,
+	0x0c3000 | PTE_P | PTE_W,
+	0x0c4000 | PTE_P | PTE_W,
+	0x0c5000 | PTE_P | PTE_W,
+	0x0c6000 | PTE_P | PTE_W,
+	0x0c7000 | PTE_P | PTE_W,
+	0x0c8000 | PTE_P | PTE_W,
+	0x0c9000 | PTE_P | PTE_W,
+	0x0ca000 | PTE_P | PTE_W,
+	0x0cb000 | PTE_P | PTE_W,
+	0x0cc000 | PTE_P | PTE_W,
+	0x0cd000 | PTE_P | PTE_W,
+	0x0ce000 | PTE_P | PTE_W,
+	0x0cf000 | PTE_P | PTE_W,
+	0x0d0000 | PTE_P | PTE_W,
+	0x0d1000 | PTE_P | PTE_W,
+	0x0d2000 | PTE_P | PTE_W,
+	0x0d3000 | PTE_P | PTE_W,
+	0x0d4000 | PTE_P | PTE_W,
+	0x0d5000 | PTE_P | PTE_W,
+	0x0d6000 | PTE_P | PTE_W,
+	0x0d7000 | PTE_P | PTE_W,
+	0x0d8000 | PTE_P | PTE_W,
+	0x0d9000 | PTE_P | PTE_W,
+	0x0da000 | PTE_P | PTE_W,
+	0x0db000 | PTE_P | PTE_W,
+	0x0dc000 | PTE_P | PTE_W,
+	0x0dd000 | PTE_P | PTE_W,
+	0x0de000 | PTE_P | PTE_W,
+	0x0df000 | PTE_P | PTE_W,
+	0x0e0000 | PTE_P | PTE_W,
+	0x0e1000 | PTE_P | PTE_W,
+	0x0e2000 | PTE_P | PTE_W,
+	0x0e3000 | PTE_P | PTE_W,
+	0x0e4000 | PTE_P | PTE_W,
+	0x0e5000 | PTE_P | PTE_W,
+	0x0e6000 | PTE_P | PTE_W,
+	0x0e7000 | PTE_P | PTE_W,
+	0x0e8000 | PTE_P | PTE_W,
+	0x0e9000 | PTE_P | PTE_W,
+	0x0ea000 | PTE_P | PTE_W,
+	0x0eb000 | PTE_P | PTE_W,
+	0x0ec000 | PTE_P | PTE_W,
+	0x0ed000 | PTE_P | PTE_W,
+	0x0ee000 | PTE_P | PTE_W,
+	0x0ef000 | PTE_P | PTE_W,
+	0x0f0000 | PTE_P | PTE_W,
+	0x0f1000 | PTE_P | PTE_W,
+	0x0f2000 | PTE_P | PTE_W,
+	0x0f3000 | PTE_P | PTE_W,
+	0x0f4000 | PTE_P | PTE_W,
+	0x0f5000 | PTE_P | PTE_W,
+	0x0f6000 | PTE_P | PTE_W,
+	0x0f7000 | PTE_P | PTE_W,
+	0x0f8000 | PTE_P | PTE_W,
+	0x0f9000 | PTE_P | PTE_W,
+	0x0fa000 | PTE_P | PTE_W,
+	0x0fb000 | PTE_P | PTE_W,
+	0x0fc000 | PTE_P | PTE_W,
+	0x0fd000 | PTE_P | PTE_W,
+	0x0fe000 | PTE_P | PTE_W,
+	0x0ff000 | PTE_P | PTE_W,
+	0x100000 | PTE_P | PTE_W,
+	0x101000 | PTE_P | PTE_W,
+	0x102000 | PTE_P | PTE_W,
+	0x103000 | PTE_P | PTE_W,
+	0x104000 | PTE_P | PTE_W,
+	0x105000 | PTE_P | PTE_W,
+	0x106000 | PTE_P | PTE_W,
+	0x107000 | PTE_P | PTE_W,
+	0x108000 | PTE_P | PTE_W,
+	0x109000 | PTE_P | PTE_W,
+	0x10a000 | PTE_P | PTE_W,
+	0x10b000 | PTE_P | PTE_W,
+	0x10c000 | PTE_P | PTE_W,
+	0x10d000 | PTE_P | PTE_W,
+	0x10e000 | PTE_P | PTE_W,
+	0x10f000 | PTE_P | PTE_W,
+	0x110000 | PTE_P | PTE_W,
+	0x111000 | PTE_P | PTE_W,
+	0x112000 | PTE_P | PTE_W,
+	0x113000 | PTE_P | PTE_W,
+	0x114000 | PTE_P | PTE_W,
+	0x115000 | PTE_P | PTE_W,
+	0x116000 | PTE_P | PTE_W,
+	0x117000 | PTE_P | PTE_W,
+	0x118000 | PTE_P | PTE_W,
+	0x119000 | PTE_P | PTE_W,
+	0x11a000 | PTE_P | PTE_W,
+	0x11b000 | PTE_P | PTE_W,
+	0x11c000 | PTE_P | PTE_W,
+	0x11d000 | PTE_P | PTE_W,
+	0x11e000 | PTE_P | PTE_W,
+	0x11f000 | PTE_P | PTE_W,
+	0x120000 | PTE_P | PTE_W,
+	0x121000 | PTE_P | PTE_W,
+	0x122000 | PTE_P | PTE_W,
+	0x123000 | PTE_P | PTE_W,
+	0x124000 | PTE_P | PTE_W,
+	0x125000 | PTE_P | PTE_W,
+	0x126000 | PTE_P | PTE_W,
+	0x127000 | PTE_P | PTE_W,
+	0x128000 | PTE_P | PTE_W,
+	0x129000 | PTE_P | PTE_W,
+	0x12a000 | PTE_P | PTE_W,
+	0x12b000 | PTE_P | PTE_W,
+	0x12c000 | PTE_P | PTE_W,
+	0x12d000 | PTE_P | PTE_W,
+	0x12e000 | PTE_P | PTE_W,
+	0x12f000 | PTE_P | PTE_W,
+	0x130000 | PTE_P | PTE_W,
+	0x131000 | PTE_P | PTE_W,
+	0x132000 | PTE_P | PTE_W,
+	0x133000 | PTE_P | PTE_W,
+	0x134000 | PTE_P | PTE_W,
+	0x135000 | PTE_P | PTE_W,
+	0x136000 | PTE_P | PTE_W,
+	0x137000 | PTE_P | PTE_W,
+	0x138000 | PTE_P | PTE_W,
+	0x139000 | PTE_P | PTE_W,
+	0x13a000 | PTE_P | PTE_W,
+	0x13b000 | PTE_P | PTE_W,
+	0x13c000 | PTE_P | PTE_W,
+	0x13d000 | PTE_P | PTE_W,
+	0x13e000 | PTE_P | PTE_W,
+	0x13f000 | PTE_P | PTE_W,
+	0x140000 | PTE_P | PTE_W,
+	0x141000 | PTE_P | PTE_W,
+	0x142000 | PTE_P | PTE_W,
+	0x143000 | PTE_P | PTE_W,
+	0x144000 | PTE_P | PTE_W,
+	0x145000 | PTE_P | PTE_W,
+	0x146000 | PTE_P | PTE_W,
+	0x147000 | PTE_P | PTE_W,
+	0x148000 | PTE_P | PTE_W,
+	0x149000 | PTE_P | PTE_W,
+	0x14a000 | PTE_P | PTE_W,
+	0x14b000 | PTE_P | PTE_W,
+	0x14c000 | PTE_P | PTE_W,
+	0x14d000 | PTE_P | PTE_W,
+	0x14e000 | PTE_P | PTE_W,
+	0x14f000 | PTE_P | PTE_W,
+	0x150000 | PTE_P | PTE_W,
+	0x151000 | PTE_P | PTE_W,
+	0x152000 | PTE_P | PTE_W,
+	0x153000 | PTE_P | PTE_W,
+	0x154000 | PTE_P | PTE_W,
+	0x155000 | PTE_P | PTE_W,
+	0x156000 | PTE_P | PTE_W,
+	0x157000 | PTE_P | PTE_W,
+	0x158000 | PTE_P | PTE_W,
+	0x159000 | PTE_P | PTE_W,
+	0x15a000 | PTE_P | PTE_W,
+	0x15b000 | PTE_P | PTE_W,
+	0x15c000 | PTE_P | PTE_W,
+	0x15d000 | PTE_P | PTE_W,
+	0x15e000 | PTE_P | PTE_W,
+	0x15f000 | PTE_P | PTE_W,
+	0x160000 | PTE_P | PTE_W,
+	0x161000 | PTE_P | PTE_W,
+	0x162000 | PTE_P | PTE_W,
+	0x163000 | PTE_P | PTE_W,
+	0x164000 | PTE_P | PTE_W,
+	0x165000 | PTE_P | PTE_W,
+	0x166000 | PTE_P | PTE_W,
+	0x167000 | PTE_P | PTE_W,
+	0x168000 | PTE_P | PTE_W,
+	0x169000 | PTE_P | PTE_W,
+	0x16a000 | PTE_P | PTE_W,
+	0x16b000 | PTE_P | PTE_W,
+	0x16c000 | PTE_P | PTE_W,
+	0x16d000 | PTE_P | PTE_W,
+	0x16e000 | PTE_P | PTE_W,
+	0x16f000 | PTE_P | PTE_W,
+	0x170000 | PTE_P | PTE_W,
+	0x171000 | PTE_P | PTE_W,
+	0x172000 | PTE_P | PTE_W,
+	0x173000 | PTE_P | PTE_W,
+	0x174000 | PTE_P | PTE_W,
+	0x175000 | PTE_P | PTE_W,
+	0x176000 | PTE_P | PTE_W,
+	0x177000 | PTE_P | PTE_W,
+	0x178000 | PTE_P | PTE_W,
+	0x179000 | PTE_P | PTE_W,
+	0x17a000 | PTE_P | PTE_W,
+	0x17b000 | PTE_P | PTE_W,
+	0x17c000 | PTE_P | PTE_W,
+	0x17d000 | PTE_P | PTE_W,
+	0x17e000 | PTE_P | PTE_W,
+	0x17f000 | PTE_P | PTE_W,
+	0x180000 | PTE_P | PTE_W,
+	0x181000 | PTE_P | PTE_W,
+	0x182000 | PTE_P | PTE_W,
+	0x183000 | PTE_P | PTE_W,
+	0x184000 | PTE_P | PTE_W,
+	0x185000 | PTE_P | PTE_W,
+	0x186000 | PTE_P | PTE_W,
+	0x187000 | PTE_P | PTE_W,
+	0x188000 | PTE_P | PTE_W,
+	0x189000 | PTE_P | PTE_W,
+	0x18a000 | PTE_P | PTE_W,
+	0x18b000 | PTE_P | PTE_W,
+	0x18c000 | PTE_P | PTE_W,
+	0x18d000 | PTE_P | PTE_W,
+	0x18e000 | PTE_P | PTE_W,
+	0x18f000 | PTE_P | PTE_W,
+	0x190000 | PTE_P | PTE_W,
+	0x191000 | PTE_P | PTE_W,
+	0x192000 | PTE_P | PTE_W,
+	0x193000 | PTE_P | PTE_W,
+	0x194000 | PTE_P | PTE_W,
+	0x195000 | PTE_P | PTE_W,
+	0x196000 | PTE_P | PTE_W,
+	0x197000 | PTE_P | PTE_W,
+	0x198000 | PTE_P | PTE_W,
+	0x199000 | PTE_P | PTE_W,
+	0x19a000 | PTE_P | PTE_W,
+	0x19b000 | PTE_P | PTE_W,
+	0x19c000 | PTE_P | PTE_W,
+	0x19d000 | PTE_P | PTE_W,
+	0x19e000 | PTE_P | PTE_W,
+	0x19f000 | PTE_P | PTE_W,
+	0x1a0000 | PTE_P | PTE_W,
+	0x1a1000 | PTE_P | PTE_W,
+	0x1a2000 | PTE_P | PTE_W,
+	0x1a3000 | PTE_P | PTE_W,
+	0x1a4000 | PTE_P | PTE_W,
+	0x1a5000 | PTE_P | PTE_W,
+	0x1a6000 | PTE_P | PTE_W,
+	0x1a7000 | PTE_P | PTE_W,
+	0x1a8000 | PTE_P | PTE_W,
+	0x1a9000 | PTE_P | PTE_W,
+	0x1aa000 | PTE_P | PTE_W,
+	0x1ab000 | PTE_P | PTE_W,
+	0x1ac000 | PTE_P | PTE_W,
+	0x1ad000 | PTE_P | PTE_W,
+	0x1ae000 | PTE_P | PTE_W,
+	0x1af000 | PTE_P | PTE_W,
+	0x1b0000 | PTE_P | PTE_W,
+	0x1b1000 | PTE_P | PTE_W,
+	0x1b2000 | PTE_P | PTE_W,
+	0x1b3000 | PTE_P | PTE_W,
+	0x1b4000 | PTE_P | PTE_W,
+	0x1b5000 | PTE_P | PTE_W,
+	0x1b6000 | PTE_P | PTE_W,
+	0x1b7000 | PTE_P | PTE_W,
+	0x1b8000 | PTE_P | PTE_W,
+	0x1b9000 | PTE_P | PTE_W,
+	0x1ba000 | PTE_P | PTE_W,
+	0x1bb000 | PTE_P | PTE_W,
+	0x1bc000 | PTE_P | PTE_W,
+	0x1bd000 | PTE_P | PTE_W,
+	0x1be000 | PTE_P | PTE_W,
+	0x1bf000 | PTE_P | PTE_W,
+	0x1c0000 | PTE_P | PTE_W,
+	0x1c1000 | PTE_P | PTE_W,
+	0x1c2000 | PTE_P | PTE_W,
+	0x1c3000 | PTE_P | PTE_W,
+	0x1c4000 | PTE_P | PTE_W,
+	0x1c5000 | PTE_P | PTE_W,
+	0x1c6000 | PTE_P | PTE_W,
+	0x1c7000 | PTE_P | PTE_W,
+	0x1c8000 | PTE_P | PTE_W,
+	0x1c9000 | PTE_P | PTE_W,
+	0x1ca000 | PTE_P | PTE_W,
+	0x1cb000 | PTE_P | PTE_W,
+	0x1cc000 | PTE_P | PTE_W,
+	0x1cd000 | PTE_P | PTE_W,
+	0x1ce000 | PTE_P | PTE_W,
+	0x1cf000 | PTE_P | PTE_W,
+	0x1d0000 | PTE_P | PTE_W,
+	0x1d1000 | PTE_P | PTE_W,
+	0x1d2000 | PTE_P | PTE_W,
+	0x1d3000 | PTE_P | PTE_W,
+	0x1d4000 | PTE_P | PTE_W,
+	0x1d5000 | PTE_P | PTE_W,
+	0x1d6000 | PTE_P | PTE_W,
+	0x1d7000 | PTE_P | PTE_W,
+	0x1d8000 | PTE_P | PTE_W,
+	0x1d9000 | PTE_P | PTE_W,
+	0x1da000 | PTE_P | PTE_W,
+	0x1db000 | PTE_P | PTE_W,
+	0x1dc000 | PTE_P | PTE_W,
+	0x1dd000 | PTE_P | PTE_W,
+	0x1de000 | PTE_P | PTE_W,
+	0x1df000 | PTE_P | PTE_W,
+	0x1e0000 | PTE_P | PTE_W,
+	0x1e1000 | PTE_P | PTE_W,
+	0x1e2000 | PTE_P | PTE_W,
+	0x1e3000 | PTE_P | PTE_W,
+	0x1e4000 | PTE_P | PTE_W,
+	0x1e5000 | PTE_P | PTE_W,
+	0x1e6000 | PTE_P | PTE_W,
+	0x1e7000 | PTE_P | PTE_W,
+	0x1e8000 | PTE_P | PTE_W,
+	0x1e9000 | PTE_P | PTE_W,
+	0x1ea000 | PTE_P | PTE_W,
+	0x1eb000 | PTE_P | PTE_W,
+	0x1ec000 | PTE_P | PTE_W,
+	0x1ed000 | PTE_P | PTE_W,
+	0x1ee000 | PTE_P | PTE_W,
+	0x1ef000 | PTE_P | PTE_W,
+	0x1f0000 | PTE_P | PTE_W,
+	0x1f1000 | PTE_P | PTE_W,
+	0x1f2000 | PTE_P | PTE_W,
+	0x1f3000 | PTE_P | PTE_W,
+	0x1f4000 | PTE_P | PTE_W,
+	0x1f5000 | PTE_P | PTE_W,
+	0x1f6000 | PTE_P | PTE_W,
+	0x1f7000 | PTE_P | PTE_W,
+	0x1f8000 | PTE_P | PTE_W,
+	0x1f9000 | PTE_P | PTE_W,
+	0x1fa000 | PTE_P | PTE_W,
+	0x1fb000 | PTE_P | PTE_W,
+	0x1fc000 | PTE_P | PTE_W,
+	0x1fd000 | PTE_P | PTE_W,
+	0x1fe000 | PTE_P | PTE_W,
+	0x1ff000 | PTE_P | PTE_W,
+	0x200000 | PTE_P | PTE_W,
+	0x201000 | PTE_P | PTE_W,
+	0x202000 | PTE_P | PTE_W,
+	0x203000 | PTE_P | PTE_W,
+	0x204000 | PTE_P | PTE_W,
+	0x205000 | PTE_P | PTE_W,
+	0x206000 | PTE_P | PTE_W,
+	0x207000 | PTE_P | PTE_W,
+	0x208000 | PTE_P | PTE_W,
+	0x209000 | PTE_P | PTE_W,
+	0x20a000 | PTE_P | PTE_W,
+	0x20b000 | PTE_P | PTE_W,
+	0x20c000 | PTE_P | PTE_W,
+	0x20d000 | PTE_P | PTE_W,
+	0x20e000 | PTE_P | PTE_W,
+	0x20f000 | PTE_P | PTE_W,
+	0x210000 | PTE_P | PTE_W,
+	0x211000 | PTE_P | PTE_W,
+	0x212000 | PTE_P | PTE_W,
+	0x213000 | PTE_P | PTE_W,
+	0x214000 | PTE_P | PTE_W,
+	0x215000 | PTE_P | PTE_W,
+	0x216000 | PTE_P | PTE_W,
+	0x217000 | PTE_P | PTE_W,
+	0x218000 | PTE_P | PTE_W,
+	0x219000 | PTE_P | PTE_W,
+	0x21a000 | PTE_P | PTE_W,
+	0x21b000 | PTE_P | PTE_W,
+	0x21c000 | PTE_P | PTE_W,
+	0x21d000 | PTE_P | PTE_W,
+	0x21e000 | PTE_P | PTE_W,
+	0x21f000 | PTE_P | PTE_W,
+	0x220000 | PTE_P | PTE_W,
+	0x221000 | PTE_P | PTE_W,
+	0x222000 | PTE_P | PTE_W,
+	0x223000 | PTE_P | PTE_W,
+	0x224000 | PTE_P | PTE_W,
+	0x225000 | PTE_P | PTE_W,
+	0x226000 | PTE_P | PTE_W,
+	0x227000 | PTE_P | PTE_W,
+	0x228000 | PTE_P | PTE_W,
+	0x229000 | PTE_P | PTE_W,
+	0x22a000 | PTE_P | PTE_W,
+	0x22b000 | PTE_P | PTE_W,
+	0x22c000 | PTE_P | PTE_W,
+	0x22d000 | PTE_P | PTE_W,
+	0x22e000 | PTE_P | PTE_W,
+	0x22f000 | PTE_P | PTE_W,
+	0x230000 | PTE_P | PTE_W,
+	0x231000 | PTE_P | PTE_W,
+	0x232000 | PTE_P | PTE_W,
+	0x233000 | PTE_P | PTE_W,
+	0x234000 | PTE_P | PTE_W,
+	0x235000 | PTE_P | PTE_W,
+	0x236000 | PTE_P | PTE_W,
+	0x237000 | PTE_P | PTE_W,
+	0x238000 | PTE_P | PTE_W,
+	0x239000 | PTE_P | PTE_W,
+	0x23a000 | PTE_P | PTE_W,
+	0x23b000 | PTE_P | PTE_W,
+	0x23c000 | PTE_P | PTE_W,
+	0x23d000 | PTE_P | PTE_W,
+	0x23e000 | PTE_P | PTE_W,
+	0x23f000 | PTE_P | PTE_W,
+	0x240000 | PTE_P | PTE_W,
+	0x241000 | PTE_P | PTE_W,
+	0x242000 | PTE_P | PTE_W,
+	0x243000 | PTE_P | PTE_W,
+	0x244000 | PTE_P | PTE_W,
+	0x245000 | PTE_P | PTE_W,
+	0x246000 | PTE_P | PTE_W,
+	0x247000 | PTE_P | PTE_W,
+	0x248000 | PTE_P | PTE_W,
+	0x249000 | PTE_P | PTE_W,
+	0x24a000 | PTE_P | PTE_W,
+	0x24b000 | PTE_P | PTE_W,
+	0x24c000 | PTE_P | PTE_W,
+	0x24d000 | PTE_P | PTE_W,
+	0x24e000 | PTE_P | PTE_W,
+	0x24f000 | PTE_P | PTE_W,
+	0x250000 | PTE_P | PTE_W,
+	0x251000 | PTE_P | PTE_W,
+	0x252000 | PTE_P | PTE_W,
+	0x253000 | PTE_P | PTE_W,
+	0x254000 | PTE_P | PTE_W,
+	0x255000 | PTE_P | PTE_W,
+	0x256000 | PTE_P | PTE_W,
+	0x257000 | PTE_P | PTE_W,
+	0x258000 | PTE_P | PTE_W,
+	0x259000 | PTE_P | PTE_W,
+	0x25a000 | PTE_P | PTE_W,
+	0x25b000 | PTE_P | PTE_W,
+	0x25c000 | PTE_P | PTE_W,
+	0x25d000 | PTE_P | PTE_W,
+	0x25e000 | PTE_P | PTE_W,
+	0x25f000 | PTE_P | PTE_W,
+	0x260000 | PTE_P | PTE_W,
+	0x261000 | PTE_P | PTE_W,
+	0x262000 | PTE_P | PTE_W,
+	0x263000 | PTE_P | PTE_W,
+	0x264000 | PTE_P | PTE_W,
+	0x265000 | PTE_P | PTE_W,
+	0x266000 | PTE_P | PTE_W,
+	0x267000 | PTE_P | PTE_W,
+	0x268000 | PTE_P | PTE_W,
+	0x269000 | PTE_P | PTE_W,
+	0x26a000 | PTE_P | PTE_W,
+	0x26b000 | PTE_P | PTE_W,
+	0x26c000 | PTE_P | PTE_W,
+	0x26d000 | PTE_P | PTE_W,
+	0x26e000 | PTE_P | PTE_W,
+	0x26f000 | PTE_P | PTE_W,
+	0x270000 | PTE_P | PTE_W,
+	0x271000 | PTE_P | PTE_W,
+	0x272000 | PTE_P | PTE_W,
+	0x273000 | PTE_P | PTE_W,
+	0x274000 | PTE_P | PTE_W,
+	0x275000 | PTE_P | PTE_W,
+	0x276000 | PTE_P | PTE_W,
+	0x277000 | PTE_P | PTE_W,
+	0x278000 | PTE_P | PTE_W,
+	0x279000 | PTE_P | PTE_W,
+	0x27a000 | PTE_P | PTE_W,
+	0x27b000 | PTE_P | PTE_W,
+	0x27c000 | PTE_P | PTE_W,
+	0x27d000 | PTE_P | PTE_W,
+	0x27e000 | PTE_P | PTE_W,
+	0x27f000 | PTE_P | PTE_W,
+	0x280000 | PTE_P | PTE_W,
+	0x281000 | PTE_P | PTE_W,
+	0x282000 | PTE_P | PTE_W,
+	0x283000 | PTE_P | PTE_W,
+	0x284000 | PTE_P | PTE_W,
+	0x285000 | PTE_P | PTE_W,
+	0x286000 | PTE_P | PTE_W,
+	0x287000 | PTE_P | PTE_W,
+	0x288000 | PTE_P | PTE_W,
+	0x289000 | PTE_P | PTE_W,
+	0x28a000 | PTE_P | PTE_W,
+	0x28b000 | PTE_P | PTE_W,
+	0x28c000 | PTE_P | PTE_W,
+	0x28d000 | PTE_P | PTE_W,
+	0x28e000 | PTE_P | PTE_W,
+	0x28f000 | PTE_P | PTE_W,
+	0x290000 | PTE_P | PTE_W,
+	0x291000 | PTE_P | PTE_W,
+	0x292000 | PTE_P | PTE_W,
+	0x293000 | PTE_P | PTE_W,
+	0x294000 | PTE_P | PTE_W,
+	0x295000 | PTE_P | PTE_W,
+	0x296000 | PTE_P | PTE_W,
+	0x297000 | PTE_P | PTE_W,
+	0x298000 | PTE_P | PTE_W,
+	0x299000 | PTE_P | PTE_W,
+	0x29a000 | PTE_P | PTE_W,
+	0x29b000 | PTE_P | PTE_W,
+	0x29c000 | PTE_P | PTE_W,
+	0x29d000 | PTE_P | PTE_W,
+	0x29e000 | PTE_P | PTE_W,
+	0x29f000 | PTE_P | PTE_W,
+	0x2a0000 | PTE_P | PTE_W,
+	0x2a1000 | PTE_P | PTE_W,
+	0x2a2000 | PTE_P | PTE_W,
+	0x2a3000 | PTE_P | PTE_W,
+	0x2a4000 | PTE_P | PTE_W,
+	0x2a5000 | PTE_P | PTE_W,
+	0x2a6000 | PTE_P | PTE_W,
+	0x2a7000 | PTE_P | PTE_W,
+	0x2a8000 | PTE_P | PTE_W,
+	0x2a9000 | PTE_P | PTE_W,
+	0x2aa000 | PTE_P | PTE_W,
+	0x2ab000 | PTE_P | PTE_W,
+	0x2ac000 | PTE_P | PTE_W,
+	0x2ad000 | PTE_P | PTE_W,
+	0x2ae000 | PTE_P | PTE_W,
+	0x2af000 | PTE_P | PTE_W,
+	0x2b0000 | PTE_P | PTE_W,
+	0x2b1000 | PTE_P | PTE_W,
+	0x2b2000 | PTE_P | PTE_W,
+	0x2b3000 | PTE_P | PTE_W,
+	0x2b4000 | PTE_P | PTE_W,
+	0x2b5000 | PTE_P | PTE_W,
+	0x2b6000 | PTE_P | PTE_W,
+	0x2b7000 | PTE_P | PTE_W,
+	0x2b8000 | PTE_P | PTE_W,
+	0x2b9000 | PTE_P | PTE_W,
+	0x2ba000 | PTE_P | PTE_W,
+	0x2bb000 | PTE_P | PTE_W,
+	0x2bc000 | PTE_P | PTE_W,
+	0x2bd000 | PTE_P | PTE_W,
+	0x2be000 | PTE_P | PTE_W,
+	0x2bf000 | PTE_P | PTE_W,
+	0x2c0000 | PTE_P | PTE_W,
+	0x2c1000 | PTE_P | PTE_W,
+	0x2c2000 | PTE_P | PTE_W,
+	0x2c3000 | PTE_P | PTE_W,
+	0x2c4000 | PTE_P | PTE_W,
+	0x2c5000 | PTE_P | PTE_W,
+	0x2c6000 | PTE_P | PTE_W,
+	0x2c7000 | PTE_P | PTE_W,
+	0x2c8000 | PTE_P | PTE_W,
+	0x2c9000 | PTE_P | PTE_W,
+	0x2ca000 | PTE_P | PTE_W,
+	0x2cb000 | PTE_P | PTE_W,
+	0x2cc000 | PTE_P | PTE_W,
+	0x2cd000 | PTE_P | PTE_W,
+	0x2ce000 | PTE_P | PTE_W,
+	0x2cf000 | PTE_P | PTE_W,
+	0x2d0000 | PTE_P | PTE_W,
+	0x2d1000 | PTE_P | PTE_W,
+	0x2d2000 | PTE_P | PTE_W,
+	0x2d3000 | PTE_P | PTE_W,
+	0x2d4000 | PTE_P | PTE_W,
+	0x2d5000 | PTE_P | PTE_W,
+	0x2d6000 | PTE_P | PTE_W,
+	0x2d7000 | PTE_P | PTE_W,
+	0x2d8000 | PTE_P | PTE_W,
+	0x2d9000 | PTE_P | PTE_W,
+	0x2da000 | PTE_P | PTE_W,
+	0x2db000 | PTE_P | PTE_W,
+	0x2dc000 | PTE_P | PTE_W,
+	0x2dd000 | PTE_P | PTE_W,
+	0x2de000 | PTE_P | PTE_W,
+	0x2df000 | PTE_P | PTE_W,
+	0x2e0000 | PTE_P | PTE_W,
+	0x2e1000 | PTE_P | PTE_W,
+	0x2e2000 | PTE_P | PTE_W,
+	0x2e3000 | PTE_P | PTE_W,
+	0x2e4000 | PTE_P | PTE_W,
+	0x2e5000 | PTE_P | PTE_W,
+	0x2e6000 | PTE_P | PTE_W,
+	0x2e7000 | PTE_P | PTE_W,
+	0x2e8000 | PTE_P | PTE_W,
+	0x2e9000 | PTE_P | PTE_W,
+	0x2ea000 | PTE_P | PTE_W,
+	0x2eb000 | PTE_P | PTE_W,
+	0x2ec000 | PTE_P | PTE_W,
+	0x2ed000 | PTE_P | PTE_W,
+	0x2ee000 | PTE_P | PTE_W,
+	0x2ef000 | PTE_P | PTE_W,
+	0x2f0000 | PTE_P | PTE_W,
+	0x2f1000 | PTE_P | PTE_W,
+	0x2f2000 | PTE_P | PTE_W,
+	0x2f3000 | PTE_P | PTE_W,
+	0x2f4000 | PTE_P | PTE_W,
+	0x2f5000 | PTE_P | PTE_W,
+	0x2f6000 | PTE_P | PTE_W,
+	0x2f7000 | PTE_P | PTE_W,
+	0x2f8000 | PTE_P | PTE_W,
+	0x2f9000 | PTE_P | PTE_W,
+	0x2fa000 | PTE_P | PTE_W,
+	0x2fb000 | PTE_P | PTE_W,
+	0x2fc000 | PTE_P | PTE_W,
+	0x2fd000 | PTE_P | PTE_W,
+	0x2fe000 | PTE_P | PTE_W,
+	0x2ff000 | PTE_P | PTE_W,
+	0x300000 | PTE_P | PTE_W,
+	0x301000 | PTE_P | PTE_W,
+	0x302000 | PTE_P | PTE_W,
+	0x303000 | PTE_P | PTE_W,
+	0x304000 | PTE_P | PTE_W,
+	0x305000 | PTE_P | PTE_W,
+	0x306000 | PTE_P | PTE_W,
+	0x307000 | PTE_P | PTE_W,
+	0x308000 | PTE_P | PTE_W,
+	0x309000 | PTE_P | PTE_W,
+	0x30a000 | PTE_P | PTE_W,
+	0x30b000 | PTE_P | PTE_W,
+	0x30c000 | PTE_P | PTE_W,
+	0x30d000 | PTE_P | PTE_W,
+	0x30e000 | PTE_P | PTE_W,
+	0x30f000 | PTE_P | PTE_W,
+	0x310000 | PTE_P | PTE_W,
+	0x311000 | PTE_P | PTE_W,
+	0x312000 | PTE_P | PTE_W,
+	0x313000 | PTE_P | PTE_W,
+	0x314000 | PTE_P | PTE_W,
+	0x315000 | PTE_P | PTE_W,
+	0x316000 | PTE_P | PTE_W,
+	0x317000 | PTE_P | PTE_W,
+	0x318000 | PTE_P | PTE_W,
+	0x319000 | PTE_P | PTE_W,
+	0x31a000 | PTE_P | PTE_W,
+	0x31b000 | PTE_P | PTE_W,
+	0x31c000 | PTE_P | PTE_W,
+	0x31d000 | PTE_P | PTE_W,
+	0x31e000 | PTE_P | PTE_W,
+	0x31f000 | PTE_P | PTE_W,
+	0x320000 | PTE_P | PTE_W,
+	0x321000 | PTE_P | PTE_W,
+	0x322000 | PTE_P | PTE_W,
+	0x323000 | PTE_P | PTE_W,
+	0x324000 | PTE_P | PTE_W,
+	0x325000 | PTE_P | PTE_W,
+	0x326000 | PTE_P | PTE_W,
+	0x327000 | PTE_P | PTE_W,
+	0x328000 | PTE_P | PTE_W,
+	0x329000 | PTE_P | PTE_W,
+	0x32a000 | PTE_P | PTE_W,
+	0x32b000 | PTE_P | PTE_W,
+	0x32c000 | PTE_P | PTE_W,
+	0x32d000 | PTE_P | PTE_W,
+	0x32e000 | PTE_P | PTE_W,
+	0x32f000 | PTE_P | PTE_W,
+	0x330000 | PTE_P | PTE_W,
+	0x331000 | PTE_P | PTE_W,
+	0x332000 | PTE_P | PTE_W,
+	0x333000 | PTE_P | PTE_W,
+	0x334000 | PTE_P | PTE_W,
+	0x335000 | PTE_P | PTE_W,
+	0x336000 | PTE_P | PTE_W,
+	0x337000 | PTE_P | PTE_W,
+	0x338000 | PTE_P | PTE_W,
+	0x339000 | PTE_P | PTE_W,
+	0x33a000 | PTE_P | PTE_W,
+	0x33b000 | PTE_P | PTE_W,
+	0x33c000 | PTE_P | PTE_W,
+	0x33d000 | PTE_P | PTE_W,
+	0x33e000 | PTE_P | PTE_W,
+	0x33f000 | PTE_P | PTE_W,
+	0x340000 | PTE_P | PTE_W,
+	0x341000 | PTE_P | PTE_W,
+	0x342000 | PTE_P | PTE_W,
+	0x343000 | PTE_P | PTE_W,
+	0x344000 | PTE_P | PTE_W,
+	0x345000 | PTE_P | PTE_W,
+	0x346000 | PTE_P | PTE_W,
+	0x347000 | PTE_P | PTE_W,
+	0x348000 | PTE_P | PTE_W,
+	0x349000 | PTE_P | PTE_W,
+	0x34a000 | PTE_P | PTE_W,
+	0x34b000 | PTE_P | PTE_W,
+	0x34c000 | PTE_P | PTE_W,
+	0x34d000 | PTE_P | PTE_W,
+	0x34e000 | PTE_P | PTE_W,
+	0x34f000 | PTE_P | PTE_W,
+	0x350000 | PTE_P | PTE_W,
+	0x351000 | PTE_P | PTE_W,
+	0x352000 | PTE_P | PTE_W,
+	0x353000 | PTE_P | PTE_W,
+	0x354000 | PTE_P | PTE_W,
+	0x355000 | PTE_P | PTE_W,
+	0x356000 | PTE_P | PTE_W,
+	0x357000 | PTE_P | PTE_W,
+	0x358000 | PTE_P | PTE_W,
+	0x359000 | PTE_P | PTE_W,
+	0x35a000 | PTE_P | PTE_W,
+	0x35b000 | PTE_P | PTE_W,
+	0x35c000 | PTE_P | PTE_W,
+	0x35d000 | PTE_P | PTE_W,
+	0x35e000 | PTE_P | PTE_W,
+	0x35f000 | PTE_P | PTE_W,
+	0x360000 | PTE_P | PTE_W,
+	0x361000 | PTE_P | PTE_W,
+	0x362000 | PTE_P | PTE_W,
+	0x363000 | PTE_P | PTE_W,
+	0x364000 | PTE_P | PTE_W,
+	0x365000 | PTE_P | PTE_W,
+	0x366000 | PTE_P | PTE_W,
+	0x367000 | PTE_P | PTE_W,
+	0x368000 | PTE_P | PTE_W,
+	0x369000 | PTE_P | PTE_W,
+	0x36a000 | PTE_P | PTE_W,
+	0x36b000 | PTE_P | PTE_W,
+	0x36c000 | PTE_P | PTE_W,
+	0x36d000 | PTE_P | PTE_W,
+	0x36e000 | PTE_P | PTE_W,
+	0x36f000 | PTE_P | PTE_W,
+	0x370000 | PTE_P | PTE_W,
+	0x371000 | PTE_P | PTE_W,
+	0x372000 | PTE_P | PTE_W,
+	0x373000 | PTE_P | PTE_W,
+	0x374000 | PTE_P | PTE_W,
+	0x375000 | PTE_P | PTE_W,
+	0x376000 | PTE_P | PTE_W,
+	0x377000 | PTE_P | PTE_W,
+	0x378000 | PTE_P | PTE_W,
+	0x379000 | PTE_P | PTE_W,
+	0x37a000 | PTE_P | PTE_W,
+	0x37b000 | PTE_P | PTE_W,
+	0x37c000 | PTE_P | PTE_W,
+	0x37d000 | PTE_P | PTE_W,
+	0x37e000 | PTE_P | PTE_W,
+	0x37f000 | PTE_P | PTE_W,
+	0x380000 | PTE_P | PTE_W,
+	0x381000 | PTE_P | PTE_W,
+	0x382000 | PTE_P | PTE_W,
+	0x383000 | PTE_P | PTE_W,
+	0x384000 | PTE_P | PTE_W,
+	0x385000 | PTE_P | PTE_W,
+	0x386000 | PTE_P | PTE_W,
+	0x387000 | PTE_P | PTE_W,
+	0x388000 | PTE_P | PTE_W,
+	0x389000 | PTE_P | PTE_W,
+	0x38a000 | PTE_P | PTE_W,
+	0x38b000 | PTE_P | PTE_W,
+	0x38c000 | PTE_P | PTE_W,
+	0x38d000 | PTE_P | PTE_W,
+	0x38e000 | PTE_P | PTE_W,
+	0x38f000 | PTE_P | PTE_W,
+	0x390000 | PTE_P | PTE_W,
+	0x391000 | PTE_P | PTE_W,
+	0x392000 | PTE_P | PTE_W,
+	0x393000 | PTE_P | PTE_W,
+	0x394000 | PTE_P | PTE_W,
+	0x395000 | PTE_P | PTE_W,
+	0x396000 | PTE_P | PTE_W,
+	0x397000 | PTE_P | PTE_W,
+	0x398000 | PTE_P | PTE_W,
+	0x399000 | PTE_P | PTE_W,
+	0x39a000 | PTE_P | PTE_W,
+	0x39b000 | PTE_P | PTE_W,
+	0x39c000 | PTE_P | PTE_W,
+	0x39d000 | PTE_P | PTE_W,
+	0x39e000 | PTE_P | PTE_W,
+	0x39f000 | PTE_P | PTE_W,
+	0x3a0000 | PTE_P | PTE_W,
+	0x3a1000 | PTE_P | PTE_W,
+	0x3a2000 | PTE_P | PTE_W,
+	0x3a3000 | PTE_P | PTE_W,
+	0x3a4000 | PTE_P | PTE_W,
+	0x3a5000 | PTE_P | PTE_W,
+	0x3a6000 | PTE_P | PTE_W,
+	0x3a7000 | PTE_P | PTE_W,
+	0x3a8000 | PTE_P | PTE_W,
+	0x3a9000 | PTE_P | PTE_W,
+	0x3aa000 | PTE_P | PTE_W,
+	0x3ab000 | PTE_P | PTE_W,
+	0x3ac000 | PTE_P | PTE_W,
+	0x3ad000 | PTE_P | PTE_W,
+	0x3ae000 | PTE_P | PTE_W,
+	0x3af000 | PTE_P | PTE_W,
+	0x3b0000 | PTE_P | PTE_W,
+	0x3b1000 | PTE_P | PTE_W,
+	0x3b2000 | PTE_P | PTE_W,
+	0x3b3000 | PTE_P | PTE_W,
+	0x3b4000 | PTE_P | PTE_W,
+	0x3b5000 | PTE_P | PTE_W,
+	0x3b6000 | PTE_P | PTE_W,
+	0x3b7000 | PTE_P | PTE_W,
+	0x3b8000 | PTE_P | PTE_W,
+	0x3b9000 | PTE_P | PTE_W,
+	0x3ba000 | PTE_P | PTE_W,
+	0x3bb000 | PTE_P | PTE_W,
+	0x3bc000 | PTE_P | PTE_W,
+	0x3bd000 | PTE_P | PTE_W,
+	0x3be000 | PTE_P | PTE_W,
+	0x3bf000 | PTE_P | PTE_W,
+	0x3c0000 | PTE_P | PTE_W,
+	0x3c1000 | PTE_P | PTE_W,
+	0x3c2000 | PTE_P | PTE_W,
+	0x3c3000 | PTE_P | PTE_W,
+	0x3c4000 | PTE_P | PTE_W,
+	0x3c5000 | PTE_P | PTE_W,
+	0x3c6000 | PTE_P | PTE_W,
+	0x3c7000 | PTE_P | PTE_W,
+	0x3c8000 | PTE_P | PTE_W,
+	0x3c9000 | PTE_P | PTE_W,
+	0x3ca000 | PTE_P | PTE_W,
+	0x3cb000 | PTE_P | PTE_W,
+	0x3cc000 | PTE_P | PTE_W,
+	0x3cd000 | PTE_P | PTE_W,
+	0x3ce000 | PTE_P | PTE_W,
+	0x3cf000 | PTE_P | PTE_W,
+	0x3d0000 | PTE_P | PTE_W,
+	0x3d1000 | PTE_P | PTE_W,
+	0x3d2000 | PTE_P | PTE_W,
+	0x3d3000 | PTE_P | PTE_W,
+	0x3d4000 | PTE_P | PTE_W,
+	0x3d5000 | PTE_P | PTE_W,
+	0x3d6000 | PTE_P | PTE_W,
+	0x3d7000 | PTE_P | PTE_W,
+	0x3d8000 | PTE_P | PTE_W,
+	0x3d9000 | PTE_P | PTE_W,
+	0x3da000 | PTE_P | PTE_W,
+	0x3db000 | PTE_P | PTE_W,
+	0x3dc000 | PTE_P | PTE_W,
+	0x3dd000 | PTE_P | PTE_W,
+	0x3de000 | PTE_P | PTE_W,
+	0x3df000 | PTE_P | PTE_W,
+	0x3e0000 | PTE_P | PTE_W,
+	0x3e1000 | PTE_P | PTE_W,
+	0x3e2000 | PTE_P | PTE_W,
+	0x3e3000 | PTE_P | PTE_W,
+	0x3e4000 | PTE_P | PTE_W,
+	0x3e5000 | PTE_P | PTE_W,
+	0x3e6000 | PTE_P | PTE_W,
+	0x3e7000 | PTE_P | PTE_W,
+	0x3e8000 | PTE_P | PTE_W,
+	0x3e9000 | PTE_P | PTE_W,
+	0x3ea000 | PTE_P | PTE_W,
+	0x3eb000 | PTE_P | PTE_W,
+	0x3ec000 | PTE_P | PTE_W,
+	0x3ed000 | PTE_P | PTE_W,
+	0x3ee000 | PTE_P | PTE_W,
+	0x3ef000 | PTE_P | PTE_W,
+	0x3f0000 | PTE_P | PTE_W,
+	0x3f1000 | PTE_P | PTE_W,
+	0x3f2000 | PTE_P | PTE_W,
+	0x3f3000 | PTE_P | PTE_W,
+	0x3f4000 | PTE_P | PTE_W,
+	0x3f5000 | PTE_P | PTE_W,
+	0x3f6000 | PTE_P | PTE_W,
+	0x3f7000 | PTE_P | PTE_W,
+	0x3f8000 | PTE_P | PTE_W,
+	0x3f9000 | PTE_P | PTE_W,
+	0x3fa000 | PTE_P | PTE_W,
+	0x3fb000 | PTE_P | PTE_W,
+	0x3fc000 | PTE_P | PTE_W,
+	0x3fd000 | PTE_P | PTE_W,
+	0x3fe000 | PTE_P | PTE_W,
+	0x3ff000 | PTE_P | PTE_W,
+};
+
diff --git a/kern.old/env.c b/kern.old/env.c
new file mode 100755
index 0000000..aad1f04
--- /dev/null
+++ b/kern.old/env.c
@@ -0,0 +1,703 @@
+/* See COPYRIGHT for copyright information. */
+
+#include <inc/x86.h>
+#include <inc/mmu.h>
+#include <inc/error.h>
+#include <inc/string.h>
+#include <inc/assert.h>
+#include <inc/elf.h>
+
+#include <kern/env.h>
+#include <kern/pmap.h>
+#include <kern/trap.h>
+#include <kern/monitor.h>
+#include <kern/sched.h>
+#include <kern/cpu.h>
+#include <kern/spinlock.h>
+
+struct Env *envs = NULL;		// All environments
+static struct Env *env_free_list;	// Free environment list
+// (linked by Env->env_link)
+
+#define ENVGENSHIFT	12		// >= LOGNENV
+
+// Global descriptor table.
+//
+// Set up global descriptor table (GDT) with separate segments for
+// kernel mode and user mode.  Segments serve many purposes on the x86.
+// We don't use any of their memory-mapping capabilities, but we need
+// them to switch privilege levels. 
+//
+// The kernel and user segments are identical except for the DPL.
+// To load the SS register, the CPL must equal the DPL.  Thus,
+// we must duplicate the segments for the user and the kernel.
+//
+// In particular, the last argument to the SEG macro used in the
+// definition of gdt specifies the Descriptor Privilege Level (DPL)
+// of that descriptor: 0 for kernel and 3 for user.
+//
+struct Segdesc gdt[NCPU + 5] =
+{
+    // 0x0 - unused (always faults -- for trapping NULL far pointers)
+    SEG_NULL,
+
+    // 0x8 - kernel code segment
+    [GD_KT >> 3] = SEG(STA_X | STA_R, 0x0, 0xffffffff, 0),
+
+    // 0x10 - kernel data segment
+    [GD_KD >> 3] = SEG(STA_W, 0x0, 0xffffffff, 0),
+
+    // 0x18 - user code segment
+    [GD_UT >> 3] = SEG(STA_X | STA_R, 0x0, 0xffffffff, 3),
+
+    // 0x20 - user data segment
+    [GD_UD >> 3] = SEG(STA_W, 0x0, 0xffffffff, 3),
+
+    // Per-CPU TSS descriptors (starting from GD_TSS0) are initialized
+    // in trap_init_percpu()
+    [GD_TSS0 >> 3] = SEG_NULL
+};
+
+struct Pseudodesc gdt_pd = {
+    sizeof(gdt) - 1, (unsigned long) gdt
+};
+
+//
+// Converts an envid to an env pointer.
+// If checkperm is set, the specified environment must be either the
+// current environment or an immediate child of the current environment.
+//
+// RETURNS
+//   0 on success, -E_BAD_ENV on error.
+//   On success, sets *env_store to the environment.
+//   On error, sets *env_store to NULL.
+//
+    int
+envid2env(envid_t envid, struct Env **env_store, bool checkperm)
+{
+    struct Env *e;
+
+    // If envid is zero, return the current environment.
+    if (envid == 0) {
+	*env_store = curenv;
+	return 0;
+    }
+
+    // Look up the Env structure via the index part of the envid,
+    // then check the env_id field in that struct Env
+    // to ensure that the envid is not stale
+    // (i.e., does not refer to a _previous_ environment
+    // that used the same slot in the envs[] array).
+    e = &envs[ENVX(envid)];
+    lock(&e->lock);
+    if (e->env_status == ENV_FREE || e->env_id != envid) {
+	*env_store = 0;
+	unlock(&e->lock);
+	return -E_BAD_ENV;
+    }
+
+    // Check that the calling environment has legitimate permission
+    // to manipulate the specified environment.
+    // If checkperm is set, the specified environment
+    // must be either the current environment
+    // or an immediate child of the current environment.
+    if (checkperm && e != curenv && e->env_parent_id != curenv->env_id) {
+	*env_store = 0;
+	unlock(&e->lock);
+	return -E_BAD_ENV;
+    }
+
+    *env_store = e;
+    return 0;
+}
+
+// Mark all environments in 'envs' as free, set their env_ids to 0,
+// and insert them into the env_free_list.
+// Make sure the environments are in the free list in the same order
+// they are in the envs array (i.e., so that the first call to
+// env_alloc() returns envs[0]).
+//
+    void
+env_init(void)
+{
+    // Set up envs array
+    // LAB 3: Your code here.
+    int i;
+    env_free_list = NULL;
+    for (i = NENV - 1; i >= 0; i--) {
+	envs[i].env_id = 0;
+	envs[i].env_link = env_free_list;
+	spin_initlock(&envs[i].lock);
+	env_free_list = &(envs[i]);
+    }
+
+    // Per-CPU part of the initialization
+    env_init_percpu();
+}
+
+// Load GDT and segment descriptors.
+    void
+env_init_percpu(void)
+{
+    lgdt(&gdt_pd);
+    // The kernel never uses GS or FS, so we leave those set to
+    // the user data segment.
+    asm volatile("movw %%ax,%%gs" : : "a" (GD_UD|3));
+    asm volatile("movw %%ax,%%fs" : : "a" (GD_UD|3));
+    // The kernel does use ES, DS, and SS.  We'll change between
+    // the kernel and user data segments as needed.
+    asm volatile("movw %%ax,%%es" : : "a" (GD_KD));
+    asm volatile("movw %%ax,%%ds" : : "a" (GD_KD));
+    asm volatile("movw %%ax,%%ss" : : "a" (GD_KD));
+    // Load the kernel text segment into CS.
+    asm volatile("ljmp %0,$1f\n 1:\n" : : "i" (GD_KT));
+    // For good measure, clear the local descriptor table (LDT),
+    // since we don't use it.
+    lldt(0);
+}
+
+
+
+    static void
+boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
+{
+    int i;
+    lock(&page_lock);
+    for (i = 0; i < size; i += PGSIZE) {
+	pte_t *pte = pgdir_walk(pgdir, (void*)(va + i), 1);
+	if (pte) *pte = (pa + i) | perm | PTE_P;
+    }
+    unlock(&page_lock);
+}
+
+
+//
+// Initialize the kernel virtual memory layout for environment e.
+// Allocate a page directory, set e->env_pgdir accordingly,
+// and initialize the kernel portion of the new environment's address space.
+// Do NOT (yet) map anything into the user portion
+// of the environment's virtual address space.
+//
+// Returns 0 on success, < 0 on error.  Errors include:
+//	-E_NO_MEM if page directory or table could not be allocated.
+//
+    static int
+env_setup_vm(struct Env *e)
+{
+    int i;
+    struct PageInfo *p = NULL;
+
+    // Allocate a page for the page directory
+    lock(&page_lock);
+    if (!(p = page_alloc(ALLOC_ZERO))) {
+	unlock(&page_lock);
+	return -E_NO_MEM;
+    }
+    unlock(&page_lock);
+
+    // Now, set e->env_pgdir and initialize the page directory.
+    //
+    // Hint:
+    //    - The VA space of all envs is identical above UTOP
+    //	(except at UVPT, which we've set below).
+    //	See inc/memlayout.h for permissions and layout.
+    //	Can you use kern_pgdir as a template?  Hint: Yes.
+    //	(Make sure you got the permissions right in Lab 2.)
+    //    - The initial VA below UTOP is empty.
+    //    - You do not need to make any more calls to page_alloc.
+    //    - Note: In general, pp_ref is not maintained for
+    //	physical pages mapped only above UTOP, but env_pgdir
+    //	is an exception -- you need to increment env_pgdir's
+    //	pp_ref for env_free to work correctly.
+    //    - The functions in kern/pmap.h are handy.
+
+    // LAB 3: Your code here.
+    e->env_pgdir = (pde_t*)page2kva(p);
+    memcpy(e->env_pgdir, kern_pgdir, PGSIZE);
+    memset(e->env_pgdir, 0, PDX(UTOP) * sizeof(pte_t));
+    p->pp_ref++;
+
+
+    // UVPT maps the env's own page table read-only.
+    // Permissions: kernel R, user R
+    e->env_pgdir[PDX(UVPT)] = PADDR(e->env_pgdir) | PTE_P | PTE_U;
+
+    return 0;
+}
+
+//
+// Allocates and initializes a new environment.
+// On success, the new environment is stored in *newenv_store.
+//
+// Returns 0 on success, < 0 on failure.  Errors include:
+//	-E_NO_FREE_ENV if all NENVS environments are allocated
+//	-E_NO_MEM on memory exhaustion
+//
+    int
+env_alloc(struct Env **newenv_store, envid_t parent_id)
+{
+<<<<<<< HEAD
+	int32_t generation;
+	int r;
+	struct Env *e;
+
+	if (!(e = env_free_list))
+		return -E_NO_FREE_ENV;
+
+	// Allocate and set up the page directory for this environment.
+	if ((r = env_setup_vm(e)) < 0)
+		return r;
+
+	// Generate an env_id for this environment.
+	generation = (e->env_id + (1 << ENVGENSHIFT)) & ~(NENV - 1);
+	if (generation <= 0)	// Don't create a negative env_id.
+		generation = 1 << ENVGENSHIFT;
+	e->env_id = generation | (e - envs);
+
+	// Set the basic status variables.
+	e->env_parent_id = parent_id;
+	e->env_type = ENV_TYPE_USER;
+	e->env_status = ENV_RUNNABLE;
+	e->env_runs = 0;
+
+	// Clear out all the saved register state,
+	// to prevent the register values
+	// of a prior environment inhabiting this Env structure
+	// from "leaking" into our new environment.
+	memset(&e->env_tf, 0, sizeof(e->env_tf));
+
+	// Set up appropriate initial values for the segment registers.
+	// GD_UD is the user data segment selector in the GDT, and
+	// GD_UT is the user text segment selector (see inc/memlayout.h).
+	// The low 2 bits of each segment register contains the
+	// Requestor Privilege Level (RPL); 3 means user mode.  When
+	// we switch privilege levels, the hardware does various
+	// checks involving the RPL and the Descriptor Privilege Level
+	// (DPL) stored in the descriptors themselves.
+	e->env_tf.tf_ds = GD_UD | 3;
+	e->env_tf.tf_es = GD_UD | 3;
+	e->env_tf.tf_ss = GD_UD | 3;
+	e->env_tf.tf_esp = USTACKTOP;
+	e->env_tf.tf_cs = GD_UT | 3;
+	// You will set e->env_tf.tf_eip later.
+
+	// Enable interrupts while in user mode.
+	// LAB 4: Your code here.
+
+	// Clear the page fault handler until user installs one.
+	e->env_pgfault_upcall = 0;
+
+	// Also clear the IPC receiving flag.
+	e->env_ipc_recving = 0;
+
+	// commit the allocation
+	env_free_list = e->env_link;
+	*newenv_store = e;
+
+	// cprintf("[%08x] new env %08x\n", curenv ? curenv->env_id : 0, e->env_id);
+	return 0;
+=======
+    int32_t generation;
+    int r;
+    struct Env *e;
+
+    lock(&env_lock);
+    if (!(e = env_free_list)) {
+	unlock(&env_lock);
+	return -E_NO_FREE_ENV;
+    }
+    lock(&e->lock);
+
+    // Allocate and set up the page directory for this environment.
+    if ((r = env_setup_vm(e)) < 0) {
+	unlock(&env_lock);
+	unlock(&e->lock);
+	return r;
+    }
+
+    // Generate an env_id for this environment.
+    generation = (e->env_id + (1 << ENVGENSHIFT)) & ~(NENV - 1);
+    if (generation <= 0)	// Don't create a negative env_id.
+	generation = 1 << ENVGENSHIFT;
+    e->env_id = generation | (e - envs);
+
+    // Set the basic status variables.
+    e->env_parent_id = parent_id;
+    e->env_type = ENV_TYPE_USER;
+    e->env_status = ENV_RUNNABLE;
+    e->env_runs = 0;
+    e->env_in_kernel = 0;
+
+    // Clear out all the saved register state,
+    // to prevent the register values
+    // of a prior environment inhabiting this Env structure
+    // from "leaking" into our new environment.
+    memset(&e->env_tf, 0, sizeof(e->env_tf));
+
+    // Set up appropriate initial values for the segment registers.
+    // GD_UD is the user data segment selector in the GDT, and
+    // GD_UT is the user text segment selector (see inc/memlayout.h).
+    // The low 2 bits of each segment register contains the
+    // Requestor Privilege Level (RPL); 3 means user mode.  When
+    // we switch privilege levels, the hardware does various
+    // checks involving the RPL and the Descriptor Privilege Level
+    // (DPL) stored in the descriptors themselves.
+    e->env_tf.tf_ds = GD_UD | 3;
+    e->env_tf.tf_es = GD_UD | 3;
+    e->env_tf.tf_ss = GD_UD | 3;
+    e->env_tf.tf_esp = USTACKTOP;
+    e->env_tf.tf_cs = GD_UT | 3;
+    // You will set e->env_tf.tf_eip later.
+
+    // Enable interrupts while in user mode.
+    // LAB 4: Your code here.
+    e->env_tf.tf_eflags |= FL_IF;
+
+
+    // Clear the page fault handler until user installs one.
+    e->env_pgfault_upcall = 0;
+
+    // Also clear the IPC receiving flag.
+    e->env_ipc_recving = 0;
+
+    // commit the allocation
+    env_free_list = e->env_link;
+    *newenv_store = e;
+
+    unlock(&env_lock);
+
+    cprintf("[%08x] new env %08x\n", curenv ? curenv->env_id : 0, e->env_id);
+    return 0;
+>>>>>>> lab4
+}
+
+//
+// Allocate len bytes of physical memory for environment env,
+// and map it at virtual address va in the environment's address space.
+// Does not zero or otherwise initialize the mapped pages in any way.
+// Pages should be writable by user and kernel.
+// Panic if any allocation attempt fails.
+//
+    static void
+region_alloc(struct Env *e, void *va, size_t len)
+{
+    // LAB 3: Your code here.
+    // (But only if you need it for load_icode.)
+    //
+    // Hint: It is easier to use region_alloc if the caller can pass
+    //   'va' and 'len' values that are not page-aligned.
+    //   You should round va down, and round (va + len) up.
+    //   (Watch out for corner-cases!)
+    int l = 0, va_ = (uintptr_t)va;
+    struct PageInfo *p;
+    va = (void*)ROUNDDOWN(va_, PGSIZE);
+    len = ROUNDUP(va_ + len, PGSIZE) - (uintptr_t)va;
+    lock(&page_lock);
+    for (; l < len; l += PGSIZE) {
+	p = page_alloc(0);
+	if (!p) panic("Panic: region_alloc()\n");
+	if (page_insert(e->env_pgdir, p, va + l, PTE_U | PTE_W))
+	    panic("Panic: region_alloc()\n");
+    }
+    unlock(&page_lock);
+}
+
+//
+// Set up the initial program binary, stack, and processor flags
+// for a user process.
+// This function is ONLY called during kernel initialization,
+// before running the first user-mode environment.
+//
+// This function loads all loadable segments from the ELF binary image
+// into the environment's user memory, starting at the appropriate
+// virtual addresses indicated in the ELF program header.
+// At the same time it clears to zero any portions of these segments
+// that are marked in the program header as being mapped
+// but not actually present in the ELF file - i.e., the program's bss section.
+//
+// All this is very similar to what our boot loader does, except the boot
+// loader also needs to read the code from disk.  Take a look at
+// boot/main.c to get ideas.
+//
+// Finally, this function maps one page for the program's initial stack.
+//
+// load_icode panics if it encounters problems.
+//  - How might load_icode fail?  What might be wrong with the given input?
+//
+    static void
+load_icode(struct Env *e, uint8_t *binary)
+{
+    // Hints:
+    //  Load each program segment into virtual memory
+    //  at the address specified in the ELF section header.
+    //  You should only load segments with ph->p_type == ELF_PROG_LOAD.
+    //  Each segment's virtual address can be found in ph->p_va
+    //  and its size in memory can be found in ph->p_memsz.
+    //  The ph->p_filesz bytes from the ELF binary, starting at
+    //  'binary + ph->p_offset', should be copied to virtual address
+    //  ph->p_va.  Any remaining memory bytes should be cleared to zero.
+    //  (The ELF header should have ph->p_filesz <= ph->p_memsz.)
+    //  Use functions from the previous lab to allocate and map pages.
+    //
+    //  All page protection bits should be user read/write for now.
+    //  ELF segments are not necessarily page-aligned, but you can
+    //  assume for this function that no two segments will touch
+    //  the same virtual page.
+    //
+    //  You may find a function like region_alloc useful.
+    //
+    //  Loading the segments is much simpler if you can move data
+    //  directly into the virtual addresses stored in the ELF binary.
+    //  So which page directory should be in force during
+    //  this function?
+    //
+    //  You must also do something with the program's entry point,
+    //  to make sure that the environment starts executing there.
+    //  What?  (See env_run() and env_pop_tf() below.)
+
+    // LAB 3: Your code here.
+    struct Elf *elf = (struct Elf*)binary;
+    struct Proghdr *ph, *eph;
+    struct PageInfo *pp;
+    unsigned i, va, sz, delta;
+
+    if (elf->e_magic != ELF_MAGIC) 
+	panic("Panic: load_icode() ELF_MAGIC\n");
+    ph = (struct Proghdr*)(binary + elf->e_phoff);
+    eph = ph + elf->e_phnum;
+    lcr3(PADDR(e->env_pgdir));
+    for (; ph < eph; ph++) {
+	if (ph->p_type != ELF_PROG_LOAD) continue;
+	region_alloc(e, (void*)ph->p_va, ph->p_memsz);
+	memset((void*)ph->p_va, 0, ph->p_memsz);
+	memcpy((void*)ph->p_va, binary + ph->p_offset, ph->p_filesz); 
+    }
+    lcr3(PADDR(kern_pgdir));
+    e->env_tf.tf_eip = elf->e_entry;
+
+    // Now map one page for the program's initial stack
+    // at virtual address USTACKTOP - PGSIZE.
+
+    // LAB 3: Your code here.
+    region_alloc(e, (void*)(USTACKTOP - PGSIZE), PGSIZE);
+}
+
+//
+// Allocates a new env with env_alloc, loads the named elf
+// binary into it with load_icode, and sets its env_type.
+// This function is ONLY called during kernel initialization,
+// before running the first user-mode environment.
+// The new env's parent ID is set to 0.
+//
+    void
+env_create(uint8_t *binary, enum EnvType type)
+{
+<<<<<<< HEAD
+	// LAB 3: Your code here.
+
+	// If this is the file server (type == ENV_TYPE_FS) give it I/O privileges.
+	// LAB 5: Your code here.
+=======
+    // LAB 3: Your code here.
+    struct Env *e;
+    env_alloc(&e, 0);
+    load_icode(e, binary);
+    e->env_type = type;
+    unlock(&e->lock);
+>>>>>>> lab4
+}
+
+//
+// Frees env e and all memory it uses.
+//
+    void
+env_free(struct Env *e)
+{
+<<<<<<< HEAD
+	pte_t *pt;
+	uint32_t pdeno, pteno;
+	physaddr_t pa;
+
+	// If freeing the current environment, switch to kern_pgdir
+	// before freeing the page directory, just in case the page
+	// gets reused.
+	if (e == curenv)
+		lcr3(PADDR(kern_pgdir));
+
+	// Note the environment's demise.
+	// cprintf("[%08x] free env %08x\n", curenv ? curenv->env_id : 0, e->env_id);
+
+	// Flush all mapped pages in the user portion of the address space
+	static_assert(UTOP % PTSIZE == 0);
+	for (pdeno = 0; pdeno < PDX(UTOP); pdeno++) {
+
+		// only look at mapped page tables
+		if (!(e->env_pgdir[pdeno] & PTE_P))
+			continue;
+
+		// find the pa and va of the page table
+		pa = PTE_ADDR(e->env_pgdir[pdeno]);
+		pt = (pte_t*) KADDR(pa);
+
+		// unmap all PTEs in this page table
+		for (pteno = 0; pteno <= PTX(~0); pteno++) {
+			if (pt[pteno] & PTE_P)
+				page_remove(e->env_pgdir, PGADDR(pdeno, pteno, 0));
+		}
+
+		// free the page table itself
+		e->env_pgdir[pdeno] = 0;
+		page_decref(pa2page(pa));
+=======
+    pte_t *pt;
+    uint32_t pdeno, pteno;
+    physaddr_t pa;
+
+    // If freeing the current environment, switch to kern_pgdir
+    // before freeing the page directory, just in case the page
+    // gets reused.
+    if (e == curenv)
+	lcr3(PADDR(kern_pgdir));
+
+    // Note the environment's demise.
+    cprintf("[%08x] free env %08x\n", curenv ? curenv->env_id : 0, e->env_id);
+
+    // Flush all mapped pages in the user portion of the address space
+    static_assert(UTOP % PTSIZE == 0);
+    for (pdeno = 0; pdeno < PDX(UTOP); pdeno++) {
+
+	// only look at mapped page tables
+	if (!(e->env_pgdir[pdeno] & PTE_P))
+	    continue;
+
+	// find the pa and va of the page table
+	pa = PTE_ADDR(e->env_pgdir[pdeno]);
+	pt = (pte_t*) KADDR(pa);
+
+	// unmap all PTEs in this page table
+	for (pteno = 0; pteno <= PTX(~0); pteno++) {
+	    if (pt[pteno] & PTE_P) {
+		lock(&page_lock);
+		page_remove(e->env_pgdir, PGADDR(pdeno, pteno, 0));
+		unlock(&page_lock);
+	    }
+>>>>>>> lab4
+	}
+
+	// free the page table itself
+	e->env_pgdir[pdeno] = 0;
+	lock(&page_lock);
+	page_decref(pa2page(pa));
+	unlock(&page_lock);
+    }
+
+    // free the page directory
+    pa = PADDR(e->env_pgdir);
+    e->env_pgdir = 0;
+    lock(&page_lock);
+    page_decref(pa2page(pa));
+    unlock(&page_lock);
+
+    // return the environment to the free list
+    e->env_status = ENV_FREE;
+    lock(&env_lock);
+    e->env_link = env_free_list;
+    env_free_list = e;
+    unlock(&env_lock);
+}
+
+//
+// Frees environment e.
+// If e was the current env, then runs a new environment (and does not return
+// to the caller).
+//
+    void
+env_destroy(struct Env *e)
+{
+    // If e is currently running on other CPUs, we change its state to
+    // ENV_DYING. A zombie environment will be freed the next time
+    // it traps to the kernel.
+    if (e->env_status == ENV_RUNNING && curenv != e) {
+	e->env_status = ENV_DYING;
+	return;
+    }
+
+    env_free(e);
+
+    if (curenv == e) {
+	curenv = NULL;
+	unlock(&e->lock);
+	sched_yield();
+    }
+}
+
+
+//
+// Restores the register values in the Trapframe with the 'iret' instruction.
+// This exits the kernel and starts executing some environment's code.
+//
+// This function does not return.
+//
+    void
+env_pop_tf(struct Trapframe *tf)
+{
+    // Record the CPU we are running on for user-space debugging
+    curenv->env_cpunum = cpunum();
+    if ((curenv->env_tf.tf_cs & 3) == 3) {
+	curenv->env_in_kernel = 0;
+    }
+    unlock(&curenv->lock);
+
+    asm volatile(
+	    "\tmovl %0,%%esp\n"
+	    "\tpopal\n"
+	    "\tpopl %%es\n"
+	    "\tpopl %%ds\n"
+	    "\taddl $0x8,%%esp\n" /* skip tf_trapno and tf_errcode */
+	    "\tiret\n"
+	    : : "g" (tf) : "memory");
+    panic("iret failed");  /* mostly to placate the compiler */
+}
+
+//
+// Context switch from curenv to env e.
+// Note: if this is the first call to env_run, curenv is NULL.
+//
+// This function does not return.
+//
+    void
+env_run(struct Env *e)
+{
+    // Step 1: If this is a context switch (a new environment is running):
+    //	   1. Set the current environment (if any) back to
+    //	      ENV_RUNNABLE if it is ENV_RUNNING (think about
+    //	      what other states it can be in),
+    //	   2. Set 'curenv' to the new environment,
+    //	   3. Set its status to ENV_RUNNING,
+    //	   4. Update its 'env_runs' counter,
+    //	   5. Use lcr3() to switch to its address space.
+    // Step 2: Use env_pop_tf() to restore the environment's
+    //	   registers and drop into user mode in the
+    //	   environment.
+
+    // Hint: This function loads the new environment's state from
+    //	e->env_tf.  Go back through the code you wrote above
+    //	and make sure you have set the relevant parts of
+    //	e->env_tf to sensible values.
+
+    // LAB 3: Your code here.
+    if (curenv && e != curenv) {
+	lock(&curenv->lock);
+	if (curenv->env_status == ENV_RUNNING)
+	    curenv->env_status = ENV_RUNNABLE;
+	curenv->env_in_kernel = 0;
+	unlock(&curenv->lock);
+    }
+    curenv = e;
+    curenv->env_status = ENV_RUNNING;
+    curenv->env_runs++;
+    lcr3(PADDR(e->env_pgdir));
+
+    env_pop_tf(&e->env_tf);
+}
+
diff --git a/kern.old/env.h b/kern.old/env.h
new file mode 100755
index 0000000..286ece7
--- /dev/null
+++ b/kern.old/env.h
@@ -0,0 +1,36 @@
+/* See COPYRIGHT for copyright information. */
+
+#ifndef JOS_KERN_ENV_H
+#define JOS_KERN_ENV_H
+
+#include <inc/env.h>
+#include <kern/cpu.h>
+
+extern struct Env *envs;		// All environments
+#define curenv (thiscpu->cpu_env)		// Current environment
+extern struct Segdesc gdt[];
+
+void	env_init(void);
+void	env_init_percpu(void);
+int	env_alloc(struct Env **e, envid_t parent_id);
+void	env_free(struct Env *e);
+void	env_create(uint8_t *binary, enum EnvType type);
+void	env_destroy(struct Env *e);	// Does not return if e == curenv
+
+int	envid2env(envid_t envid, struct Env **env_store, bool checkperm);
+// The following two functions do not return
+void	env_run(struct Env *e) __attribute__((noreturn));
+void	env_pop_tf(struct Trapframe *tf) __attribute__((noreturn));
+
+// Without this extra macro, we couldn't pass macros like TEST to
+// ENV_CREATE because of the C pre-processor's argument prescan rule.
+#define ENV_PASTE3(x, y, z) x ## y ## z
+
+#define ENV_CREATE(x, type)						\
+	do {								\
+		extern uint8_t ENV_PASTE3(_binary_obj_, x, _start)[];	\
+		env_create(ENV_PASTE3(_binary_obj_, x, _start),		\
+			   type);					\
+	} while (0)
+
+#endif // !JOS_KERN_ENV_H
diff --git a/kern.old/init.c b/kern.old/init.c
new file mode 100755
index 0000000..e7e8f93
--- /dev/null
+++ b/kern.old/init.c
@@ -0,0 +1,180 @@
+/* See COPYRIGHT for copyright information. */
+
+#include <inc/stdio.h>
+#include <inc/string.h>
+#include <inc/assert.h>
+
+#include <kern/monitor.h>
+#include <kern/console.h>
+#include <kern/pmap.h>
+#include <kern/kclock.h>
+#include <kern/env.h>
+#include <kern/trap.h>
+#include <kern/sched.h>
+#include <kern/picirq.h>
+#include <kern/cpu.h>
+#include <kern/spinlock.h>
+
+static void boot_aps(void);
+
+    void
+i386_init(void)
+{
+    extern char edata[], end[];
+
+    // Before doing anything else, complete the ELF loading process.
+    // Clear the uninitialized global data (BSS) section of our program.
+    // This ensures that all static/global variables start out zero.
+    memset(edata, 0, end - edata);
+
+    // Initialize the console.
+    // Can't call cprintf until after we do this!
+    cons_init();
+
+    cprintf("6828 decimal is %o octal!\n", 6828);
+
+    // Lab 2 memory management initialization functions
+    mem_init();
+
+    // Lab 3 user environment initialization functions
+    env_init();
+    trap_init();
+
+    // Lab 4 multiprocessor initialization functions
+    mp_init();
+    lapic_init();
+
+    // Lab 4 multitasking initialization functions
+    pic_init();
+
+    // Acquire the big kernel lock before waking up APs
+    // Your code here:
+
+    //Challenge
+    spin_initlock(&page_lock);
+    spin_initlock(&console_lock);
+    spin_initlock(&env_lock);
+    spin_initlock(&monitor_lock);
+
+    // Starting non-boot CPUs
+    boot_aps();
+
+
+
+	// Start fs.
+	ENV_CREATE(fs_fs, ENV_TYPE_FS);
+
+#if defined(TEST)
+    // Don't touch -- used by grading script!
+    ENV_CREATE(TEST, ENV_TYPE_USER);
+#else
+	// Touch all you want.
+	ENV_CREATE(user_icode, ENV_TYPE_USER);
+#endif // TEST*
+
+	// Should not be necessary - drains keyboard because interrupt has given up.
+	kbd_intr();
+
+	// Schedule and run the first user environment!
+	sched_yield();
+}
+
+// While boot_aps is booting a given CPU, it communicates the per-core
+// stack pointer that should be loaded by mpentry.S to that CPU in
+// this variable.
+void *mpentry_kstack;
+
+// Start the non-boot (AP) processors.
+    static void
+boot_aps(void)
+{
+    extern unsigned char mpentry_start[], mpentry_end[];
+    void *code;
+    struct CpuInfo *c;
+
+    // Write entry code to unused memory at MPENTRY_PADDR
+    code = KADDR(MPENTRY_PADDR);
+    memmove(code, mpentry_start, mpentry_end - mpentry_start);
+
+    // Boot each AP one at a time
+    for (c = cpus; c < cpus + ncpu; c++) {
+	if (c == cpus + cpunum())  // We've started already.
+	    continue;
+
+	// Tell mpentry.S what stack to use 
+	mpentry_kstack = percpu_kstacks[c - cpus] + KSTKSIZE;
+	// Start the CPU at mpentry_start
+	lapic_startap(c->cpu_id, PADDR(code));
+	// Wait for the CPU to finish some basic setup in mp_main()
+	while(c->cpu_status != CPU_STARTED)
+	    ;
+    }
+}
+
+// Setup code for APs
+    void
+mp_main(void)
+{
+    // We are in high EIP now, safe to switch to kern_pgdir 
+    lcr3(PADDR(kern_pgdir));
+    cprintf("SMP: CPU %d starting\n", cpunum());
+
+    lapic_init();
+    env_init_percpu();
+    trap_init_percpu();
+    xchg(&thiscpu->cpu_status, CPU_STARTED); // tell boot_aps() we're up
+
+    // Now that we have finished some basic setup, call sched_yield()
+    // to start running processes on this CPU.  But make sure that
+    // only one CPU can enter the scheduler at a time!
+    //
+    // Your code here:
+    sched_yield();
+}
+
+/*
+ * Variable panicstr contains argument to first call to panic; used as flag
+ * to indicate that the kernel has already called panic.
+ */
+const char *panicstr;
+
+/*
+ * Panic is called on unresolvable fatal errors.
+ * It prints "panic: mesg", and then enters the kernel monitor.
+ */
+    void
+_panic(const char *file, int line, const char *fmt,...)
+{
+    va_list ap;
+
+    if (panicstr)
+	goto dead;
+    panicstr = fmt;
+
+    // Be extra sure that the machine is in as reasonable state
+    asm volatile("cli; cld");
+
+    va_start(ap, fmt);
+    cprintf("kernel panic on CPU %d at %s:%d: ", cpunum(), file, line);
+    vcprintf(fmt, ap);
+    cprintf("\n");
+    va_end(ap);
+
+dead:
+    /* break into the kernel monitor */
+    while (1)
+	monitor(NULL);
+}
+
+/* like panic, but don't */
+    void
+_warn(const char *file, int line, const char *fmt,...)
+{
+    va_list ap;
+
+    va_start(ap, fmt);
+    cprintf("kernel warning at %s:%d: ", file, line);
+    vcprintf(fmt, ap);
+    cprintf("\n");
+    va_end(ap);
+}
diff --git a/kern.old/kclock.c b/kern.old/kclock.c
new file mode 100755
index 0000000..08a87f2
--- /dev/null
+++ b/kern.old/kclock.c
@@ -0,0 +1,22 @@
+/* See COPYRIGHT for copyright information. */
+
+/* Support for reading the NVRAM from the real-time clock. */
+
+#include <inc/x86.h>
+
+#include <kern/kclock.h>
+
+
+unsigned
+mc146818_read(unsigned reg)
+{
+	outb(IO_RTC, reg);
+	return inb(IO_RTC+1);
+}
+
+void
+mc146818_write(unsigned reg, unsigned datum)
+{
+	outb(IO_RTC, reg);
+	outb(IO_RTC+1, datum);
+}
diff --git a/kern.old/kclock.h b/kern.old/kclock.h
new file mode 100755
index 0000000..e409a81
--- /dev/null
+++ b/kern.old/kclock.h
@@ -0,0 +1,29 @@
+/* See COPYRIGHT for copyright information. */
+
+#ifndef JOS_KERN_KCLOCK_H
+#define JOS_KERN_KCLOCK_H
+#ifndef JOS_KERNEL
+# error "This is a JOS kernel header; user programs should not #include it"
+#endif
+
+#define	IO_RTC		0x070		/* RTC port */
+
+#define	MC_NVRAM_START	0xe	/* start of NVRAM: offset 14 */
+#define	MC_NVRAM_SIZE	50	/* 50 bytes of NVRAM */
+
+/* NVRAM bytes 7 & 8: base memory size */
+#define NVRAM_BASELO	(MC_NVRAM_START + 7)	/* low byte; RTC off. 0x15 */
+#define NVRAM_BASEHI	(MC_NVRAM_START + 8)	/* high byte; RTC off. 0x16 */
+
+/* NVRAM bytes 9 & 10: extended memory size (between 1MB and 16MB) */
+#define NVRAM_EXTLO	(MC_NVRAM_START + 9)	/* low byte; RTC off. 0x17 */
+#define NVRAM_EXTHI	(MC_NVRAM_START + 10)	/* high byte; RTC off. 0x18 */
+
+/* NVRAM bytes 38 and 39: extended memory size (between 16MB and 4G) */
+#define NVRAM_EXT16LO	(MC_NVRAM_START + 38)	/* low byte; RTC off. 0x34 */
+#define NVRAM_EXT16HI	(MC_NVRAM_START + 39)	/* high byte; RTC off. 0x35 */
+
+unsigned mc146818_read(unsigned reg);
+void mc146818_write(unsigned reg, unsigned datum);
+
+#endif	// !JOS_KERN_KCLOCK_H
diff --git a/kern.old/kdebug.c b/kern.old/kdebug.c
new file mode 100755
index 0000000..b721c0b
--- /dev/null
+++ b/kern.old/kdebug.c
@@ -0,0 +1,238 @@
+#include <inc/stab.h>
+#include <inc/string.h>
+#include <inc/memlayout.h>
+#include <inc/assert.h>
+
+#include <kern/kdebug.h>
+#include <kern/pmap.h>
+#include <kern/env.h>
+
+extern const struct Stab __STAB_BEGIN__[];	// Beginning of stabs table
+extern const struct Stab __STAB_END__[];	// End of stabs table
+extern const char __STABSTR_BEGIN__[];		// Beginning of string table
+extern const char __STABSTR_END__[];		// End of string table
+
+struct UserStabData {
+    const struct Stab *stabs;
+    const struct Stab *stab_end;
+    const char *stabstr;
+    const char *stabstr_end;
+};
+
+
+// stab_binsearch(stabs, region_left, region_right, type, addr)
+//
+//	Some stab types are arranged in increasing order by instruction
+//	address.  For example, N_FUN stabs (stab entries with n_type ==
+//	N_FUN), which mark functions, and N_SO stabs, which mark source files.
+//
+//	Given an instruction address, this function finds the single stab
+//	entry of type 'type' that contains that address.
+//
+//	The search takes place within the range [*region_left, *region_right].
+//	Thus, to search an entire set of N stabs, you might do:
+//
+//		left = 0;
+//		right = N - 1;     /* rightmost stab */
+//		stab_binsearch(stabs, &left, &right, type, addr);
+//
+//	The search modifies *region_left and *region_right to bracket the
+//	'addr'.  *region_left points to the matching stab that contains
+//	'addr', and *region_right points just before the next stab.  If
+//	*region_left > *region_right, then 'addr' is not contained in any
+//	matching stab.
+//
+//	For example, given these N_SO stabs:
+//		Index  Type   Address
+//		0      SO     f0100000
+//		13     SO     f0100040
+//		117    SO     f0100176
+//		118    SO     f0100178
+//		555    SO     f0100652
+//		556    SO     f0100654
+//		657    SO     f0100849
+//	this code:
+//		left = 0, right = 657;
+//		stab_binsearch(stabs, &left, &right, N_SO, 0xf0100184);
+//	will exit setting left = 118, right = 554.
+//
+    static void
+stab_binsearch(const struct Stab *stabs, int *region_left, int *region_right,
+	int type, uintptr_t addr)
+{
+    int l = *region_left, r = *region_right, any_matches = 0;
+
+    while (l <= r) {
+	int true_m = (l + r) / 2, m = true_m;
+
+	// search for earliest stab with right type
+	while (m >= l && stabs[m].n_type != type)
+	    m--;
+	if (m < l) {	// no match in [l, m]
+	    l = true_m + 1;
+	    continue;
+	}
+
+	// actual binary search
+	any_matches = 1;
+	if (stabs[m].n_value < addr) {
+	    *region_left = m;
+	    l = true_m + 1;
+	} else if (stabs[m].n_value > addr) {
+	    *region_right = m - 1;
+	    r = m - 1;
+	} else {
+	    // exact match for 'addr', but continue loop to find
+	    // *region_right
+	    *region_left = m;
+	    l = m;
+	    addr++;
+	}
+    }
+
+    if (!any_matches)
+	*region_right = *region_left - 1;
+    else {
+	// find rightmost region containing 'addr'
+	for (l = *region_right;
+		l > *region_left && stabs[l].n_type != type;
+		l--)
+	    /* do nothing */;
+	*region_left = l;
+    }
+}
+
+
+// debuginfo_eip(addr, info)
+//
+//	Fill in the 'info' structure with information about the specified
+//	instruction address, 'addr'.  Returns 0 if information was found, and
+//	negative if not.  But even if it returns negative it has stored some
+//	information into '*info'.
+//
+    int
+debuginfo_eip(uintptr_t addr, struct Eipdebuginfo *info)
+{
+    const struct Stab *stabs, *stab_end;
+    const char *stabstr, *stabstr_end;
+    int lfile, rfile, lfun, rfun, lline, rline;
+
+    // Initialize *info
+    info->eip_file = "<unknown>";
+    info->eip_line = 0;
+    info->eip_fn_name = "<unknown>";
+    info->eip_fn_namelen = 9;
+    info->eip_fn_addr = addr;
+    info->eip_fn_narg = 0;
+
+    // Find the relevant set of stabs
+    if (addr >= ULIM) {
+	stabs = __STAB_BEGIN__;
+	stab_end = __STAB_END__;
+	stabstr = __STABSTR_BEGIN__;
+	stabstr_end = __STABSTR_END__;
+    } else {
+	// The user-application linker script, user/user.ld,
+	// puts information about the application's stabs (equivalent
+	// to __STAB_BEGIN__, __STAB_END__, __STABSTR_BEGIN__, and
+	// __STABSTR_END__) in a structure located at virtual address
+	// USTABDATA.
+	const struct UserStabData *usd = (const struct UserStabData *) USTABDATA;
+
+	// Make sure this memory is valid.
+	// Return -1 if it is not.  Hint: Call user_mem_check.
+	// LAB 3: Your code here.
+	if (user_mem_check(curenv, usd, sizeof(struct UserStabData), PTE_U) < 0)
+	    return -1;
+
+	stabs = usd->stabs;
+	stab_end = usd->stab_end;
+	stabstr = usd->stabstr;
+	stabstr_end = usd->stabstr_end;
+
+	// Make sure the STABS and string table memory is valid.
+	// LAB 3: Your code here.
+	if (user_mem_check(curenv, stabs, stab_end - stabs, PTE_U) < 0) return -1;
+	if (user_mem_check(curenv, stabstr, stabstr_end - stabstr, PTE_U) < 0) return -1;
+    }
+
+    // String table validity checks
+    if (stabstr_end <= stabstr || stabstr_end[-1] != 0)
+	return -1;
+
+    // Now we find the right stabs that define the function containing
+    // 'eip'.  First, we find the basic source file containing 'eip'.
+    // Then, we look in that source file for the function.  Then we look
+    // for the line number.
+
+    // Search the entire set of stabs for the source file (type N_SO).
+    lfile = 0;
+    rfile = (stab_end - stabs) - 1;
+    stab_binsearch(stabs, &lfile, &rfile, N_SO, addr);
+    if (lfile == 0)
+	return -1;
+
+    // Search within that file's stabs for the function definition
+    // (N_FUN).
+    lfun = lfile;
+    rfun = rfile;
+    stab_binsearch(stabs, &lfun, &rfun, N_FUN, addr);
+
+    if (lfun <= rfun) {
+	// stabs[lfun] points to the function name
+	// in the string table, but check bounds just in case.
+	if (stabs[lfun].n_strx < stabstr_end - stabstr)
+	    info->eip_fn_name = stabstr + stabs[lfun].n_strx;
+	info->eip_fn_addr = stabs[lfun].n_value;
+	addr -= info->eip_fn_addr;
+	// Search within the function definition for the line number.
+	lline = lfun;
+	rline = rfun;
+    } else {
+	// Couldn't find function stab!  Maybe we're in an assembly
+	// file.  Search the whole file for the line number.
+	info->eip_fn_addr = addr;
+	lline = lfile;
+	rline = rfile;
+    }
+    // Ignore stuff after the colon.
+    info->eip_fn_namelen = strfind(info->eip_fn_name, ':') - info->eip_fn_name;
+
+
+    // Search within [lline, rline] for the line number stab.
+    // If found, set info->eip_line to the right line number.
+    // If not found, return -1.
+    //
+    // Hint:
+    //	There's a particular stabs type used for line numbers.
+    //	Look at the STABS documentation and <inc/stab.h> to find
+    //	which one.
+    // Your code here.
+    stab_binsearch(stabs, &lline, &rline, N_SLINE, addr);
+    if (lline <= rline) info->eip_line = lline - lfun;
+    else return -1;
+
+
+    // Search backwards from the line number for the relevant filename
+    // stab.
+    // We can't just use the "lfile" stab because inlined functions
+    // can interpolate code from a different file!
+    // Such included source files use the N_SOL stab type.
+    while (lline >= lfile
+	    && stabs[lline].n_type != N_SOL
+	    && (stabs[lline].n_type != N_SO || !stabs[lline].n_value))
+	lline--;
+    if (lline >= lfile && stabs[lline].n_strx < stabstr_end - stabstr)
+	info->eip_file = stabstr + stabs[lline].n_strx;
+
+
+    // Set eip_fn_narg to the number of arguments taken by the function,
+    // or 0 if there was no containing function.
+    if (lfun < rfun)
+	for (lline = lfun + 1;
+		lline < rfun && stabs[lline].n_type == N_PSYM;
+		lline++)
+	    info->eip_fn_narg++;
+
+    return 0;
+}
diff --git a/kern.old/kdebug.h b/kern.old/kdebug.h
new file mode 100755
index 0000000..236af39
--- /dev/null
+++ b/kern.old/kdebug.h
@@ -0,0 +1,20 @@
+#ifndef JOS_KERN_KDEBUG_H
+#define JOS_KERN_KDEBUG_H
+
+#include <inc/types.h>
+
+// Debug information about a particular instruction pointer
+struct Eipdebuginfo {
+	const char *eip_file;		// Source code filename for EIP
+	int eip_line;			// Source code linenumber for EIP
+
+	const char *eip_fn_name;	// Name of function containing EIP
+					//  - Note: not null terminated!
+	int eip_fn_namelen;		// Length of function name
+	uintptr_t eip_fn_addr;		// Address of start of function
+	int eip_fn_narg;		// Number of function arguments
+};
+
+int debuginfo_eip(uintptr_t eip, struct Eipdebuginfo *info);
+
+#endif
diff --git a/kern.old/kernel.ld b/kern.old/kernel.ld
new file mode 100755
index 0000000..45a0b6a
--- /dev/null
+++ b/kern.old/kernel.ld
@@ -0,0 +1,61 @@
+/* Simple linker script for the JOS kernel.
+   See the GNU ld 'info' manual ("info ld") to learn the syntax. */
+
+OUTPUT_FORMAT("elf32-i386", "elf32-i386", "elf32-i386")
+OUTPUT_ARCH(i386)
+ENTRY(_start)
+
+SECTIONS
+{
+	/* Link the kernel at this address: "." means the current address */
+	. = 0xF0100000;
+
+	/* AT(...) gives the load address of this section, which tells
+	   the boot loader where to load the kernel in physical memory */
+	.text : AT(0x100000) {
+		*(.text .stub .text.* .gnu.linkonce.t.*)
+	}
+
+	PROVIDE(etext = .);	/* Define the 'etext' symbol to this value */
+
+	.rodata : {
+		*(.rodata .rodata.* .gnu.linkonce.r.*)
+	}
+
+	/* Include debugging information in kernel memory */
+	.stab : {
+		PROVIDE(__STAB_BEGIN__ = .);
+		*(.stab);
+		PROVIDE(__STAB_END__ = .);
+		BYTE(0)		/* Force the linker to allocate space
+				   for this section */
+	}
+
+	.stabstr : {
+		PROVIDE(__STABSTR_BEGIN__ = .);
+		*(.stabstr);
+		PROVIDE(__STABSTR_END__ = .);
+		BYTE(0)		/* Force the linker to allocate space
+				   for this section */
+	}
+
+	/* Adjust the address for the data segment to the next page */
+	. = ALIGN(0x1000);
+
+	/* The data segment */
+	.data : {
+		*(.data)
+	}
+
+	PROVIDE(edata = .);
+
+	.bss : {
+		*(.bss)
+	}
+
+	PROVIDE(end = .);
+
+	/DISCARD/ : {
+		*(.eh_frame .note.GNU-stack)
+	}
+}
diff --git a/kern.old/lapic.c b/kern.old/lapic.c
new file mode 100755
index 0000000..dc05777
--- /dev/null
+++ b/kern.old/lapic.c
@@ -0,0 +1,182 @@
+// The local APIC manages internal (non-I/O) interrupts.
+// See Chapter 8 & Appendix C of Intel processor manual volume 3.
+
+#include <inc/types.h>
+#include <inc/memlayout.h>
+#include <inc/trap.h>
+#include <inc/mmu.h>
+#include <inc/stdio.h>
+#include <inc/x86.h>
+#include <kern/pmap.h>
+#include <kern/cpu.h>
+
+// Local APIC registers, divided by 4 for use as uint32_t[] indices.
+#define ID      (0x0020/4)   // ID
+#define VER     (0x0030/4)   // Version
+#define TPR     (0x0080/4)   // Task Priority
+#define EOI     (0x00B0/4)   // EOI
+#define SVR     (0x00F0/4)   // Spurious Interrupt Vector
+	#define ENABLE     0x00000100   // Unit Enable
+#define ESR     (0x0280/4)   // Error Status
+#define ICRLO   (0x0300/4)   // Interrupt Command
+	#define INIT       0x00000500   // INIT/RESET
+	#define STARTUP    0x00000600   // Startup IPI
+	#define DELIVS     0x00001000   // Delivery status
+	#define ASSERT     0x00004000   // Assert interrupt (vs deassert)
+	#define DEASSERT   0x00000000
+	#define LEVEL      0x00008000   // Level triggered
+	#define BCAST      0x00080000   // Send to all APICs, including self.
+	#define OTHERS     0x000C0000   // Send to all APICs, excluding self.
+	#define BUSY       0x00001000
+	#define FIXED      0x00000000
+#define ICRHI   (0x0310/4)   // Interrupt Command [63:32]
+#define TIMER   (0x0320/4)   // Local Vector Table 0 (TIMER)
+	#define X1         0x0000000B   // divide counts by 1
+	#define PERIODIC   0x00020000   // Periodic
+#define PCINT   (0x0340/4)   // Performance Counter LVT
+#define LINT0   (0x0350/4)   // Local Vector Table 1 (LINT0)
+#define LINT1   (0x0360/4)   // Local Vector Table 2 (LINT1)
+#define ERROR   (0x0370/4)   // Local Vector Table 3 (ERROR)
+	#define MASKED     0x00010000   // Interrupt masked
+#define TICR    (0x0380/4)   // Timer Initial Count
+#define TCCR    (0x0390/4)   // Timer Current Count
+#define TDCR    (0x03E0/4)   // Timer Divide Configuration
+
+physaddr_t lapicaddr;        // Initialized in mpconfig.c
+volatile uint32_t *lapic;
+
+static void
+lapicw(int index, int value)
+{
+	lapic[index] = value;
+	lapic[ID];  // wait for write to finish, by reading
+}
+
+void
+lapic_init(void)
+{
+	if (!lapicaddr)
+		return;
+
+	// lapicaddr is the physical address of the LAPIC's 4K MMIO
+	// region.  Map it in to virtual memory so we can access it.
+	lapic = mmio_map_region(lapicaddr, 4096);
+
+	// Enable local APIC; set spurious interrupt vector.
+	lapicw(SVR, ENABLE | (IRQ_OFFSET + IRQ_SPURIOUS));
+
+	// The timer repeatedly counts down at bus frequency
+	// from lapic[TICR] and then issues an interrupt.  
+	// If we cared more about precise timekeeping,
+	// TICR would be calibrated using an external time source.
+	lapicw(TDCR, X1);
+	lapicw(TIMER, PERIODIC | (IRQ_OFFSET + IRQ_TIMER));
+	lapicw(TICR, 10000000); 
+
+	// Leave LINT0 of the BSP enabled so that it can get
+	// interrupts from the 8259A chip.
+	//
+	// According to Intel MP Specification, the BIOS should initialize
+	// BSP's local APIC in Virtual Wire Mode, in which 8259A's
+	// INTR is virtually connected to BSP's LINTIN0. In this mode,
+	// we do not need to program the IOAPIC.
+	if (thiscpu != bootcpu)
+		lapicw(LINT0, MASKED);
+
+	// Disable NMI (LINT1) on all CPUs
+	lapicw(LINT1, MASKED);
+
+	// Disable performance counter overflow interrupts
+	// on machines that provide that interrupt entry.
+	if (((lapic[VER]>>16) & 0xFF) >= 4)
+		lapicw(PCINT, MASKED);
+
+	// Map error interrupt to IRQ_ERROR.
+	lapicw(ERROR, IRQ_OFFSET + IRQ_ERROR);
+
+	// Clear error status register (requires back-to-back writes).
+	lapicw(ESR, 0);
+	lapicw(ESR, 0);
+
+	// Ack any outstanding interrupts.
+	lapicw(EOI, 0);
+
+	// Send an Init Level De-Assert to synchronize arbitration ID's.
+	lapicw(ICRHI, 0);
+	lapicw(ICRLO, BCAST | INIT | LEVEL);
+	while(lapic[ICRLO] & DELIVS)
+		;
+
+	// Enable interrupts on the APIC (but not on the processor).
+	lapicw(TPR, 0);
+}
+
+int
+cpunum(void)
+{
+	if (lapic)
+		return lapic[ID] >> 24;
+	return 0;
+}
+
+// Acknowledge interrupt.
+void
+lapic_eoi(void)
+{
+	if (lapic)
+		lapicw(EOI, 0);
+}
+
+// Spin for a given number of microseconds.
+// On real hardware would want to tune this dynamically.
+static void
+microdelay(int us)
+{
+}
+
+#define IO_RTC  0x70
+
+// Start additional processor running entry code at addr.
+// See Appendix B of MultiProcessor Specification.
+void
+lapic_startap(uint8_t apicid, uint32_t addr)
+{
+	int i;
+	uint16_t *wrv;
+
+	// "The BSP must initialize CMOS shutdown code to 0AH
+	// and the warm reset vector (DWORD based at 40:67) to point at
+	// the AP startup code prior to the [universal startup algorithm]."
+	outb(IO_RTC, 0xF);  // offset 0xF is shutdown code
+	outb(IO_RTC+1, 0x0A);
+	wrv = (uint16_t *)KADDR((0x40 << 4 | 0x67));  // Warm reset vector
+	wrv[0] = 0;
+	wrv[1] = addr >> 4;
+
+	// "Universal startup algorithm."
+	// Send INIT (level-triggered) interrupt to reset other CPU.
+	lapicw(ICRHI, apicid << 24);
+	lapicw(ICRLO, INIT | LEVEL | ASSERT);
+	microdelay(200);
+	lapicw(ICRLO, INIT | LEVEL);
+	microdelay(100);    // should be 10ms, but too slow in Bochs!
+
+	// Send startup IPI (twice!) to enter code.
+	// Regular hardware is supposed to only accept a STARTUP
+	// when it is in the halted state due to an INIT.  So the second
+	// should be ignored, but it is part of the official Intel algorithm.
+	// Bochs complains about the second one.  Too bad for Bochs.
+	for (i = 0; i < 2; i++) {
+		lapicw(ICRHI, apicid << 24);
+		lapicw(ICRLO, STARTUP | (addr >> 12));
+		microdelay(200);
+	}
+}
+
+void
+lapic_ipi(int vector)
+{
+	lapicw(ICRLO, OTHERS | FIXED | vector);
+	while (lapic[ICRLO] & DELIVS)
+		;
+}
diff --git a/kern.old/mergedep.pl b/kern.old/mergedep.pl
new file mode 100755
index 0000000..1730d53
--- /dev/null
+++ b/kern.old/mergedep.pl
@@ -0,0 +1,86 @@
+#!/usr/bin/perl
+# Copyright 2003 Bryan Ford
+# Distributed under the GNU General Public License.
+#
+# Usage: mergedep <main-depfile> [<new-depfiles> ...]
+#
+# This script merges the contents of all <new-depfiles> specified
+# on the command line into the single file <main-depfile>,
+# which may or may not previously exist.
+# Dependencies in the <new-depfiles> will override
+# any existing dependencies for the same targets in <main-depfile>.
+# The <new-depfiles> are deleted after <main-depfile> is updated.
+#
+# The <new-depfiles> are typically generated by GCC with the -MD option,
+# and the <main-depfile> is typically included from a Makefile,
+# as shown here for GNU 'make':
+#
+#	.deps: $(wildcard *.d)
+#		perl mergedep $@ $^
+#	-include .deps
+#
+# This script properly handles multiple dependencies per <new-depfile>,
+# including dependencies having no target,
+# so it is compatible with GCC3's -MP option.
+#
+
+sub readdeps {
+	my $filename = shift;
+
+	open(DEPFILE, $filename) or return 0;
+	while (<DEPFILE>) {
+		if (/([^:]*):([^\\:]*)([\\]?)$/) {
+			my $target = $1;
+			my $deplines = $2;
+			my $slash = $3;
+			while ($slash ne '') {
+				$_ = <DEPFILE>;
+				defined($_) or die
+					"Unterminated dependency in $filename";
+				/(^[ \t][^\\]*)([\\]?)$/ or die
+					"Bad continuation line in $filename";
+				$deplines = "$deplines\\\n$1";
+				$slash = $2;
+			}
+			#print "DEPENDENCY [[$target]]: [[$deplines]]\n";
+			$dephash{$target} = $deplines;
+		} elsif (/^[#]?[ \t]*$/) {
+			# ignore blank lines and comments
+		} else {
+			die "Bad dependency line in $filename: $_";
+		}
+	}
+	close DEPFILE;
+	return 1;
+}
+
+
+if ($#ARGV < 0) {
+	print "Usage: mergedep <main-depfile> [<new-depfiles> ..]\n";
+	exit(1);
+}
+
+%dephash = ();
+
+# Read the main dependency file
+$maindeps = $ARGV[0];
+readdeps($maindeps);
+
+# Read and merge in the new dependency files
+foreach $i (1 .. $#ARGV) {
+	readdeps($ARGV[$i]) or die "Can't open $ARGV[$i]";
+}
+
+# Update the main dependency file
+open(DEPFILE, ">$maindeps.tmp") or die "Can't open output file $maindeps.tmp";
+foreach $target (keys %dephash) {
+	print DEPFILE "$target:$dephash{$target}";
+}
+close DEPFILE;
+rename("$maindeps.tmp", "$maindeps") or die "Can't overwrite $maindeps";
+
+# Finally, delete the new dependency files
+foreach $i (1 .. $#ARGV) {
+	unlink($ARGV[$i]) or print "Error removing $ARGV[$i]\n";
+}
+
diff --git a/kern.old/monitor.c b/kern.old/monitor.c
new file mode 100755
index 0000000..9264ee2
--- /dev/null
+++ b/kern.old/monitor.c
@@ -0,0 +1,280 @@
+// Simple command-line kernel monitor useful for
+// controlling the kernel and exploring the system interactively.
+
+#include <inc/stdio.h>
+#include <inc/string.h>
+#include <inc/memlayout.h>
+#include <inc/assert.h>
+#include <inc/x86.h>
+
+#include <kern/console.h>
+#include <kern/monitor.h>
+#include <kern/kdebug.h>
+#include <kern/trap.h>
+#include <kern/pmap.h>
+#include <kern/spinlock.h>
+
+#define CMDBUF_SIZE	80	// enough for one VGA text line
+
+int
+mon_pgmap(int argc, char **argv, struct Trapframe *tf);
+int
+mon_memdump(int argc, char **argv, struct Trapframe *tf);
+int
+mon_pgperm(int argc, char **argv, struct Trapframe *tf);
+int
+mon_continue(int argc, char **argv, struct Trapframe *tf);
+int
+mon_stepins(int argc, char **argv, struct Trapframe *tf);
+
+
+
+struct Command {
+    const char *name;
+    const char *desc;
+    // return -1 to force monitor to exit
+    int (*func)(int argc, char** argv, struct Trapframe* tf);
+};
+
+static struct Command commands[] = {
+    { "help", "Display this list of commands", mon_help },
+    { "kerninfo", "Display information about the kernel", mon_kerninfo },
+    { "pgmap", "Display the physical page mappings", mon_pgmap },
+    { "pgperm", "set, clear, or change the permissions", mon_pgperm },
+    { "memdump", "Dump the contents of a range of memory", mon_memdump },
+    { "backtrace", "Backtrace", mon_backtrace },
+    { "si", "single-step one instruction at a time", mon_stepins },
+    { "c", "continue", mon_continue },
+};
+
+
+/***** Implementations of basic kernel monitor commands *****/
+
+    int
+mon_help(int argc, char **argv, struct Trapframe *tf)
+{
+    int i;
+
+    for (i = 0; i < ARRAY_SIZE(commands); i++)
+	cprintf("%s - %s\n", commands[i].name, commands[i].desc);
+    return 0;
+}
+
+    int
+mon_kerninfo(int argc, char **argv, struct Trapframe *tf)
+{
+    extern char _start[], entry[], etext[], edata[], end[];
+
+    cprintf("Special kernel symbols:\n");
+    cprintf("  _start                  %08x (phys)\n", _start);
+    cprintf("  entry  %08x (virt)  %08x (phys)\n", entry, entry - KERNBASE);
+    cprintf("  etext  %08x (virt)  %08x (phys)\n", etext, etext - KERNBASE);
+    cprintf("  edata  %08x (virt)  %08x (phys)\n", edata, edata - KERNBASE);
+    cprintf("  end    %08x (virt)  %08x (phys)\n", end, end - KERNBASE);
+    cprintf("Kernel executable memory footprint: %dKB\n",
+	    ROUNDUP(end - entry, 1024) / 1024);
+    return 0;
+}
+
+    int
+mon_backtrace(int argc, char **argv, struct Trapframe *tf)
+{
+    int *ebp, eip, *old_ebp;
+    int ary[5]={};
+
+    cprintf("Stack backtrace:\n");
+
+    ebp=(int *)read_ebp();
+    while((int)ebp!=0)
+    {
+	old_ebp=(int *)*(ebp);
+	eip=*(ebp+1);
+	for(int i=0;i<5;++i)
+	{
+	    int j=i+2;
+	    ary[i]=*(ebp+j);
+	}
+	struct Eipdebuginfo eip_info;
+	debuginfo_eip((uintptr_t)eip, &eip_info);
+	cprintf("\033[16ebp %08x eip %08x args %08x %08x %08x %08x %08x\n",ebp,eip,ary[0],ary[1],ary[2],ary[3],ary[4]);
+	cprintf("\033[28	%s:%d:", eip_info.eip_file, eip_info.eip_line);
+	cprintf("\033[3a %.*s+%d\n", eip_info.eip_fn_namelen, eip_info.eip_fn_name, eip - eip_info.eip_fn_addr);
+	ebp=old_ebp;
+    }
+
+    return 0;
+}
+
+
+
+
+    int
+mon_pgmap(int argc, char **argv, struct Trapframe *tf)
+{
+    uintptr_t va1, va2, va;
+    struct PageInfo *pg;
+    pte_t *pte;
+    if (argc != 3) {
+	cprintf("Usage: pgmap va1 va2\n Display physical memory mapping from virtual memory va1 to va2\nva1 and va2 are hex\n");
+	return 0;
+    }
+    else {
+	for (va1 = strtol(argv[1], 0, 16), va2 = strtol(argv[2], 0, 16); va1 < va2; va1 += PGSIZE) {
+	    va = va1 & ~0xfff;
+	    pg = page_lookup(kern_pgdir, (void*)va, 0);
+	    pte = pgdir_walk(kern_pgdir, (void* )va,0);
+	    if (pg){
+		cprintf("[%x, %x) ---> [%x, %x)    ", va, va + PGSIZE, page2pa(pg), page2pa(pg) + PGSIZE);
+		if(*pte & PTE_U)
+		    cprintf("user: ");
+		else 
+		    cprintf("kernel: ");
+
+		if(*pte &PTE_W)
+		    cprintf("read/write ");
+		else 
+		    cprintf("read only ");
+	    }else
+		cprintf("[%x, %x) ---> NULL    ", va, va + PGSIZE);
+
+	    cprintf("\n");                                                                                       
+	}
+    }
+    return 0;
+}
+
+
+    int
+mon_pgperm(int argc, char **argv, struct Trapframe *tf)
+{
+    uintptr_t va, perm;
+    if (argc != 4) {
+	cprintf("Usage: pgperm +/-/= perm va\nset perm of page which contains va, va is hex\n");
+	return 0;
+    }
+    else {
+	va = strtol(argv[3], 0, 16);
+	perm = strtol(argv[2], 0, 16);
+	pte_t *pte = pgdir_walk(kern_pgdir, (void*)va, 0);
+	if (!pte) {
+	    cprintf("0x%x is not mapped\n", va);
+	}
+	else {
+	    if (argv[1][0] == '+') *pte |= perm;
+	    if (argv[1][0] == '0') *pte &= ~perm;
+	    if (argv[1][0] == '=') *pte = PTE_ADDR(*pte) | perm;
+	}
+    }
+    return 0;
+}
+
+    int
+mon_memdump(int argc, char **argv, struct Trapframe *tf)
+{
+    uintptr_t a1, a2, a;
+    struct PageInfo *pg;
+    if (argc != 4) {
+	cprintf("Usage: memdump p/v a1 a2\n Dump memory content via virtual or physical address\na1 and a2 are hex\n");
+	return 0;
+    }
+    else {
+	a1 = strtol(argv[2], 0, 16), a2 = strtol(argv[3], 0, 16);
+	if (argv[1][0] == 'p') a1 = (int)KADDR(a1), a2 = (int)KADDR(a2);
+	for (a = a1; a < a2 && a >= KERNBASE; a += 4) {
+	    if (!((a - a1) & 0xf)) cprintf("\n%x:\t", a);
+	    cprintf(" %x", *(int*)(a));
+	}
+	cprintf("\n");
+    }
+    return 0;
+}
+
+
+/***** Kernel monitor command interpreter *****/
+
+#define WHITESPACE "\t\r\n "
+#define MAXARGS 16
+
+    static int
+runcmd(char *buf, struct Trapframe *tf)
+{
+    int argc;
+    char *argv[MAXARGS];
+    int i;
+
+    // Parse the command buffer into whitespace-separated arguments
+    argc = 0;
+    argv[argc] = 0;
+    while (1) {
+	// gobble whitespace
+	while (*buf && strchr(WHITESPACE, *buf))
+	    *buf++ = 0;
+	if (*buf == 0)
+	    break;
+
+	// save and scan past next arg
+	if (argc == MAXARGS-1) {
+	    cprintf("Too many arguments (max %d)\n", MAXARGS);
+	    return 0;
+	}
+	argv[argc++] = buf;
+	while (*buf && !strchr(WHITESPACE, *buf))
+	    buf++;
+    }
+    argv[argc] = 0;
+
+    // Lookup and invoke the command
+    if (argc == 0)
+	return 0;
+    for (i = 0; i < ARRAY_SIZE(commands); i++) {
+	if (strcmp(argv[0], commands[i].name) == 0)
+	    return commands[i].func(argc, argv, tf);
+    }
+    cprintf("Unknown command '%s'\n", argv[0]);
+    return 0;
+}
+
+    void
+monitor(struct Trapframe *tf)
+{
+    char *buf;
+
+    lock(&monitor_lock);
+
+    cprintf("Welcome to the JOS kernel monitor!\n");
+    cprintf("Type 'help' for a list of commands.\n");
+
+    if (tf != NULL)
+	print_trapframe(tf);
+
+    while (1) {
+	buf = readline("K> ");
+	if (buf != NULL)
+	    if (runcmd(buf, tf) < 0)
+		break;
+    }
+    unlock(&monitor_lock);
+}
+
+extern void env_pop_tf(struct Trapframe *tf);
+    int
+mon_continue(int argc, char **argv, struct Trapframe *tf)
+{
+    if (tf->tf_trapno == T_BRKPT || tf->tf_trapno == T_DEBUG) {
+	tf->tf_eflags &= ~FL_TF;
+	env_pop_tf(tf);
+    }
+    return 0;
+}
+
+    int
+mon_stepins(int argc, char **argv, struct Trapframe *tf)
+{
+    if (tf->tf_trapno == T_BRKPT || tf->tf_trapno == T_DEBUG) {
+	tf->tf_eflags |= FL_TF;
+	env_pop_tf(tf);
+    }
+    return 0;
+}
+
+
diff --git a/kern.old/monitor.h b/kern.old/monitor.h
new file mode 100755
index 0000000..0aa0f26
--- /dev/null
+++ b/kern.old/monitor.h
@@ -0,0 +1,19 @@
+#ifndef JOS_KERN_MONITOR_H
+#define JOS_KERN_MONITOR_H
+#ifndef JOS_KERNEL
+# error "This is a JOS kernel header; user programs should not #include it"
+#endif
+
+struct Trapframe;
+
+// Activate the kernel monitor,
+// optionally providing a trap frame indicating the current state
+// (NULL if none).
+void monitor(struct Trapframe *tf);
+
+// Functions implementing monitor commands.
+int mon_help(int argc, char **argv, struct Trapframe *tf);
+int mon_kerninfo(int argc, char **argv, struct Trapframe *tf);
+int mon_backtrace(int argc, char **argv, struct Trapframe *tf);
+
+#endif	// !JOS_KERN_MONITOR_H
diff --git a/kern.old/mpconfig.c b/kern.old/mpconfig.c
new file mode 100755
index 0000000..dbca4fd
--- /dev/null
+++ b/kern.old/mpconfig.c
@@ -0,0 +1,225 @@
+// Search for and parse the multiprocessor configuration table
+// See http://developer.intel.com/design/pentium/datashts/24201606.pdf
+
+#include <inc/types.h>
+#include <inc/string.h>
+#include <inc/memlayout.h>
+#include <inc/x86.h>
+#include <inc/mmu.h>
+#include <inc/env.h>
+#include <kern/cpu.h>
+#include <kern/pmap.h>
+
+struct CpuInfo cpus[NCPU];
+struct CpuInfo *bootcpu;
+int ismp;
+int ncpu;
+
+// Per-CPU kernel stacks
+unsigned char percpu_kstacks[NCPU][KSTKSIZE]
+__attribute__ ((aligned(PGSIZE)));
+
+
+// See MultiProcessor Specification Version 1.[14]
+
+struct mp {             // floating pointer [MP 4.1]
+	uint8_t signature[4];           // "_MP_"
+	physaddr_t physaddr;            // phys addr of MP config table
+	uint8_t length;                 // 1
+	uint8_t specrev;                // [14]
+	uint8_t checksum;               // all bytes must add up to 0
+	uint8_t type;                   // MP system config type
+	uint8_t imcrp;
+	uint8_t reserved[3];
+} __attribute__((__packed__));
+
+struct mpconf {         // configuration table header [MP 4.2]
+	uint8_t signature[4];           // "PCMP"
+	uint16_t length;                // total table length
+	uint8_t version;                // [14]
+	uint8_t checksum;               // all bytes must add up to 0
+	uint8_t product[20];            // product id
+	physaddr_t oemtable;            // OEM table pointer
+	uint16_t oemlength;             // OEM table length
+	uint16_t entry;                 // entry count
+	physaddr_t lapicaddr;           // address of local APIC
+	uint16_t xlength;               // extended table length
+	uint8_t xchecksum;              // extended table checksum
+	uint8_t reserved;
+	uint8_t entries[0];             // table entries
+} __attribute__((__packed__));
+
+struct mpproc {         // processor table entry [MP 4.3.1]
+	uint8_t type;                   // entry type (0)
+	uint8_t apicid;                 // local APIC id
+	uint8_t version;                // local APIC version
+	uint8_t flags;                  // CPU flags
+	uint8_t signature[4];           // CPU signature
+	uint32_t feature;               // feature flags from CPUID instruction
+	uint8_t reserved[8];
+} __attribute__((__packed__));
+
+// mpproc flags
+#define MPPROC_BOOT 0x02                // This mpproc is the bootstrap processor
+
+// Table entry types
+#define MPPROC    0x00  // One per processor
+#define MPBUS     0x01  // One per bus
+#define MPIOAPIC  0x02  // One per I/O APIC
+#define MPIOINTR  0x03  // One per bus interrupt source
+#define MPLINTR   0x04  // One per system interrupt source
+
+static uint8_t
+sum(void *addr, int len)
+{
+	int i, sum;
+
+	sum = 0;
+	for (i = 0; i < len; i++)
+		sum += ((uint8_t *)addr)[i];
+	return sum;
+}
+
+// Look for an MP structure in the len bytes at physical address addr.
+static struct mp *
+mpsearch1(physaddr_t a, int len)
+{
+	struct mp *mp = KADDR(a), *end = KADDR(a + len);
+
+	for (; mp < end; mp++)
+		if (memcmp(mp->signature, "_MP_", 4) == 0 &&
+		    sum(mp, sizeof(*mp)) == 0)
+			return mp;
+	return NULL;
+}
+
+// Search for the MP Floating Pointer Structure, which according to
+// [MP 4] is in one of the following three locations:
+// 1) in the first KB of the EBDA;
+// 2) if there is no EBDA, in the last KB of system base memory;
+// 3) in the BIOS ROM between 0xE0000 and 0xFFFFF.
+static struct mp *
+mpsearch(void)
+{
+	uint8_t *bda;
+	uint32_t p;
+	struct mp *mp;
+
+	static_assert(sizeof(*mp) == 16);
+
+	// The BIOS data area lives in 16-bit segment 0x40.
+	bda = (uint8_t *) KADDR(0x40 << 4);
+
+	// [MP 4] The 16-bit segment of the EBDA is in the two bytes
+	// starting at byte 0x0E of the BDA.  0 if not present.
+	if ((p = *(uint16_t *) (bda + 0x0E))) {
+		p <<= 4;	// Translate from segment to PA
+		if ((mp = mpsearch1(p, 1024)))
+			return mp;
+	} else {
+		// The size of base memory, in KB is in the two bytes
+		// starting at 0x13 of the BDA.
+		p = *(uint16_t *) (bda + 0x13) * 1024;
+		if ((mp = mpsearch1(p - 1024, 1024)))
+			return mp;
+	}
+	return mpsearch1(0xF0000, 0x10000);
+}
+
+// Search for an MP configuration table.  For now, don't accept the
+// default configurations (physaddr == 0).
+// Check for the correct signature, checksum, and version.
+static struct mpconf *
+mpconfig(struct mp **pmp)
+{
+	struct mpconf *conf;
+	struct mp *mp;
+
+	if ((mp = mpsearch()) == 0)
+		return NULL;
+	if (mp->physaddr == 0 || mp->type != 0) {
+		cprintf("SMP: Default configurations not implemented\n");
+		return NULL;
+	}
+	conf = (struct mpconf *) KADDR(mp->physaddr);
+	if (memcmp(conf, "PCMP", 4) != 0) {
+		cprintf("SMP: Incorrect MP configuration table signature\n");
+		return NULL;
+	}
+	if (sum(conf, conf->length) != 0) {
+		cprintf("SMP: Bad MP configuration checksum\n");
+		return NULL;
+	}
+	if (conf->version != 1 && conf->version != 4) {
+		cprintf("SMP: Unsupported MP version %d\n", conf->version);
+		return NULL;
+	}
+	if ((sum((uint8_t *)conf + conf->length, conf->xlength) + conf->xchecksum) & 0xff) {
+		cprintf("SMP: Bad MP configuration extended checksum\n");
+		return NULL;
+	}
+	*pmp = mp;
+	return conf;
+}
+
+void
+mp_init(void)
+{
+	struct mp *mp;
+	struct mpconf *conf;
+	struct mpproc *proc;
+	uint8_t *p;
+	unsigned int i;
+
+	bootcpu = &cpus[0];
+	if ((conf = mpconfig(&mp)) == 0)
+		return;
+	ismp = 1;
+	lapicaddr = conf->lapicaddr;
+
+	for (p = conf->entries, i = 0; i < conf->entry; i++) {
+		switch (*p) {
+		case MPPROC:
+			proc = (struct mpproc *)p;
+			if (proc->flags & MPPROC_BOOT)
+				bootcpu = &cpus[ncpu];
+			if (ncpu < NCPU) {
+				cpus[ncpu].cpu_id = ncpu;
+				ncpu++;
+			} else {
+				cprintf("SMP: too many CPUs, CPU %d disabled\n",
+					proc->apicid);
+			}
+			p += sizeof(struct mpproc);
+			continue;
+		case MPBUS:
+		case MPIOAPIC:
+		case MPIOINTR:
+		case MPLINTR:
+			p += 8;
+			continue;
+		default:
+			cprintf("mpinit: unknown config type %x\n", *p);
+			ismp = 0;
+			i = conf->entry;
+		}
+	}
+
+	bootcpu->cpu_status = CPU_STARTED;
+	if (!ismp) {
+		// Didn't like what we found; fall back to no MP.
+		ncpu = 1;
+		lapicaddr = 0;
+		cprintf("SMP: configuration not found, SMP disabled\n");
+		return;
+	}
+	cprintf("SMP: CPU %d found %d CPU(s)\n", bootcpu->cpu_id,  ncpu);
+
+	if (mp->imcrp) {
+		// [MP 3.2.6.1] If the hardware implements PIC mode,
+		// switch to getting interrupts from the LAPIC.
+		cprintf("SMP: Setting IMCR to switch from PIC mode to symmetric I/O mode\n");
+		outb(0x22, 0x70);   // Select IMCR
+		outb(0x23, inb(0x23) | 1);  // Mask external interrupts.
+	}
+}
diff --git a/kern.old/mpentry.S b/kern.old/mpentry.S
new file mode 100755
index 0000000..72dd827
--- /dev/null
+++ b/kern.old/mpentry.S
@@ -0,0 +1,97 @@
+/* See COPYRIGHT for copyright information. */
+
+#include <inc/mmu.h>
+#include <inc/memlayout.h>
+
+###################################################################
+# entry point for APs
+###################################################################
+
+# Each non-boot CPU ("AP") is started up in response to a STARTUP
+# IPI from the boot CPU.  Section B.4.2 of the Multi-Processor
+# Specification says that the AP will start in real mode with CS:IP
+# set to XY00:0000, where XY is an 8-bit value sent with the
+# STARTUP. Thus this code must start at a 4096-byte boundary.
+#
+# Because this code sets DS to zero, it must run from an address in
+# the low 2^16 bytes of physical memory.
+#
+# boot_aps() (in init.c) copies this code to MPENTRY_PADDR (which
+# satisfies the above restrictions).  Then, for each AP, it stores the
+# address of the pre-allocated per-core stack in mpentry_kstack, sends
+# the STARTUP IPI, and waits for this code to acknowledge that it has
+# started (which happens in mp_main in init.c).
+#
+# This code is similar to boot/boot.S except that
+#    - it does not need to enable A20
+#    - it uses MPBOOTPHYS to calculate absolute addresses of its
+#      symbols, rather than relying on the linker to fill them
+
+#define RELOC(x) ((x) - KERNBASE)
+#define MPBOOTPHYS(s) ((s) - mpentry_start + MPENTRY_PADDR)
+
+.set PROT_MODE_CSEG, 0x8	# kernel code segment selector
+.set PROT_MODE_DSEG, 0x10	# kernel data segment selector
+
+.code16           
+.globl mpentry_start
+mpentry_start:
+	cli            
+
+	xorw    %ax, %ax
+	movw    %ax, %ds
+	movw    %ax, %es
+	movw    %ax, %ss
+
+	lgdt    MPBOOTPHYS(gdtdesc)
+	movl    %cr0, %eax
+	orl     $CR0_PE, %eax
+	movl    %eax, %cr0
+
+	ljmpl   $(PROT_MODE_CSEG), $(MPBOOTPHYS(start32))
+
+.code32
+start32:
+	movw    $(PROT_MODE_DSEG), %ax
+	movw    %ax, %ds
+	movw    %ax, %es
+	movw    %ax, %ss
+	movw    $0, %ax
+	movw    %ax, %fs
+	movw    %ax, %gs
+
+	# Set up initial page table. We cannot use kern_pgdir yet because
+	# we are still running at a low EIP.
+	movl    $(RELOC(entry_pgdir)), %eax
+	movl    %eax, %cr3
+	# Turn on paging.
+	movl    %cr0, %eax
+	orl     $(CR0_PE|CR0_PG|CR0_WP), %eax
+	movl    %eax, %cr0
+
+	# Switch to the per-cpu stack allocated in boot_aps()
+	movl    mpentry_kstack, %esp
+	movl    $0x0, %ebp       # nuke frame pointer
+
+	# Call mp_main().  (Exercise for the reader: why the indirect call?)
+	movl    $mp_main, %eax
+	call    *%eax
+
+	# If mp_main returns (it shouldn't), loop.
+spin:
+	jmp     spin
+
+# Bootstrap GDT
+.p2align 2					# force 4 byte alignment
+gdt:
+	SEG_NULL				# null seg
+	SEG(STA_X|STA_R, 0x0, 0xffffffff)	# code seg
+	SEG(STA_W, 0x0, 0xffffffff)		# data seg
+
+gdtdesc:
+	.word   0x17				# sizeof(gdt) - 1
+	.long   MPBOOTPHYS(gdt)			# address gdt
+
+.globl mpentry_end
+mpentry_end:
+	nop
diff --git a/kern.old/picirq.c b/kern.old/picirq.c
new file mode 100755
index 0000000..8cb3e62
--- /dev/null
+++ b/kern.old/picirq.c
@@ -0,0 +1,86 @@
+/* See COPYRIGHT for copyright information. */
+
+#include <inc/assert.h>
+#include <inc/trap.h>
+
+#include <kern/picirq.h>
+
+
+// Current IRQ mask.
+// Initial IRQ mask has interrupt 2 enabled (for slave 8259A).
+uint16_t irq_mask_8259A = 0xFFFF & ~(1<<IRQ_SLAVE);
+static bool didinit;
+
+/* Initialize the 8259A interrupt controllers. */
+void
+pic_init(void)
+{
+	didinit = 1;
+
+	// mask all interrupts
+	outb(IO_PIC1+1, 0xFF);
+	outb(IO_PIC2+1, 0xFF);
+
+	// Set up master (8259A-1)
+
+	// ICW1:  0001g0hi
+	//    g:  0 = edge triggering, 1 = level triggering
+	//    h:  0 = cascaded PICs, 1 = master only
+	//    i:  0 = no ICW4, 1 = ICW4 required
+	outb(IO_PIC1, 0x11);
+
+	// ICW2:  Vector offset
+	outb(IO_PIC1+1, IRQ_OFFSET);
+
+	// ICW3:  bit mask of IR lines connected to slave PICs (master PIC),
+	//        3-bit No of IR line at which slave connects to master(slave PIC).
+	outb(IO_PIC1+1, 1<<IRQ_SLAVE);
+
+	// ICW4:  000nbmap
+	//    n:  1 = special fully nested mode
+	//    b:  1 = buffered mode
+	//    m:  0 = slave PIC, 1 = master PIC
+	//	  (ignored when b is 0, as the master/slave role
+	//	  can be hardwired).
+	//    a:  1 = Automatic EOI mode
+	//    p:  0 = MCS-80/85 mode, 1 = intel x86 mode
+	outb(IO_PIC1+1, 0x3);
+
+	// Set up slave (8259A-2)
+	outb(IO_PIC2, 0x11);			// ICW1
+	outb(IO_PIC2+1, IRQ_OFFSET + 8);	// ICW2
+	outb(IO_PIC2+1, IRQ_SLAVE);		// ICW3
+	// NB Automatic EOI mode doesn't tend to work on the slave.
+	// Linux source code says it's "to be investigated".
+	outb(IO_PIC2+1, 0x01);			// ICW4
+
+	// OCW3:  0ef01prs
+	//   ef:  0x = NOP, 10 = clear specific mask, 11 = set specific mask
+	//    p:  0 = no polling, 1 = polling mode
+	//   rs:  0x = NOP, 10 = read IRR, 11 = read ISR
+	outb(IO_PIC1, 0x68);             /* clear specific mask */
+	outb(IO_PIC1, 0x0a);             /* read IRR by default */
+
+	outb(IO_PIC2, 0x68);               /* OCW3 */
+	outb(IO_PIC2, 0x0a);               /* OCW3 */
+
+	if (irq_mask_8259A != 0xFFFF)
+		irq_setmask_8259A(irq_mask_8259A);
+}
+
+void
+irq_setmask_8259A(uint16_t mask)
+{
+	int i;
+	irq_mask_8259A = mask;
+	if (!didinit)
+		return;
+	outb(IO_PIC1+1, (char)mask);
+	outb(IO_PIC2+1, (char)(mask >> 8));
+	cprintf("enabled interrupts:");
+	for (i = 0; i < 16; i++)
+		if (~mask & (1<<i))
+			cprintf(" %d", i);
+	cprintf("\n");
+}
+
diff --git a/kern.old/picirq.h b/kern.old/picirq.h
new file mode 100755
index 0000000..4734889
--- /dev/null
+++ b/kern.old/picirq.h
@@ -0,0 +1,28 @@
+/* See COPYRIGHT for copyright information. */
+
+#ifndef JOS_KERN_PICIRQ_H
+#define JOS_KERN_PICIRQ_H
+#ifndef JOS_KERNEL
+# error "This is a JOS kernel header; user programs should not #include it"
+#endif
+
+#define MAX_IRQS	16	// Number of IRQs
+
+// I/O Addresses of the two 8259A programmable interrupt controllers
+#define IO_PIC1		0x20	// Master (IRQs 0-7)
+#define IO_PIC2		0xA0	// Slave (IRQs 8-15)
+
+#define IRQ_SLAVE	2	// IRQ at which slave connects to master
+
+
+#ifndef __ASSEMBLER__
+
+#include <inc/types.h>
+#include <inc/x86.h>
+
+extern uint16_t irq_mask_8259A;
+void pic_init(void);
+void irq_setmask_8259A(uint16_t mask);
+#endif // !__ASSEMBLER__
+
+#endif // !JOS_KERN_PICIRQ_H
diff --git a/kern.old/pmap.c b/kern.old/pmap.c
new file mode 100755
index 0000000..43e53b7
--- /dev/null
+++ b/kern.old/pmap.c
@@ -0,0 +1,1098 @@
+/* See COPYRIGHT for copyright information. */
+
+#include <inc/x86.h>
+#include <inc/mmu.h>
+#include <inc/error.h>
+#include <inc/string.h>
+#include <inc/assert.h>
+
+#include <kern/pmap.h>
+#include <kern/kclock.h>
+#include <kern/env.h>
+#include <kern/cpu.h>
+#include <kern/spinlock.h>
+
+// These variables are set by i386_detect_memory()
+size_t npages;			// Amount of physical memory (in pages)
+static size_t npages_basemem;	// Amount of base memory (in pages)
+
+// These variables are set in mem_init()
+pde_t *kern_pgdir;		// Kernel's initial page directory
+struct PageInfo *pages;		// Physical page state array
+static struct PageInfo *page_free_list;	// Free list of physical pages
+
+// --------------------------------------------------------------
+// Detect machine's physical memory setup.
+// --------------------------------------------------------------
+
+    static int
+nvram_read(int r)
+{
+    return mc146818_read(r) | (mc146818_read(r + 1) << 8);
+}
+
+    static void
+i386_detect_memory(void)
+{
+    size_t basemem, extmem, ext16mem, totalmem;
+
+    // Use CMOS calls to measure available base & extended memory.
+    // (CMOS calls return results in kilobytes.)
+    basemem = nvram_read(NVRAM_BASELO);
+    extmem = nvram_read(NVRAM_EXTLO);
+    ext16mem = nvram_read(NVRAM_EXT16LO) * 64;
+
+    // Calculate the number of physical pages available in both base
+    // and extended memory.
+    if (ext16mem)
+	totalmem = 16 * 1024 + ext16mem;
+    else if (extmem)
+	totalmem = 1 * 1024 + extmem;
+    else
+	totalmem = basemem;
+
+    npages = totalmem / (PGSIZE / 1024);
+    npages_basemem = basemem / (PGSIZE / 1024);
+
+    cprintf("Physical memory: %uK available, base = %uK, extended = %uK\n",
+	    totalmem, basemem, totalmem - basemem);
+}
+
+
+// --------------------------------------------------------------
+// Set up memory mappings above UTOP.
+// --------------------------------------------------------------
+
+static void mem_init_mp(void);
+static void boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm);
+static void check_page_free_list(bool only_low_memory);
+static void check_page_alloc(void);
+static void check_kern_pgdir(void);
+static physaddr_t check_va2pa(pde_t *pgdir, uintptr_t va);
+static void check_page(void);
+static void check_page_installed_pgdir(void);
+
+// This simple physical memory allocator is used only while JOS is setting
+// up its virtual memory system.  page_alloc() is the real allocator.
+//
+// If n>0, allocates enough pages of contiguous physical memory to hold 'n'
+// bytes.  Doesn't initialize the memory.  Returns a kernel virtual address.
+//
+// If n==0, returns the address of the next free page without allocating
+// anything.
+//
+// If we're out of memory, boot_alloc should panic.
+// This function may ONLY be used during initialization,
+// before the page_free_list list has been set up.
+    static void *
+boot_alloc(uint32_t n)
+{
+    static char *nextfree;	// virtual address of next byte of free memory
+    char *result;
+
+    // Initialize nextfree if this is the first time.
+    // 'end' is a magic symbol automatically generated by the linker,
+    // which points to the end of the kernel's bss segment:
+    // the first virtual address that the linker did *not* assign
+    // to any kernel code or global variables.
+    if (!nextfree) {
+	extern char end[];
+	nextfree = ROUNDUP((char *) end, PGSIZE);
+    }
+
+    // Allocate a chunk large enough to hold 'n' bytes, then update
+    // nextfree.  Make sure nextfree is kept aligned
+    // to a multiple of PGSIZE.
+    // LAB 2: Your code here.
+    if (n == 0) return (void*)nextfree;
+    n = ROUNDUP(n, PGSIZE);
+    if (PADDR(nextfree + n) > npages * PGSIZE)
+    {
+	panic("kern/pmap.c: boot_alloc()");
+	return NULL;
+    }
+    result = nextfree;
+    nextfree += n;
+    return result;
+}
+
+// Set up a two-level page table:
+//    kern_pgdir is its linear (virtual) address of the root
+//
+// This function only sets up the kernel part of the address space
+// (ie. addresses >= UTOP).  The user part of the address space
+// will be setup later.
+//
+// From UTOP to ULIM, the user is allowed to read but not write.
+// Above ULIM the user cannot read or write.
+    void
+mem_init(void)
+{
+    uint32_t cr0;
+    size_t n;
+
+    // Find out how much memory the machine has (npages & npages_basemem).
+    i386_detect_memory();
+
+    // Remove this line when you're ready to test this function.
+    //panic("mem_init: This function is not finished\n");
+
+    //////////////////////////////////////////////////////////////////////
+    // create initial page directory.
+    kern_pgdir = (pde_t *) boot_alloc(PGSIZE);
+    memset(kern_pgdir, 0, PGSIZE);
+
+    //////////////////////////////////////////////////////////////////////
+    // Recursively insert PD in itself as a page table, to form
+    // a virtual page table at virtual address UVPT.
+    // (For now, you don't have understand the greater purpose of the
+    // following line.)
+
+    // Permissions: kernel R, user R
+    kern_pgdir[PDX(UVPT)] = PADDR(kern_pgdir) | PTE_U | PTE_P;
+
+    //////////////////////////////////////////////////////////////////////
+    // Allocate an array of npages 'struct PageInfo's and store it in 'pages'.
+    // The kernel uses this array to keep track of physical pages: for
+    // each physical page, there is a corresponding struct PageInfo in this
+    // array.  'npages' is the number of physical pages in memory.  Use memset
+    // to initialize all fields of each struct PageInfo to 0.
+    // Your code goes here:
+    pages = (struct PageInfo*)boot_alloc(npages * sizeof(struct PageInfo));
+    memset(pages, 0, npages * sizeof(struct PageInfo));
+
+    //////////////////////////////////////////////////////////////////////
+    // Make 'envs' point to an array of size 'NENV' of 'struct Env'.
+    // LAB 3: Your code here.
+    envs = (struct Env*)boot_alloc(NENV * sizeof(struct Env));
+
+    //////////////////////////////////////////////////////////////////////
+    // Now that we've allocated the initial kernel data structures, we set
+    // up the list of free physical pages. Once we've done so, all further
+    // memory management will go through the page_* functions. In
+    // particular, we can now map memory using boot_map_region
+    // or page_insert
+    page_init();
+
+    check_page_free_list(1);
+    check_page_alloc();
+    check_page();
+
+    //////////////////////////////////////////////////////////////////////
+    // Now we set up virtual memory
+
+    //////////////////////////////////////////////////////////////////////
+    // Map 'pages' read-only by the user at linear address UPAGES
+    // Permissions:
+    //    - the new image at UPAGES -- kernel R, user R
+    //      (ie. perm = PTE_U | PTE_P)
+    //    - pages itself -- kernel RW, user NONE
+    // Your code goes here:
+    boot_map_region(kern_pgdir, UPAGES, ROUNDUP(sizeof(struct PageInfo)* npages, PGSIZE), PADDR(pages), PTE_U);
+
+    //////////////////////////////////////////////////////////////////////
+    // Map the 'envs' array read-only by the user at linear address UENVS
+    // (ie. perm = PTE_U | PTE_P).
+    // Permissions:
+    //    - the new image at UENVS  -- kernel R, user R
+    //    - envs itself -- kernel RW, user NONE
+    // LAB 3: Your code here.
+    boot_map_region(kern_pgdir, UENVS, ROUNDUP(sizeof(struct Env) * NENV, PGSIZE), PADDR(envs), PTE_U);	
+
+    //////////////////////////////////////////////////////////////////////
+    // Use the physical memory that 'bootstack' refers to as the kernel
+    // stack.  The kernel stack grows down from virtual address KSTACKTOP.
+    // We consider the entire range from [KSTACKTOP-PTSIZE, KSTACKTOP)
+    // to be the kernel stack, but break this into two pieces:
+    //     * [KSTACKTOP-KSTKSIZE, KSTACKTOP) -- backed by physical memory
+    //     * [KSTACKTOP-PTSIZE, KSTACKTOP-KSTKSIZE) -- not backed; so if
+    //       the kernel overflows its stack, it will fault rather than
+    //       overwrite memory.  Known as a "guard page".
+    //     Permissions: kernel RW, user NONE
+    // Your code goes here:
+    boot_map_region(kern_pgdir, KSTACKTOP - KSTKSIZE, ROUNDUP(KSTKSIZE, PGSIZE), PADDR(bootstack), PTE_W);
+
+    //////////////////////////////////////////////////////////////////////
+    // Map all of physical memory at KERNBASE.
+    // Ie.  the VA range [KERNBASE, 2^32) should map to
+    //      the PA range [0, 2^32 - KERNBASE)
+    // We might not have 2^32 - KERNBASE bytes of physical memory, but
+    // we just set up the mapping anyway.
+    // Permissions: kernel RW, user NONE
+    // Your code goes here:
+    boot_map_region(kern_pgdir, (uintptr_t)KERNBASE , -KERNBASE, (physaddr_t)0, PTE_W);
+
+
+    // Initialize the SMP-related parts of the memory map
+    mem_init_mp();
+
+    // Check that the initial page directory has been set up correctly.
+    check_kern_pgdir();
+
+    // Switch from the minimal entry page directory to the full kern_pgdir
+    // page table we just created.	Our instruction pointer should be
+    // somewhere between KERNBASE and KERNBASE+4MB right now, which is
+    // mapped the same way by both page tables.
+    //
+    // If the machine reboots at this point, you've probably set up your
+    // kern_pgdir wrong.
+    lcr3(PADDR(kern_pgdir));
+
+    check_page_free_list(0);
+
+    // entry.S set the really important flags in cr0 (including enabling
+    // paging).  Here we configure the rest of the flags that we care about.
+    cr0 = rcr0();
+    cr0 |= CR0_PE|CR0_PG|CR0_AM|CR0_WP|CR0_NE|CR0_MP;
+    cr0 &= ~(CR0_TS|CR0_EM);
+    lcr0(cr0);
+
+    // Some more checks, only possible after kern_pgdir is installed.
+    check_page_installed_pgdir();
+}
+
+// Modify mappings in kern_pgdir to support SMP
+//   - Map the per-CPU stacks in the region [KSTACKTOP-PTSIZE, KSTACKTOP)
+//
+    static void
+mem_init_mp(void)
+{
+    // Map per-CPU stacks starting at KSTACKTOP, for up to 'NCPU' CPUs.
+    //
+    // For CPU i, use the physical memory that 'percpu_kstacks[i]' refers
+    // to as its kernel stack. CPU i's kernel stack grows down from virtual
+    // address kstacktop_i = KSTACKTOP - i * (KSTKSIZE + KSTKGAP), and is
+    // divided into two pieces, just like the single stack you set up in
+    // mem_init:
+    //     * [kstacktop_i - KSTKSIZE, kstacktop_i)
+    //          -- backed by physical memory
+    //     * [kstacktop_i - (KSTKSIZE + KSTKGAP), kstacktop_i - KSTKSIZE)
+    //          -- not backed; so if the kernel overflows its stack,
+    //             it will fault rather than overwrite another CPU's stack.
+    //             Known as a "guard page".
+    //     Permissions: kernel RW, user NONE
+    //
+    // LAB 4: Your code here:
+    int c;
+    for (c = 0; c < NCPU; ++c) {
+	boot_map_region(kern_pgdir, KSTACKTOP - c * (KSTKSIZE + KSTKGAP) - KSTKSIZE,
+		ROUNDUP(KSTKSIZE, PGSIZE), PADDR(percpu_kstacks[c]), PTE_W);
+    }
+
+}
+
+// --------------------------------------------------------------
+// Tracking of physical pages.
+// The 'pages' array has one 'struct PageInfo' entry per physical page.
+// Pages are reference counted, and free pages are kept on a linked list.
+// --------------------------------------------------------------
+
+//
+// Initialize page structure and memory free list.
+// After this is done, NEVER use boot_alloc again.  ONLY use the page
+// allocator functions below to allocate and deallocate physical
+// memory via the page_free_list.
+//
+    void
+page_init(void)
+{
+    // LAB 4:
+    // Change your code to mark the physical page at MPENTRY_PADDR
+    // as in use
+
+    // The example code here marks all physical pages as free.
+    // However this is not truly the case.  What memory is free?
+    //  1) Mark physical page 0 as in use.
+    //     This way we preserve the real-mode IDT and BIOS structures
+    //     in case we ever need them.  (Currently we don't, but...)
+    //  2) The rest of base memory, [PGSIZE, npages_basemem * PGSIZE)
+    //     is free.
+    //  3) Then comes the IO hole [IOPHYSMEM, EXTPHYSMEM), which must
+    //     never be allocated.
+    //  4) Then extended memory [EXTPHYSMEM, ...).
+    //     Some of it is in use, some is free. Where is the kernel
+    //     in physical memory?  Which pages are already in use for
+    //     page tables and other data structures?
+    //
+    // Change the code to reflect this.
+    // NB: DO NOT actually touch the physical memory corresponding to
+    // free pages!
+    size_t i;
+    assert(page_free_list == 0);
+    unsigned used_top = PADDR(boot_alloc(0));
+    for (i = 0; i < npages; i++) {
+	if (i == 0 || (page2pa(&pages[i]) >= IOPHYSMEM && page2pa(&pages[i]) < used_top)||(page2pa(&pages[i]) == MPENTRY_PADDR))
+	    continue;
+	pages[i].pp_ref = 0;
+	pages[i].pp_link = page_free_list;
+	page_free_list = &pages[i];
+    }
+}
+
+//
+// Allocates a physical page.  If (alloc_flags & ALLOC_ZERO), fills the entire
+// returned physical page with '\0' bytes.  Does NOT increment the reference
+// count of the page - the caller must do these if necessary (either explicitly
+// or via page_insert).
+//
+// Be sure to set the pp_link field of the allocated page to NULL so
+// page_free can check for double-free bugs.
+//
+// Returns NULL if out of free memory.
+//
+// Hint: use page2kva and memset
+    struct PageInfo *
+page_alloc(int alloc_flags)
+{
+    // Fill this function in
+    if (page_free_list == NULL) return NULL;
+    struct PageInfo* ret = page_free_list;
+    page_free_list = ret->pp_link;
+    if (alloc_flags & ALLOC_ZERO) 
+	memset(page2kva(ret), 0, PGSIZE);
+    ret->pp_link = NULL;
+    return ret;
+}
+
+//
+// Return a page to the free list.
+// (This function should only be called when pp->pp_ref reaches 0.)
+//
+    void
+page_free(struct PageInfo *pp)
+{
+    // Fill this function in
+    // Hint: You may want to panic if pp->pp_ref is nonzero or
+    // pp->pp_link is not NULL.
+    if(pp->pp_ref == 0){
+	pp->pp_link = page_free_list;
+	page_free_list = pp;
+    }
+    else
+    {
+	panic("pp->pp_ref is not zero. Wrong call of the page_free!!!");
+    }
+}
+
+
+//
+// Decrement the reference count on a page,
+// freeing it if there are no more refs.
+//
+    void
+page_decref(struct PageInfo* pp)
+{
+    if (--pp->pp_ref == 0)
+	page_free(pp);
+}
+
+// Given 'pgdir', a pointer to a page directory, pgdir_walk returns
+// a pointer to the page table entry (PTE) for linear address 'va'.
+// This requires walking the two-level page table structure.
+//
+// The relevant page table page might not exist yet.
+// If this is true, and create == false, then pgdir_walk returns NULL.
+// Otherwise, pgdir_walk allocates a new page table page with page_alloc.
+//    - If the allocation fails, pgdir_walk returns NULL.
+//    - Otherwise, the new page's reference count is incremented,
+//	the page is cleared,
+//	and pgdir_walk returns a pointer into the new page table page.
+//
+// Hint 1: you can turn a PageInfo * into the physical address of the
+// page it refers to with page2pa() from kern/pmap.h.
+//
+// Hint 2: the x86 MMU checks permission bits in both the page directory
+// and the page table, so it's safe to leave permissions in the page
+// directory more permissive than strictly necessary.
+//
+// Hint 3: look at inc/mmu.h for useful macros that mainipulate page
+// table and page directory entries.
+//
+    pte_t *
+pgdir_walk(pde_t *pgdir, const void *va, int create)
+{
+    // Fill this function in
+    if (!(pgdir[PDX(va)] & PTE_P)) {
+	if (!create) return NULL;
+	struct PageInfo *page = page_alloc(ALLOC_ZERO);
+	if (!page) return NULL;
+	page->pp_ref = 1;
+	pgdir[PDX(va)] = page2pa(page) | PTE_P | PTE_U | PTE_W;
+    }
+    return KADDR(PTE_ADDR(pgdir[PDX(va)])) + PTX(va) * sizeof(pte_t*);
+}
+
+//
+// Map [va, va+size) of virtual address space to physical [pa, pa+size)
+// in the page table rooted at pgdir.  Size is a multiple of PGSIZE, and
+// va and pa are both page-aligned.
+// Use permission bits perm|PTE_P for the entries.
+//
+// This function is only intended to set up the ``static'' mappings
+// above UTOP. As such, it should *not* change the pp_ref field on the
+// mapped pages.
+//
+// Hint: the TA solution uses pgdir_walk
+    static void
+boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
+{
+    // Fill this function in
+    int i;
+    for (i = 0; i < size; i += PGSIZE) {
+	pte_t *pte = pgdir_walk(pgdir, (void*)(va + i), 1);
+	if (pte) *pte = (pa + i) | perm | PTE_P;
+    }
+}
+
+
+//
+// Map the physical page 'pp' at virtual address 'va'.
+// The permissions (the low 12 bits) of the page table entry
+// should be set to 'perm|PTE_P'.
+//
+// Requirements
+//   - If there is already a page mapped at 'va', it should be page_remove()d.
+//   - If necessary, on demand, a page table should be allocated and inserted
+//     into 'pgdir'.
+//   - pp->pp_ref should be incremented if the insertion succeeds.
+//   - The TLB must be invalidated if a page was formerly present at 'va'.
+//
+// Corner-case hint: Make sure to consider what happens when the same
+// pp is re-inserted at the same virtual address in the same pgdir.
+// However, try not to distinguish this case in your code, as this
+// frequently leads to subtle bugs; there's an elegant way to handle
+// everything in one code path.
+//
+// RETURNS:
+//   0 on success
+//   -E_NO_MEM, if page table couldn't be allocated
+//
+// Hint: The TA solution is implemented using pgdir_walk, page_remove,
+// and page2pa.
+//
+    int
+page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
+{
+    // Fill this function in
+    pte_t *pte = pgdir_walk(pgdir, va, 1);
+    if (pte == NULL) return -E_NO_MEM;
+    if (*pte & PTE_P) {
+	if (PTE_ADDR(*pte) == page2pa(pp)) {
+	    pp->pp_ref--;
+	    tlb_invalidate(pgdir, va);
+	}
+	else {
+	    page_remove(pgdir, va);
+	}
+    }
+    *pte = page2pa(pp) | perm | PTE_P;
+    pp->pp_ref++;
+    return 0;
+}
+
+//
+// Return the page mapped at virtual address 'va'.
+// If pte_store is not zero, then we store in it the address
+// of the pte for this page.  This is used by page_remove and
+// can be used to verify page permissions for syscall arguments,
+// but should not be used by most callers.
+//
+// Return NULL if there is no page mapped at va.
+//
+// Hint: the TA solution uses pgdir_walk and pa2page.
+//
+    struct PageInfo *
+page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
+{
+    // Fill this function in
+    pte_t *pte = pgdir_walk(pgdir, va, 0);
+    if (pte_store != NULL) *pte_store = pte;
+    if (pte == NULL || !(*pte & PTE_P)) return NULL;
+    return pa2page(PTE_ADDR(*pte));
+}
+
+//
+// Unmaps the physical page at virtual address 'va'.
+// If there is no physical page at that address, silently does nothing.
+// 
+// Details:
+//   - The ref count on the physical page should decrement.
+//   - The physical page should be freed if the refcount reaches 0.
+//   - The pg table entry corresponding to 'va' should be set to 0.
+//     (if such a PTE exists)
+//   - The TLB must be invalidated if you remove an entry from
+//     the page table.
+//
+// Hint: The TA solution is implemented using page_lookup,
+// 	tlb_invalidate, and page_decref.
+//
+    void
+page_remove(pde_t *pgdir, void *va)
+{
+    // Fill this function in
+    struct PageInfo *page = page_lookup(pgdir, va, 0);
+    pte_t *pte = pgdir_walk(pgdir, va, 0);
+    if (page != NULL) page_decref(page);
+    if (pte != NULL) {
+	*pte = 0;
+	tlb_invalidate(pgdir, va);
+    }
+}
+
+//
+// Invalidate a TLB entry, but only if the page tables being
+// edited are the ones currently in use by the processor.
+//
+    void
+tlb_invalidate(pde_t *pgdir, void *va)
+{
+    // Flush the entry only if we're modifying the current address space.
+    if (!curenv || curenv->env_pgdir == pgdir)
+	invlpg(va);
+}
+
+//
+// Reserve size bytes in the MMIO region and map [pa,pa+size) at this
+// location.  Return the base of the reserved region.  size does *not*
+// have to be multiple of PGSIZE.
+//
+    void *
+mmio_map_region(physaddr_t pa, size_t size)
+{
+    // Where to start the next region.  Initially, this is the
+    // beginning of the MMIO region.  Because this is static, its
+    // value will be preserved between calls to mmio_map_region
+    // (just like nextfree in boot_alloc).
+    static uintptr_t base = MMIOBASE;
+
+    // Reserve size bytes of virtual memory starting at base and
+    // map physical pages [pa,pa+size) to virtual addresses
+    // [base,base+size).  Since this is device memory and not
+    // regular DRAM, you'll have to tell the CPU that it isn't
+    // safe to cache access to this memory.  Luckily, the page
+    // tables provide bits for this purpose; simply create the
+    // mapping with PTE_PCD|PTE_PWT (cache-disable and
+    // write-through) in addition to PTE_W.  (If you're interested
+    // in more details on this, see section 10.5 of IA32 volume
+    // 3A.)
+    //
+    // Be sure to round size up to a multiple of PGSIZE and to
+    // handle if this reservation would overflow MMIOLIM (it's
+    // okay to simply panic if this happens).
+    //
+    // Hint: The staff solution uses boot_map_region.
+    //
+    // Your code here:
+    size = ROUNDUP(size, PGSIZE);
+    if (base + size > MMIOLIM)
+	panic("mmio_map_region(): out of memory\n");
+    boot_map_region(kern_pgdir, base, size, pa, PTE_PCD | PTE_PWT | PTE_W);
+    base += size;
+    return (void*)(base - size);
+    panic("mmio_map_region not implemented");
+}
+
+static uintptr_t user_mem_check_addr;
+
+//
+// Check that an environment is allowed to access the range of memory
+// [va, va+len) with permissions 'perm | PTE_P'.
+// Normally 'perm' will contain PTE_U at least, but this is not required.
+// 'va' and 'len' need not be page-aligned; you must test every page that
+// contains any of that range.  You will test either 'len/PGSIZE',
+// 'len/PGSIZE + 1', or 'len/PGSIZE + 2' pages.
+//
+// A user program can access a virtual address if (1) the address is below
+// ULIM, and (2) the page table gives it permission.  These are exactly
+// the tests you should implement here.
+//
+// If there is an error, set the 'user_mem_check_addr' variable to the first
+// erroneous virtual address.
+//
+// Returns 0 if the user program can access this range of addresses,
+// and -E_FAULT otherwise.
+//
+    int
+user_mem_check(struct Env *env, const void *va, size_t len, int perm)
+{
+    // LAB 3: Your code here.
+
+    uintptr_t va1 = (uintptr_t)va, va2 = va1 + len;
+    pte_t *pte;
+    for (; va1 < va2; va1 = ROUNDDOWN(va1 + PGSIZE, PGSIZE)) {
+	if (va1 >= ULIM) {
+	    user_mem_check_addr = va1;
+	    return -E_FAULT;
+	}
+	pte = pgdir_walk(env->env_pgdir, (void*)va1, 0);
+	if (pte == NULL||(*pte & (perm | PTE_P)) != (perm | PTE_P)) {
+	    user_mem_check_addr = va1;
+	    return -E_FAULT;
+	}
+    }
+    return 0;
+}
+
+//
+// Checks that environment 'env' is allowed to access the range
+// of memory [va, va+len) with permissions 'perm | PTE_U | PTE_P'.
+// If it can, then the function simply returns.
+// If it cannot, 'env' is destroyed and, if env is the current
+// environment, this function will not return.
+//
+    void
+user_mem_assert(struct Env *env, const void *va, size_t len, int perm)
+{
+    if (user_mem_check(env, va, len, perm | PTE_U) < 0) {
+	cprintf("[%08x] user_mem_check assertion failure for "
+		"va %08x\n", env->env_id, user_mem_check_addr);
+	env_destroy(env);	// may not return
+    }
+}
+
+
+// --------------------------------------------------------------
+// Checking functions.
+// --------------------------------------------------------------
+
+//
+// Check that the pages on the page_free_list are reasonable.
+//
+    static void
+check_page_free_list(bool only_low_memory)
+{
+    struct PageInfo *pp;
+    unsigned pdx_limit = only_low_memory ? 1 : NPDENTRIES;
+    int nfree_basemem = 0, nfree_extmem = 0;
+    char *first_free_page;
+
+    if (!page_free_list)
+	panic("'page_free_list' is a null pointer!");
+
+    if (only_low_memory) {
+	// Move pages with lower addresses first in the free
+	// list, since entry_pgdir does not map all pages.
+	struct PageInfo *pp1, *pp2;
+	struct PageInfo **tp[2] = { &pp1, &pp2 };
+	for (pp = page_free_list; pp; pp = pp->pp_link) {
+	    int pagetype = PDX(page2pa(pp)) >= pdx_limit;
+	    *tp[pagetype] = pp;
+	    tp[pagetype] = &pp->pp_link;
+	}
+	*tp[1] = 0;
+	*tp[0] = pp2;
+	page_free_list = pp1;
+    }
+
+    // if there's a page that shouldn't be on the free list,
+    // try to make sure it eventually causes trouble.
+    for (pp = page_free_list; pp; pp = pp->pp_link)
+	if (PDX(page2pa(pp)) < pdx_limit)
+	    memset(page2kva(pp), 0x97, 128);
+
+    first_free_page = (char *) boot_alloc(0);
+    for (pp = page_free_list; pp; pp = pp->pp_link) {
+	// check that we didn't corrupt the free list itself
+	assert(pp >= pages);
+	assert(pp < pages + npages);
+	assert(((char *) pp - (char *) pages) % sizeof(*pp) == 0);
+
+	// check a few pages that shouldn't be on the free list
+	assert(page2pa(pp) != 0);
+	assert(page2pa(pp) != IOPHYSMEM);
+	assert(page2pa(pp) != EXTPHYSMEM - PGSIZE);
+	assert(page2pa(pp) != EXTPHYSMEM);
+	assert(page2pa(pp) < EXTPHYSMEM || (char *) page2kva(pp) >= first_free_page);
+	// (new test for lab 4)
+	assert(page2pa(pp) != MPENTRY_PADDR);
+
+	if (page2pa(pp) < EXTPHYSMEM)
+	    ++nfree_basemem;
+	else
+	    ++nfree_extmem;
+    }
+    assert(nfree_basemem > 0);
+    assert(nfree_extmem > 0);
+
+    cprintf("check_page_free_list() succeeded!\n");
+}
+
+//
+// Check the physical page allocator (page_alloc(), page_free(),
+// and page_init()).
+//
+    static void
+check_page_alloc(void)
+{
+    struct PageInfo *pp, *pp0, *pp1, *pp2;
+    int nfree;
+    struct PageInfo *fl;
+    char *c;
+    int i;
+
+    if (!pages)
+	panic("'pages' is a null pointer!");
+
+    // check number of free pages
+    for (pp = page_free_list, nfree = 0; pp; pp = pp->pp_link)
+	++nfree;
+
+    // should be able to allocate three pages
+    pp0 = pp1 = pp2 = 0;
+    assert((pp0 = page_alloc(0)));
+    assert((pp1 = page_alloc(0)));
+    assert((pp2 = page_alloc(0)));
+
+    assert(pp0);
+    assert(pp1 && pp1 != pp0);
+    assert(pp2 && pp2 != pp1 && pp2 != pp0);
+    assert(page2pa(pp0) < npages*PGSIZE);
+    assert(page2pa(pp1) < npages*PGSIZE);
+    assert(page2pa(pp2) < npages*PGSIZE);
+
+    // temporarily steal the rest of the free pages
+    fl = page_free_list;
+    page_free_list = 0;
+
+    // should be no free memory
+    assert(!page_alloc(0));
+
+    // free and re-allocate?
+    page_free(pp0);
+    page_free(pp1);
+    page_free(pp2);
+    pp0 = pp1 = pp2 = 0;
+    assert((pp0 = page_alloc(0)));
+    assert((pp1 = page_alloc(0)));
+    assert((pp2 = page_alloc(0)));
+    assert(pp0);
+    assert(pp1 && pp1 != pp0);
+    assert(pp2 && pp2 != pp1 && pp2 != pp0);
+    assert(!page_alloc(0));
+
+    // test flags
+    memset(page2kva(pp0), 1, PGSIZE);
+    page_free(pp0);
+    assert((pp = page_alloc(ALLOC_ZERO)));
+    assert(pp && pp0 == pp);
+    c = page2kva(pp);
+    for (i = 0; i < PGSIZE; i++)
+	assert(c[i] == 0);
+
+    // give free list back
+    page_free_list = fl;
+
+    // free the pages we took
+    page_free(pp0);
+    page_free(pp1);
+    page_free(pp2);
+
+    // number of free pages should be the same
+    for (pp = page_free_list; pp; pp = pp->pp_link)
+	--nfree;
+    assert(nfree == 0);
+
+    cprintf("check_page_alloc() succeeded!\n");
+}
+
+//
+// Checks that the kernel part of virtual address space
+// has been setup roughly correctly (by mem_init()).
+//
+// This function doesn't test every corner case,
+// but it is a pretty good sanity check.
+//
+
+    static void
+check_kern_pgdir(void)
+{
+    uint32_t i, n;
+    pde_t *pgdir;
+
+    pgdir = kern_pgdir;
+
+    // check pages array
+    n = ROUNDUP(npages*sizeof(struct PageInfo), PGSIZE);
+    for (i = 0; i < n; i += PGSIZE)
+	assert(check_va2pa(pgdir, UPAGES + i) == PADDR(pages) + i);
+
+    // check envs array (new test for lab 3)
+    n = ROUNDUP(NENV*sizeof(struct Env), PGSIZE);
+    for (i = 0; i < n; i += PGSIZE)
+	assert(check_va2pa(pgdir, UENVS + i) == PADDR(envs) + i);
+
+    // check phys mem
+    for (i = 0; i < npages * PGSIZE; i += PGSIZE)
+	assert(check_va2pa(pgdir, KERNBASE + i) == i);
+
+    // check kernel stack
+    // (updated in lab 4 to check per-CPU kernel stacks)
+    for (n = 0; n < NCPU; n++) {
+	uint32_t base = KSTACKTOP - (KSTKSIZE + KSTKGAP) * (n + 1);
+	for (i = 0; i < KSTKSIZE; i += PGSIZE)
+	    assert(check_va2pa(pgdir, base + KSTKGAP + i)
+		    == PADDR(percpu_kstacks[n]) + i);
+	for (i = 0; i < KSTKGAP; i += PGSIZE)
+	    assert(check_va2pa(pgdir, base + i) == ~0);
+    }
+
+    // check PDE permissions
+    for (i = 0; i < NPDENTRIES; i++) {
+	switch (i) {
+	    case PDX(UVPT):
+	    case PDX(KSTACKTOP-1):
+	    case PDX(UPAGES):
+	    case PDX(UENVS):
+	    case PDX(MMIOBASE):
+		assert(pgdir[i] & PTE_P);
+		break;
+	    default:
+		if (i >= PDX(KERNBASE)) {
+		    assert(pgdir[i] & PTE_P);
+		    assert(pgdir[i] & PTE_W);
+		} else
+		    assert(pgdir[i] == 0);
+		break;
+	}
+    }
+    cprintf("check_kern_pgdir() succeeded!\n");
+}
+
+// This function returns the physical address of the page containing 'va',
+// defined by the page directory 'pgdir'.  The hardware normally performs
+// this functionality for us!  We define our own version to help check
+// the check_kern_pgdir() function; it shouldn't be used elsewhere.
+
+    static physaddr_t
+check_va2pa(pde_t *pgdir, uintptr_t va)
+{
+    pte_t *p;
+
+    pgdir = &pgdir[PDX(va)];
+    if (!(*pgdir & PTE_P))
+	return ~0;
+    p = (pte_t*) KADDR(PTE_ADDR(*pgdir));
+    if (!(p[PTX(va)] & PTE_P))
+	return ~0;
+    return PTE_ADDR(p[PTX(va)]);
+}
+
+
+// check page_insert, page_remove, &c
+    static void
+check_page(void)
+{
+    struct PageInfo *pp, *pp0, *pp1, *pp2;
+    struct PageInfo *fl;
+    pte_t *ptep, *ptep1;
+    void *va;
+    uintptr_t mm1, mm2;
+    int i;
+    extern pde_t entry_pgdir[];
+
+    // should be able to allocate three pages
+    pp0 = pp1 = pp2 = 0;
+    assert((pp0 = page_alloc(0)));
+    assert((pp1 = page_alloc(0)));
+    assert((pp2 = page_alloc(0)));
+
+    assert(pp0);
+    assert(pp1 && pp1 != pp0);
+    assert(pp2 && pp2 != pp1 && pp2 != pp0);
+
+    // temporarily steal the rest of the free pages
+    fl = page_free_list;
+    page_free_list = 0;
+
+    // should be no free memory
+    assert(!page_alloc(0));
+
+    // there is no page allocated at address 0
+    assert(page_lookup(kern_pgdir, (void *) 0x0, &ptep) == NULL);
+
+    // there is no free memory, so we can't allocate a page table
+    assert(page_insert(kern_pgdir, pp1, 0x0, PTE_W) < 0);
+
+    // free pp0 and try again: pp0 should be used for page table
+    page_free(pp0);
+    assert(page_insert(kern_pgdir, pp1, 0x0, PTE_W) == 0);
+    assert(PTE_ADDR(kern_pgdir[0]) == page2pa(pp0));
+    assert(check_va2pa(kern_pgdir, 0x0) == page2pa(pp1));
+    assert(pp1->pp_ref == 1);
+    assert(pp0->pp_ref == 1);
+
+    // should be able to map pp2 at PGSIZE because pp0 is already allocated for page table
+    assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W) == 0);
+    assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp2));
+    assert(pp2->pp_ref == 1);
+
+    // should be no free memory
+    assert(!page_alloc(0));
+
+    // should be able to map pp2 at PGSIZE because it's already there
+    assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W) == 0);
+    assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp2));
+    assert(pp2->pp_ref == 1);
+
+    // pp2 should NOT be on the free list
+    // could happen in ref counts are handled sloppily in page_insert
+    assert(!page_alloc(0));
+
+    // check that pgdir_walk returns a pointer to the pte
+    ptep = (pte_t *) KADDR(PTE_ADDR(kern_pgdir[PDX(PGSIZE)]));
+    assert(pgdir_walk(kern_pgdir, (void*)PGSIZE, 0) == ptep+PTX(PGSIZE));
+
+    // should be able to change permissions too.
+    assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W|PTE_U) == 0);
+    assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp2));
+    assert(pp2->pp_ref == 1);
+    assert(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_U);
+    assert(kern_pgdir[0] & PTE_U);
+
+    // should be able to remap with fewer permissions
+    assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W) == 0);
+    assert(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_W);
+    assert(!(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_U));
+
+    // should not be able to map at PTSIZE because need free page for page table
+    assert(page_insert(kern_pgdir, pp0, (void*) PTSIZE, PTE_W) < 0);
+
+    // insert pp1 at PGSIZE (replacing pp2)
+    assert(page_insert(kern_pgdir, pp1, (void*) PGSIZE, PTE_W) == 0);
+    assert(!(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_U));
+
+    // should have pp1 at both 0 and PGSIZE, pp2 nowhere, ...
+    assert(check_va2pa(kern_pgdir, 0) == page2pa(pp1));
+    assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp1));
+    // ... and ref counts should reflect this
+    assert(pp1->pp_ref == 2);
+    assert(pp2->pp_ref == 0);
+
+    // pp2 should be returned by page_alloc
+    assert((pp = page_alloc(0)) && pp == pp2);
+
+    // unmapping pp1 at 0 should keep pp1 at PGSIZE
+    page_remove(kern_pgdir, 0x0);
+    assert(check_va2pa(kern_pgdir, 0x0) == ~0);
+    assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp1));
+    assert(pp1->pp_ref == 1);
+    assert(pp2->pp_ref == 0);
+
+    // test re-inserting pp1 at PGSIZE
+    assert(page_insert(kern_pgdir, pp1, (void*) PGSIZE, 0) == 0);
+    assert(pp1->pp_ref);
+    assert(pp1->pp_link == NULL);
+
+    // unmapping pp1 at PGSIZE should free it
+    page_remove(kern_pgdir, (void*) PGSIZE);
+    assert(check_va2pa(kern_pgdir, 0x0) == ~0);
+    assert(check_va2pa(kern_pgdir, PGSIZE) == ~0);
+    assert(pp1->pp_ref == 0);
+    assert(pp2->pp_ref == 0);
+
+    // so it should be returned by page_alloc
+    assert((pp = page_alloc(0)) && pp == pp1);
+
+    // should be no free memory
+    assert(!page_alloc(0));
+
+    // forcibly take pp0 back
+    assert(PTE_ADDR(kern_pgdir[0]) == page2pa(pp0));
+    kern_pgdir[0] = 0;
+    assert(pp0->pp_ref == 1);
+    pp0->pp_ref = 0;
+
+    // check pointer arithmetic in pgdir_walk
+    page_free(pp0);
+    va = (void*)(PGSIZE * NPDENTRIES + PGSIZE);
+    ptep = pgdir_walk(kern_pgdir, va, 1);
+    ptep1 = (pte_t *) KADDR(PTE_ADDR(kern_pgdir[PDX(va)]));
+    assert(ptep == ptep1 + PTX(va));
+    kern_pgdir[PDX(va)] = 0;
+    pp0->pp_ref = 0;
+
+    // check that new page tables get cleared
+    memset(page2kva(pp0), 0xFF, PGSIZE);
+    page_free(pp0);
+    pgdir_walk(kern_pgdir, 0x0, 1);
+    ptep = (pte_t *) page2kva(pp0);
+    for(i=0; i<NPTENTRIES; i++)
+	assert((ptep[i] & PTE_P) == 0);
+    kern_pgdir[0] = 0;
+    pp0->pp_ref = 0;
+
+    // give free list back
+    page_free_list = fl;
+
+    // free the pages we took
+    page_free(pp0);
+    page_free(pp1);
+    page_free(pp2);
+
+    // test mmio_map_region
+    mm1 = (uintptr_t) mmio_map_region(0, 4097);
+    mm2 = (uintptr_t) mmio_map_region(0, 4096);
+    // check that they're in the right region
+    assert(mm1 >= MMIOBASE && mm1 + 8096 < MMIOLIM);
+    assert(mm2 >= MMIOBASE && mm2 + 8096 < MMIOLIM);
+    // check that they're page-aligned
+    assert(mm1 % PGSIZE == 0 && mm2 % PGSIZE == 0);
+    // check that they don't overlap
+    assert(mm1 + 8096 <= mm2);
+    // check page mappings
+    assert(check_va2pa(kern_pgdir, mm1) == 0);
+    assert(check_va2pa(kern_pgdir, mm1+PGSIZE) == PGSIZE);
+    assert(check_va2pa(kern_pgdir, mm2) == 0);
+    assert(check_va2pa(kern_pgdir, mm2+PGSIZE) == ~0);
+    // check permissions
+    assert(*pgdir_walk(kern_pgdir, (void*) mm1, 0) & (PTE_W|PTE_PWT|PTE_PCD));
+    assert(!(*pgdir_walk(kern_pgdir, (void*) mm1, 0) & PTE_U));
+    // clear the mappings
+    *pgdir_walk(kern_pgdir, (void*) mm1, 0) = 0;
+    *pgdir_walk(kern_pgdir, (void*) mm1 + PGSIZE, 0) = 0;
+    *pgdir_walk(kern_pgdir, (void*) mm2, 0) = 0;
+
+    cprintf("check_page() succeeded!\n");
+}
+
+// check page_insert, page_remove, &c, with an installed kern_pgdir
+    static void
+check_page_installed_pgdir(void)
+{
+    struct PageInfo *pp, *pp0, *pp1, *pp2;
+    struct PageInfo *fl;
+    pte_t *ptep, *ptep1;
+    uintptr_t va;
+    int i;
+
+    // check that we can read and write installed pages
+    pp1 = pp2 = 0;
+    assert((pp0 = page_alloc(0)));
+    assert((pp1 = page_alloc(0)));
+    assert((pp2 = page_alloc(0)));
+    page_free(pp0);
+    memset(page2kva(pp1), 1, PGSIZE);
+    memset(page2kva(pp2), 2, PGSIZE);
+    page_insert(kern_pgdir, pp1, (void*) PGSIZE, PTE_W);
+    assert(pp1->pp_ref == 1);
+    assert(*(uint32_t *)PGSIZE == 0x01010101U);
+    page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W);
+    assert(*(uint32_t *)PGSIZE == 0x02020202U);
+    assert(pp2->pp_ref == 1);
+    assert(pp1->pp_ref == 0);
+    *(uint32_t *)PGSIZE = 0x03030303U;
+    assert(*(uint32_t *)page2kva(pp2) == 0x03030303U);
+    page_remove(kern_pgdir, (void*) PGSIZE);
+    assert(pp2->pp_ref == 0);
+
+    // forcibly take pp0 back
+    assert(PTE_ADDR(kern_pgdir[0]) == page2pa(pp0));
+    kern_pgdir[0] = 0;
+    assert(pp0->pp_ref == 1);
+    pp0->pp_ref = 0;
+
+    // free the pages we took
+    page_free(pp0);
+
+    cprintf("check_page_installed_pgdir() succeeded!\n");
+}
diff --git a/kern.old/pmap.h b/kern.old/pmap.h
new file mode 100755
index 0000000..428087e
--- /dev/null
+++ b/kern.old/pmap.h
@@ -0,0 +1,93 @@
+/* See COPYRIGHT for copyright information. */
+
+#ifndef JOS_KERN_PMAP_H
+#define JOS_KERN_PMAP_H
+#ifndef JOS_KERNEL
+# error "This is a JOS kernel header; user programs should not #include it"
+#endif
+
+#include <inc/memlayout.h>
+#include <inc/assert.h>
+struct Env;
+
+extern char bootstacktop[], bootstack[];
+
+extern struct PageInfo *pages;
+extern size_t npages;
+
+extern pde_t *kern_pgdir;
+
+
+/* This macro takes a kernel virtual address -- an address that points above
+ * KERNBASE, where the machine's maximum 256MB of physical memory is mapped --
+ * and returns the corresponding physical address.  It panics if you pass it a
+ * non-kernel virtual address.
+ */
+#define PADDR(kva) _paddr(__FILE__, __LINE__, kva)
+
+static inline physaddr_t
+_paddr(const char *file, int line, void *kva)
+{
+	if ((uint32_t)kva < KERNBASE)
+		_panic(file, line, "PADDR called with invalid kva %08lx", kva);
+	return (physaddr_t)kva - KERNBASE;
+}
+
+/* This macro takes a physical address and returns the corresponding kernel
+ * virtual address.  It panics if you pass an invalid physical address. */
+#define KADDR(pa) _kaddr(__FILE__, __LINE__, pa)
+
+static inline void*
+_kaddr(const char *file, int line, physaddr_t pa)
+{
+	if (PGNUM(pa) >= npages)
+		_panic(file, line, "KADDR called with invalid pa %08lx", pa);
+	return (void *)(pa + KERNBASE);
+}
+
+
+enum {
+	// For page_alloc, zero the returned physical page.
+	ALLOC_ZERO = 1<<0,
+};
+
+void	mem_init(void);
+
+void	page_init(void);
+struct PageInfo *page_alloc(int alloc_flags);
+void	page_free(struct PageInfo *pp);
+int	page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm);
+void	page_remove(pde_t *pgdir, void *va);
+struct PageInfo *page_lookup(pde_t *pgdir, void *va, pte_t **pte_store);
+void	page_decref(struct PageInfo *pp);
+
+void	tlb_invalidate(pde_t *pgdir, void *va);
+
+void *	mmio_map_region(physaddr_t pa, size_t size);
+
+int	user_mem_check(struct Env *env, const void *va, size_t len, int perm);
+void	user_mem_assert(struct Env *env, const void *va, size_t len, int perm);
+
+static inline physaddr_t
+page2pa(struct PageInfo *pp)
+{
+	return (pp - pages) << PGSHIFT;
+}
+
+static inline struct PageInfo*
+pa2page(physaddr_t pa)
+{
+	if (PGNUM(pa) >= npages)
+		panic("pa2page called with invalid pa");
+	return &pages[PGNUM(pa)];
+}
+
+static inline void*
+page2kva(struct PageInfo *pp)
+{
+	return KADDR(page2pa(pp));
+}
+
+pte_t *pgdir_walk(pde_t *pgdir, const void *va, int create);
+
+#endif /* !JOS_KERN_PMAP_H */
diff --git a/kern.old/printf.c b/kern.old/printf.c
new file mode 100755
index 0000000..dffcc24
--- /dev/null
+++ b/kern.old/printf.c
@@ -0,0 +1,40 @@
+// Simple implementation of cprintf console output for the kernel,
+// based on printfmt() and the kernel console's cputchar().
+
+#include <inc/types.h>
+#include <inc/stdio.h>
+#include <inc/stdarg.h>
+#include <kern/spinlock.h>
+
+
+static void
+putch(int ch, int *cnt)
+{
+	cputchar(ch);
+	*cnt++;
+}
+
+int
+vcprintf(const char *fmt, va_list ap)
+{
+	int cnt = 0;
+
+	lock(&console_lock);
+	vprintfmt((void*)putch, &cnt, fmt, ap);
+	unlock(&console_lock);
+	return cnt;
+}
+
+int
+cprintf(const char *fmt, ...)
+{
+	va_list ap;
+	int cnt;
+
+	va_start(ap, fmt);
+	cnt = vcprintf(fmt, ap);
+	va_end(ap);
+
+	return cnt;
+}
+
diff --git a/kern.old/sched.c b/kern.old/sched.c
new file mode 100755
index 0000000..2175d9e
--- /dev/null
+++ b/kern.old/sched.c
@@ -0,0 +1,104 @@
+#include <inc/assert.h>
+#include <inc/x86.h>
+#include <kern/spinlock.h>
+#include <kern/env.h>
+#include <kern/pmap.h>
+#include <kern/monitor.h>
+#include <kern/cpu.h>
+
+void sched_halt(void);
+
+// Choose a user environment to run and run it.
+    void
+sched_yield(void)
+{
+    struct Env *idle;
+
+    // Implement simple round-robin scheduling.
+    //
+    // Search through 'envs' for an ENV_RUNNABLE environment in
+    // circular fashion starting just after the env this CPU was
+    // last running.  Switch to the first such environment found.
+    //
+    // If no envs are runnable, but the environment previously
+    // running on this CPU is still ENV_RUNNING, it's okay to
+    // choose that environment.
+    //
+    // Never choose an environment that's currently running on
+    // another CPU (env_status == ENV_RUNNING). If there are
+    // no runnable environments, simply drop through to the code
+    // below to halt the cpu.
+    // LAB 4: Your code here.
+    int i;
+    idle = (curenv ? curenv + 1 : envs);
+
+    for (i = 0; i < NENV; i += 1, idle += 1)
+    {
+	if (idle >= envs + NENV) idle = envs;
+	lock(&idle->lock);
+	if (!idle->env_in_kernel && idle->env_status == ENV_RUNNABLE) 
+	    env_run(idle);
+	unlock(&idle->lock);
+    }
+    if (curenv != NULL) {
+	if(curenv->env_status==ENV_RUNNING)
+	    env_run(curenv);
+    }
+    // sched_halt never returns
+    sched_halt();
+}
+
+// Halt this CPU when there is nothing to do. Wait until the
+// timer interrupt wakes it up. This function never returns.
+//
+    void
+sched_halt(void)
+{
+    int i;
+
+    // For debugging and testing purposes, if there are no runnable
+    // environments in the system, then drop into the kernel monitor.
+    for (i = 0; i < NENV; i++) {
+	lock(&envs[i].lock);
+	if ((envs[i].env_status == ENV_RUNNABLE ||
+		    envs[i].env_status == ENV_RUNNING ||
+		    envs[i].env_status == ENV_DYING))
+	    break;
+	unlock(&envs[i].lock);
+    }
+    if (i == NENV) {
+	cprintf("No runnable environments in the system!\n");
+	while (1)
+	    monitor(NULL);
+    }
+    else {
+	unlock(&envs[i].lock);
+    }
+
+    // Mark that no environment is running on this CPU
+    if (curenv) {
+	curenv->env_in_kernel = 0;
+	curenv = NULL;
+    }
+    lcr3(PADDR(kern_pgdir));
+
+    // Mark that this CPU is in the HALT state, so that when
+    // timer interupts come in, we know we should re-acquire the
+    // big kernel lock
+    xchg(&thiscpu->cpu_status, CPU_HALTED);
+
+    // Release the big kernel lock as if we were "leaving" the kernel
+
+    // Reset stack pointer, enable interrupts and then halt.
+    asm volatile (
+	    "movl $0, %%ebp\n"
+	    "movl %0, %%esp\n"
+	    "pushl $0\n"
+	    "pushl $0\n"
+	    "sti\n"
+	    "1:\n"
+	    "hlt\n"
+	    "jmp 1b\n"
+	    : : "a" (thiscpu->cpu_ts.ts_esp0));
+}
+
diff --git a/kern.old/sched.h b/kern.old/sched.h
new file mode 100755
index 0000000..754f6a0
--- /dev/null
+++ b/kern.old/sched.h
@@ -0,0 +1,12 @@
+/* See COPYRIGHT for copyright information. */
+
+#ifndef JOS_KERN_SCHED_H
+#define JOS_KERN_SCHED_H
+#ifndef JOS_KERNEL
+# error "This is a JOS kernel header; user programs should not #include it"
+#endif
+
+// This function does not return.
+void sched_yield(void) __attribute__((noreturn));
+
+#endif	// !JOS_KERN_SCHED_H
diff --git a/kern.old/spinlock.c b/kern.old/spinlock.c
new file mode 100755
index 0000000..4fee645
--- /dev/null
+++ b/kern.old/spinlock.c
@@ -0,0 +1,120 @@
+// Mutual exclusion spin locks.
+
+#include <inc/types.h>
+#include <inc/assert.h>
+#include <inc/x86.h>
+#include <inc/memlayout.h>
+#include <inc/string.h>
+#include <kern/cpu.h>
+#include <kern/spinlock.h>
+#include <kern/kdebug.h>
+
+// The big kernel lock
+struct spinlock kernel_lock = {
+#ifdef DEBUG_SPINLOCK
+    .name = "kernel_lock"
+#endif
+};
+
+//Challenge
+struct spinlock page_lock, console_lock, env_lock, monitor_lock;
+
+#ifdef DEBUG_SPINLOCK
+// Record the current call stack in pcs[] by following the %ebp chain.
+    static void
+get_caller_pcs(uint32_t pcs[])
+{
+    uint32_t *ebp;
+    int i;
+
+    ebp = (uint32_t *)read_ebp();
+    for (i = 0; i < 10; i++){
+	if (ebp == 0 || ebp < (uint32_t *)ULIM)
+	    break;
+	pcs[i] = ebp[1];          // saved %eip
+	ebp = (uint32_t *)ebp[0]; // saved %ebp
+    }
+    for (; i < 10; i++)
+	pcs[i] = 0;
+}
+
+// Check whether this CPU is holding the lock.
+    static int
+holding(struct spinlock *lock)
+{
+    return lock->locked && lock->cpu == thiscpu;
+}
+#endif
+
+    void
+__spin_initlock(struct spinlock *lk, char *name)
+{
+    lk->locked = 0;
+#ifdef DEBUG_SPINLOCK
+    lk->name = name;
+    lk->cpu = 0;
+#endif
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+// Holding a lock for a long time may cause
+// other CPUs to waste time spinning to acquire it.
+    void
+spin_lock(struct spinlock *lk)
+{
+#ifdef DEBUG_SPINLOCK
+    if (holding(lk))
+	panic("CPU %d cannot acquire %s: already holding", cpunum(), lk->name);
+#endif
+
+    // The xchg is atomic.
+    // It also serializes, so that reads after acquire are not
+    // reordered before it. 
+    while (xchg(&lk->locked, 1) != 0)
+	asm volatile ("pause");
+
+    // Record info about lock acquisition for debugging.
+#ifdef DEBUG_SPINLOCK
+    lk->cpu = thiscpu;
+    get_caller_pcs(lk->pcs);
+#endif
+}
+
+// Release the lock.
+    void
+spin_unlock(struct spinlock *lk)
+{
+#ifdef DEBUG_SPINLOCK
+    if (!holding(lk)) {
+	int i;
+	uint32_t pcs[10];
+	// Nab the acquiring EIP chain before it gets released
+	memmove(pcs, lk->pcs, sizeof pcs);
+	cprintf("CPU %d cannot release %s: held by CPU %d\nAcquired at:", 
+		cpunum(), lk->name, lk->cpu->cpu_id);
+	for (i = 0; i < 10 && pcs[i]; i++) {
+	    struct Eipdebuginfo info;
+	    if (debuginfo_eip(pcs[i], &info) >= 0)
+		cprintf("  %08x %s:%d: %.*s+%x\n", pcs[i],
+			info.eip_file, info.eip_line,
+			info.eip_fn_namelen, info.eip_fn_name,
+			pcs[i] - info.eip_fn_addr);
+	    else
+		cprintf("  %08x\n", pcs[i]);
+	}
+	panic("spin_unlock");
+    }
+
+    lk->pcs[0] = 0;
+    lk->cpu = 0;
+#endif
+
+    // The xchg instruction is atomic (i.e. uses the "lock" prefix) with
+    // respect to any other instruction which references the same memory.
+    // x86 CPUs will not reorder loads/stores across locked instructions
+    // (vol 3, 8.2.2). Because xchg() is implemented using asm volatile,
+    // gcc will not reorder C statements across the xchg.
+    xchg(&lk->locked, 0);
+}
+
diff --git a/kern.old/spinlock.h b/kern.old/spinlock.h
new file mode 100755
index 0000000..81414a4
--- /dev/null
+++ b/kern.old/spinlock.h
@@ -0,0 +1,63 @@
+#ifndef JOS_INC_SPINLOCK_H
+#define JOS_INC_SPINLOCK_H
+
+#include <inc/types.h>
+
+// Comment this to disable spinlock debugging
+//#define DEBUG_SPINLOCK
+
+// Mutual exclusion lock.
+struct spinlock {
+    unsigned locked;       // Is the lock held?
+
+#ifdef DEBUG_SPINLOCK
+    // For debugging:
+    char *name;            // Name of lock.
+    struct CpuInfo *cpu;   // The CPU holding the lock.
+    uintptr_t pcs[10];     // The call stack (an array of program counters)
+    // that locked the lock.
+#endif
+};
+
+void __spin_initlock(struct spinlock *lk, char *name);
+void spin_lock(struct spinlock *lk);
+void spin_unlock(struct spinlock *lk);
+
+#define spin_initlock(lock)   __spin_initlock(lock, #lock)
+
+extern struct spinlock kernel_lock;
+
+//Challenge
+extern struct spinlock page_lock, console_lock, env_lock, monitor_lock;
+
+static inline void lock(struct spinlock* spl)
+{
+    spin_lock(spl);
+}
+
+static inline void unlock(struct spinlock* spl)
+{
+    spin_unlock(spl);
+    asm volatile("pause");
+}
+//Challenge
+
+    static inline void
+lock_kernel(void)
+{
+    spin_lock(&kernel_lock);
+}
+
+    static inline void
+unlock_kernel(void)
+{
+    spin_unlock(&kernel_lock);
+
+    // Normally we wouldn't need to do this, but QEMU only runs
+    // one CPU at a time and has a long time-slice.  Without the
+    // pause, this CPU is likely to reacquire the lock before
+    // another CPU has even been given a chance to acquire it.
+    asm volatile("pause");
+}
+
+#endif
diff --git a/kern.old/syscall.c b/kern.old/syscall.c
new file mode 100755
index 0000000..cc65bd7
--- /dev/null
+++ b/kern.old/syscall.c
@@ -0,0 +1,485 @@
+/* See COPYRIGHT for copyright information. */
+
+#include <inc/x86.h>
+#include <inc/error.h>
+#include <inc/string.h>
+#include <inc/assert.h>
+
+#include <kern/env.h>
+#include <kern/pmap.h>
+#include <kern/trap.h>
+#include <kern/syscall.h>
+#include <kern/console.h>
+#include <kern/sched.h>
+#include <kern/spinlock.h>
+
+// Print a string to the system console.
+// The string is exactly 'len' characters long.
+// Destroys the environment on memory errors.
+    static void
+sys_cputs(const char *s, size_t len)
+{
+    // Check that the user has permission to read memory [s, s+len).
+    // Destroy the environment if not.
+
+    // LAB 3: Your code here.
+    lock(&curenv->lock);
+    if (curenv->env_tf.tf_cs & 3)
+	user_mem_assert(curenv, s, len, 0);
+    unlock(&curenv->lock);
+
+    // Print the string supplied by the user.
+    cprintf("%.*s", len, s);
+}
+
+// Read a character from the system console without blocking.
+// Returns the character, or 0 if there is no input waiting.
+    static int
+sys_cgetc(void)
+{
+    lock(&console_lock);
+    int c = cons_getc();
+    unlock(&console_lock);
+    return c;
+}
+
+// Returns the current environment's envid.
+    static envid_t
+sys_getenvid(void)
+{
+    lock(&curenv->lock);
+    envid_t id = curenv->env_id;
+    unlock(&curenv->lock);
+    return id;
+}
+
+// Destroy a given environment (possibly the currently running environment).
+//
+// Returns 0 on success, < 0 on error.  Errors are:
+//	-E_BAD_ENV if environment envid doesn't currently exist,
+//		or the caller doesn't have permission to change envid.
+    static int
+sys_env_destroy(envid_t envid)
+{
+    int r;
+    struct Env *e;
+
+    if ((r = envid2env(envid, &e, 1)) < 0)
+		return r;
+    if (e == curenv)
+		cprintf("[%08x] exiting gracefully\n", curenv->env_id);
+    else
+		cprintf("[%08x] destroying %08x\n", curenv->env_id, e->env_id);
+    env_destroy(e);
+    unlock(&e->lock);
+    return 0;
+}
+
+// Deschedule current environment and pick a different one to run.
+    static void
+sys_yield(void)
+{
+    sched_yield();
+}
+
+// Allocate a new environment.
+// Returns envid of new environment, or < 0 on error.  Errors are:
+//	-E_NO_FREE_ENV if no free environment is available.
+//	-E_NO_MEM on memory exhaustion.
+    envid_t
+sys_exofork(void)
+{
+    // Create the new environment with env_alloc(), from kern/env.c.
+    // It should be left as env_alloc created it, except that
+    // status is set to ENV_NOT_RUNNABLE, and the register set is copied
+    // from the current environment -- but tweaked so sys_exofork
+    // will appear to return 0.
+
+    // LAB 4: Your code here.
+    struct Env *e = NULL;
+    if (env_alloc(&e, curenv->env_id) == -E_NO_FREE_ENV) return -E_NO_FREE_ENV;
+    memcpy(&e->env_tf, &curenv->env_tf, sizeof(e->env_tf));
+    e->env_tf.tf_regs.reg_eax = 0;
+    e->env_status = ENV_NOT_RUNNABLE;
+    envid_t id = e->env_id;
+    unlock(&e->lock);
+    return id;
+}
+
+// Set envid's env_status to status, which must be ENV_RUNNABLE
+// or ENV_NOT_RUNNABLE.
+//
+// Returns 0 on success, < 0 on error.  Errors are:
+//	-E_BAD_ENV if environment envid doesn't currently exist,
+//		or the caller doesn't have permission to change envid.
+//	-E_INVAL if status is not a valid status for an environment.
+    static int
+sys_env_set_status(envid_t envid, int status)
+{
+    // Hint: Use the 'envid2env' function from kern/env.c to translate an
+    // envid to a struct Env.
+    // You should set envid2env's third argument to 1, which will
+    // check whether the current environment has permission to set
+    // envid's status.
+
+    // LAB 4: Your code here.
+    struct Env *e;
+    if (envid2env(envid, &e, 1) == -E_BAD_ENV) return -E_BAD_ENV;
+    if (status != ENV_RUNNABLE && status != ENV_NOT_RUNNABLE) {
+	unlock(&e->lock);
+	return -E_INVAL;
+    }
+    e->env_status = status;
+    unlock(&e->lock);
+    return 0;
+
+}
+
+// Set envid's trap frame to 'tf'.
+// tf is modified to make sure that user environments always run at code
+// protection level 3 (CPL 3) with interrupts enabled.
+//
+// Returns 0 on success, < 0 on error.  Errors are:
+//	-E_BAD_ENV if environment envid doesn't currently exist,
+//		or the caller doesn't have permission to change envid.
+static int
+sys_env_set_trapframe(envid_t envid, struct Trapframe *tf)
+{
+	// LAB 5: Your code here.
+	// Remember to check whether the user has supplied us with a good
+	// address!
+	panic("sys_env_set_trapframe not implemented");
+}
+
+// Set the page fault upcall for 'envid' by modifying the corresponding struct
+// Env's 'env_pgfault_upcall' field.  When 'envid' causes a page fault, the
+// kernel will push a fault record onto the exception stack, then branch to
+// 'func'.
+//
+// Returns 0 on success, < 0 on error.  Errors are:
+//	-E_BAD_ENV if environment envid doesn't currently exist,
+//		or the caller doesn't have permission to change envid.
+    static int
+sys_env_set_pgfault_upcall(envid_t envid, void *func)
+{
+    // LAB 4: Your code here.
+    struct Env *e;
+    if (envid2env(envid, &e, 1) == -E_BAD_ENV) return -E_BAD_ENV;
+    e->env_pgfault_upcall = func;
+    unlock(&e->lock);
+    return 0;
+}
+
+// Allocate a page of memory and map it at 'va' with permission
+// 'perm' in the address space of 'envid'.
+// The page's contents are set to 0.
+// If a page is already mapped at 'va', that page is unmapped as a
+// side effect.
+//
+// perm -- PTE_U | PTE_P must be set, PTE_AVAIL | PTE_W may or may not be set,
+//         but no other bits may be set.  See PTE_SYSCALL in inc/mmu.h.
+//
+// Return 0 on success, < 0 on error.  Errors are:
+//	-E_BAD_ENV if environment envid doesn't currently exist,
+//		or the caller doesn't have permission to change envid.
+//	-E_INVAL if va >= UTOP, or va is not page-aligned.
+//	-E_INVAL if perm is inappropriate (see above).
+//	-E_NO_MEM if there's no memory to allocate the new page,
+//		or to allocate any necessary page tables.
+    static int
+sys_page_alloc(envid_t envid, void *va, int perm)
+{
+    // Hint: This function is a wrapper around page_alloc() and
+    //   page_insert() from kern/pmap.c.
+    //   Most of the new code you write should be to check the
+    //   parameters for correctness.
+    //   If page_insert() fails, remember to free the page you
+    //   allocated!
+
+    // LAB 4: Your code here.
+    struct Env *e;
+    struct PageInfo *p;
+    perm &= PTE_SYSCALL;
+    if (envid2env(envid, &e, 1) == -E_BAD_ENV) return -E_BAD_ENV;
+    if ((uintptr_t)va >= UTOP || (uintptr_t)va % PGSIZE != 0) {
+	unlock(&e->lock);
+	return -E_INVAL;
+    }
+    if ((perm & (PTE_U | PTE_P)) != (PTE_U | PTE_P)) {
+	unlock(&e->lock);
+	return -E_INVAL;
+    }
+    lock(&page_lock);
+    if (!(p = page_alloc(ALLOC_ZERO))) {
+	unlock(&page_lock);
+	unlock(&e->lock);
+	return -E_NO_MEM;
+    }
+    if (page_insert(e->env_pgdir, p, va, perm) == -E_NO_MEM) {
+	page_free(p);
+	unlock(&page_lock);
+	unlock(&e->lock);
+	return -E_NO_MEM;
+    }
+    unlock(&page_lock);
+    unlock(&e->lock);
+    return 0;
+}
+
+// Map the page of memory at 'srcva' in srcenvid's address space
+// at 'dstva' in dstenvid's address space with permission 'perm'.
+// Perm has the same restrictions as in sys_page_alloc, except
+// that it also must not grant write access to a read-only
+// page.
+//
+// Return 0 on success, < 0 on error.  Errors are:
+//	-E_BAD_ENV if srcenvid and/or dstenvid doesn't currently exist,
+//		or the caller doesn't have permission to change one of them.
+//	-E_INVAL if srcva >= UTOP or srcva is not page-aligned,
+//		or dstva >= UTOP or dstva is not page-aligned.
+//	-E_INVAL is srcva is not mapped in srcenvid's address space.
+//	-E_INVAL if perm is inappropriate (see sys_page_alloc).
+//	-E_INVAL if (perm & PTE_W), but srcva is read-only in srcenvid's
+//		address space.
+//	-E_NO_MEM if there's no memory to allocate any necessary page tables.
+    static int
+sys_page_map(envid_t srcenvid, void *srcva,
+	envid_t dstenvid, void *dstva, int perm)
+{
+    // Hint: This function is a wrapper around page_lookup() and
+    //   page_insert() from kern/pmap.c.
+    //   Again, most of the new code you write should be to check the
+    //   parameters for correctness.
+    //   Use the third argument to page_lookup() to
+    //   check the current permissions on the page.
+
+    // LAB 4: Your code here.
+    struct Env *esrc, *edst;
+    struct PageInfo *p;
+    pte_t *pte;
+    perm &= PTE_SYSCALL;
+    if (envid2env(srcenvid, &esrc, 1) == -E_BAD_ENV) {
+	return -E_BAD_ENV;
+    }
+    if (dstenvid == srcenvid) {
+	edst = esrc;
+    }
+    else {
+	if (envid2env(dstenvid, &edst, 1) == -E_BAD_ENV) {
+	    unlock(&esrc->lock);
+	    return -E_BAD_ENV;
+	}
+    }
+    if ((uintptr_t)srcva >= UTOP || (uintptr_t)srcva % PGSIZE != 0 ||
+	    (uintptr_t)dstva >= UTOP || (uintptr_t)dstva % PGSIZE != 0) {
+	unlock(&esrc->lock);
+	if (edst != esrc) unlock(&edst->lock);
+	return -E_INVAL;
+    }
+    lock(&page_lock);
+    if (!(p = page_lookup(esrc->env_pgdir, srcva, &pte))) {
+	unlock(&page_lock);
+	unlock(&esrc->lock);
+	if (edst != esrc) unlock(&edst->lock);
+	return -E_INVAL;
+    }
+    if ((perm & (PTE_U | PTE_P)) != (PTE_U | PTE_P) || (perm & PTE_W & ~*pte)) {
+	unlock(&page_lock);
+	unlock(&esrc->lock);
+	if (edst != esrc) unlock(&edst->lock);
+	return -E_INVAL;
+    }
+    if (page_insert(edst->env_pgdir, p, dstva, perm) == -E_NO_MEM) {
+	page_free(p);
+	unlock(&page_lock);
+	unlock(&esrc->lock);
+	if (edst != esrc) unlock(&edst->lock);
+	return -E_NO_MEM;
+    }
+    unlock(&page_lock);
+    unlock(&esrc->lock);
+    if (edst != esrc) unlock(&edst->lock);
+    return 0;
+}
+
+// Unmap the page of memory at 'va' in the address space of 'envid'.
+// If no page is mapped, the function silently succeeds.
+//
+// Return 0 on success, < 0 on error.  Errors are:
+//	-E_BAD_ENV if environment envid doesn't currently exist,
+//		or the caller doesn't have permission to change envid.
+//	-E_INVAL if va >= UTOP, or va is not page-aligned.
+    static int
+sys_page_unmap(envid_t envid, void *va)
+{
+    // Hint: This function is a wrapper around page_remove().
+
+    // LAB 4: Your code here.
+    struct Env *e;
+    if (envid2env(envid, &e, 1) == -E_BAD_ENV) return -E_BAD_ENV;
+    if ((uintptr_t)va >= UTOP || (uintptr_t)va % PGSIZE != 0) {
+	unlock(&e->lock);
+	return -E_INVAL;
+    }
+    lock(&page_lock);
+    page_remove(e->env_pgdir, va);
+    unlock(&page_lock);
+    unlock(&e->lock);
+    return 0;
+}
+
+// Try to send 'value' to the target env 'envid'.
+// If srcva < UTOP, then also send page currently mapped at 'srcva',
+// so that receiver gets a duplicate mapping of the same page.
+//
+// The send fails with a return value of -E_IPC_NOT_RECV if the
+// target is not blocked, waiting for an IPC.
+//
+// The send also can fail for the other reasons listed below.
+//
+// Otherwise, the send succeeds, and the target's ipc fields are
+// updated as follows:
+//    env_ipc_recving is set to 0 to block future sends;
+//    env_ipc_from is set to the sending envid;
+//    env_ipc_value is set to the 'value' parameter;
+//    env_ipc_perm is set to 'perm' if a page was transferred, 0 otherwise.
+// The target environment is marked runnable again, returning 0
+// from the paused sys_ipc_recv system call.  (Hint: does the
+// sys_ipc_recv function ever actually return?)
+//
+// If the sender wants to send a page but the receiver isn't asking for one,
+// then no page mapping is transferred, but no error occurs.
+// The ipc only happens when no errors occur.
+//
+// Returns 0 on success, < 0 on error.
+// Errors are:
+//	-E_BAD_ENV if environment envid doesn't currently exist.
+//		(No need to check permissions.)
+//	-E_IPC_NOT_RECV if envid is not currently blocked in sys_ipc_recv,
+//		or another environment managed to send first.
+//	-E_INVAL if srcva < UTOP but srcva is not page-aligned.
+//	-E_INVAL if srcva < UTOP and perm is inappropriate
+//		(see sys_page_alloc).
+//	-E_INVAL if srcva < UTOP but srcva is not mapped in the caller's
+//		address space.
+//	-E_INVAL if (perm & PTE_W), but srcva is read-only in the
+//		current environment's address space.
+//	-E_NO_MEM if there's not enough memory to map srcva in envid's
+//		address space.
+    static int
+sys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, unsigned perm)
+{
+    // LAB 4: Your code here.
+    struct Env *e;
+    struct PageInfo *p;
+    pte_t *pte;
+    perm &= PTE_SYSCALL;
+    if (envid2env(envid, &e, 0) == -E_BAD_ENV) {
+	return -E_BAD_ENV;
+    }
+    if (!e->env_ipc_recving) {
+	unlock(&e->lock);
+	return -E_IPC_NOT_RECV;
+    }
+    if ((uintptr_t)srcva < UTOP) {
+	if (((uintptr_t)srcva % PGSIZE) || (perm & (PTE_P | PTE_U)) != (PTE_P | PTE_U)) {
+	    unlock(&e->lock);
+	    return -E_INVAL;
+	}
+	lock(&page_lock);
+	if (!(p = page_lookup(curenv->env_pgdir, srcva, &pte))) {
+	    unlock(&page_lock);
+	    unlock(&e->lock);
+	    return -E_INVAL;
+	}
+	if (perm & PTE_W & !(*pte & PTE_W)) {
+	    unlock(&page_lock);
+	    unlock(&e->lock);
+	    return -E_INVAL;
+	}
+	if ((uintptr_t)e->env_ipc_dstva < UTOP) {
+	    if (page_insert(e->env_pgdir, p, e->env_ipc_dstva, perm) == -E_NO_MEM) {
+		unlock(&page_lock);
+		unlock(&e->lock);
+		return -E_NO_MEM;
+	    }
+	    e->env_ipc_perm = perm;
+	}
+	unlock(&page_lock);
+    }
+    e->env_ipc_recving = 0;
+    e->env_ipc_from = curenv->env_id;
+    e->env_ipc_value = value;
+    e->env_status = ENV_RUNNABLE;
+    e->env_tf.tf_regs.reg_eax = 0;
+    unlock(&e->lock);
+    return 0;
+}
+
+// Block until a value is ready.  Record that you want to receive
+// using the env_ipc_recving and env_ipc_dstva fields of struct Env,
+// mark yourself not runnable, and then give up the CPU.
+//
+// If 'dstva' is < UTOP, then you are willing to receive a page of data.
+// 'dstva' is the virtual address at which the sent page should be mapped.
+//
+// This function only returns on error, but the system call will eventually
+// return 0 on success.
+// Return < 0 on error.  Errors are:
+//	-E_INVAL if dstva < UTOP but dstva is not page-aligned.
+    static int
+sys_ipc_recv(void *dstva)
+{
+    // LAB 4: Your code here.
+    if ((uintptr_t)dstva < UTOP && (uintptr_t)dstva % PGSIZE) return -E_INVAL;
+    struct Env *e = curenv;
+    lock(&e->lock);
+    e->env_ipc_recving = 1;
+    e->env_ipc_dstva = dstva;
+    e->env_ipc_perm = 0;
+    e->env_status = ENV_NOT_RUNNABLE;
+    unlock(&e->lock);
+    sched_yield();
+    return 0;
+}
+
+// Dispatches to the correct kernel function, passing the arguments.
+    int32_t
+syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5)
+{
+    // Call the function corresponding to the 'syscallno' parameter.
+    // Return any appropriate return value.
+    // LAB 3: Your code here.
+    switch (syscallno) {
+	case SYS_cputs:
+	    sys_cputs((const char*)a1, (size_t)a2);
+	    return 0;
+	case SYS_cgetc:
+	    return sys_cgetc();
+	case SYS_getenvid:
+	    return sys_getenvid();
+	case SYS_env_destroy:
+	    return sys_env_destroy((envid_t)a1);
+	case SYS_yield:
+	    sys_yield();
+	case SYS_exofork:
+	    return sys_exofork();
+	case SYS_env_set_status:
+	    return sys_env_set_status((envid_t)a1, (int)a2);
+	case SYS_page_alloc:
+	    return sys_page_alloc((envid_t)a1, (void*)a2, (int)a3);
+	case SYS_page_map:
+	    return sys_page_map((envid_t)a1, (void*)a2, (envid_t)a3, (void*)a4, (int)a5);
+	case SYS_page_unmap:
+	    return sys_page_unmap((envid_t)a1, (void*)a2);
+	case SYS_env_set_pgfault_upcall:
+	    return sys_env_set_pgfault_upcall((envid_t)a1, (void*)a2);
+	case SYS_ipc_try_send:
+	    return sys_ipc_try_send((envid_t)a1, (uint32_t)a2, (void*)a3, (unsigned)a4);
+	case SYS_ipc_recv:
+	    return sys_ipc_recv((void*)a1);
+	default:
+	    return -E_INVAL;
+    }
+}
+
diff --git a/kern.old/syscall.h b/kern.old/syscall.h
new file mode 100755
index 0000000..e370801
--- /dev/null
+++ b/kern.old/syscall.h
@@ -0,0 +1,11 @@
+#ifndef JOS_KERN_SYSCALL_H
+#define JOS_KERN_SYSCALL_H
+#ifndef JOS_KERNEL
+# error "This is a JOS kernel header; user programs should not #include it"
+#endif
+
+#include <inc/syscall.h>
+
+int32_t syscall(uint32_t num, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5);
+
+#endif /* !JOS_KERN_SYSCALL_H */
diff --git a/kern.old/trap.c b/kern.old/trap.c
new file mode 100755
index 0000000..6c869cf
--- /dev/null
+++ b/kern.old/trap.c
@@ -0,0 +1,515 @@
+#include <inc/mmu.h>
+#include <inc/x86.h>
+#include <inc/assert.h>
+
+#include <kern/pmap.h>
+#include <kern/trap.h>
+#include <kern/console.h>
+#include <kern/monitor.h>
+#include <kern/env.h>
+#include <kern/syscall.h>
+#include <kern/sched.h>
+#include <kern/kclock.h>
+#include <kern/picirq.h>
+#include <kern/cpu.h>
+#include <kern/spinlock.h>
+
+
+static struct Taskstate ts;
+
+/* For debugging, so print_trapframe can distinguish between printing
+ * a saved trapframe and printing the current trapframe and print some
+ * additional information in the latter case.
+ */
+static struct Trapframe *last_tf;
+
+/* Interrupt descriptor table.  (Must be built at run time because
+ * shifted function addresses can't be represented in relocation records.)
+ */
+struct Gatedesc idt[256] = { { 0 } };
+struct Pseudodesc idt_pd = {
+    sizeof(idt) - 1, (uint32_t) idt
+};
+
+
+static const char *trapname(int trapno)
+{
+    static const char * const excnames[] = {
+	"Divide error",
+	"Debug",
+	"Non-Maskable Interrupt",
+	"Breakpoint",
+	"Overflow",
+	"BOUND Range Exceeded",
+	"Invalid Opcode",
+	"Device Not Available",
+	"Double Fault",
+	"Coprocessor Segment Overrun",
+	"Invalid TSS",
+	"Segment Not Present",
+	"Stack Fault",
+	"General Protection",
+	"Page Fault",
+	"(unknown trap)",
+	"x87 FPU Floating-Point Error",
+	"Alignment Check",
+	"Machine-Check",
+	"SIMD Floating-Point Exception"
+    };
+
+    if (trapno < ARRAY_SIZE(excnames))
+	return excnames[trapno];
+    if (trapno == T_SYSCALL)
+	return "System call";
+    if (trapno >= IRQ_OFFSET && trapno < IRQ_OFFSET + 16)
+	return "Hardware Interrupt";
+    return "(unknown trap)";
+}
+
+
+    void
+trap_init(void)
+{
+    extern struct Segdesc gdt[];
+    /*
+    extern long vectors[];
+    int i;
+
+    // LAB 3: Your code here.
+    for (i = 0; i <= 0x30; ++i) {
+	switch (i) {
+	    case T_BRKPT:
+	    case T_SYSCALL:
+	    case IRQ_OFFSET + IRQ_TIMER:
+		SETGATE(idt[i], 0, GD_KT, vectors[i], 3);
+		break;
+	    default:
+		SETGATE(idt[i], 0, GD_KT, vectors[i], 0);
+	}
+    }*/
+    extern void r_divide();
+	extern void r_debug();
+	extern void r_nmi();
+	extern void r_brkpt();
+	extern void r_oflow();
+	extern void r_bound();
+	extern void r_illop();
+	extern void r_device();
+	extern void r_dblflt();
+	extern void r_tss();
+	extern void r_segnp();
+	extern void r_stack();
+	extern void r_gpflt();
+	extern void r_pgflt();
+	extern void r_fperr();
+	extern void r_align();
+	extern void r_mchk();
+	extern void r_simderr();
+	extern void r_syscall();
+	extern void r_irq0();
+	extern void r_irq1();
+	extern void r_irq2();
+	extern void r_irq3();
+	extern void r_irq4();
+	extern void r_irq5();
+	extern void r_irq6();
+	extern void r_irq7();
+	extern void r_irq8();
+	extern void r_irq9();
+	extern void r_irq10();
+	extern void r_irq11();
+	extern void r_irq12();
+	extern void r_irq13();
+	extern void r_irq14();
+	extern void r_irq15();
+
+	SETGATE(idt[T_DIVIDE], 0, GD_KT, r_divide, 0);
+	SETGATE(idt[T_DEBUG], 0, GD_KT, r_debug, 0);
+	SETGATE(idt[T_NMI], 0, GD_KT, r_nmi, 0);
+	SETGATE(idt[T_BRKPT], 0, GD_KT, r_brkpt, 3);
+	SETGATE(idt[T_OFLOW], 0, GD_KT, r_oflow, 0);
+	SETGATE(idt[T_BOUND], 0, GD_KT, r_bound, 0);
+	SETGATE(idt[T_ILLOP], 0, GD_KT, r_illop, 0);
+	SETGATE(idt[T_DEVICE], 0, GD_KT, r_device, 0);
+	SETGATE(idt[T_DBLFLT], 0, GD_KT, r_dblflt, 0);
+	SETGATE(idt[T_TSS], 0, GD_KT, r_tss, 0);
+	SETGATE(idt[T_SEGNP], 0, GD_KT, r_segnp, 0);
+	SETGATE(idt[T_STACK], 0, GD_KT, r_stack, 0);
+	SETGATE(idt[T_GPFLT], 0, GD_KT, r_gpflt, 0);
+	SETGATE(idt[T_PGFLT], 0, GD_KT, r_pgflt, 0);
+	SETGATE(idt[T_FPERR], 0, GD_KT, r_fperr, 0);
+	SETGATE(idt[T_ALIGN], 0, GD_KT, r_align, 0);
+	SETGATE(idt[T_MCHK], 0, GD_KT, r_mchk, 0);
+	SETGATE(idt[T_SIMDERR], 0, GD_KT, r_simderr, 0);
+	SETGATE(idt[T_SYSCALL], 0, GD_KT, r_syscall, 3);
+
+	SETGATE(idt[IRQ_OFFSET + 0], 0, GD_KT, r_irq0, 0);
+	SETGATE(idt[IRQ_OFFSET + 1], 0, GD_KT, r_irq1, 0);
+	SETGATE(idt[IRQ_OFFSET + 2], 0, GD_KT, r_irq2, 0);
+	SETGATE(idt[IRQ_OFFSET + 3], 0, GD_KT, r_irq3, 0);
+	SETGATE(idt[IRQ_OFFSET + 4], 0, GD_KT, r_irq4, 0);
+	SETGATE(idt[IRQ_OFFSET + 5], 0, GD_KT, r_irq5, 0);
+	SETGATE(idt[IRQ_OFFSET + 6], 0, GD_KT, r_irq6, 0);
+	SETGATE(idt[IRQ_OFFSET + 7], 0, GD_KT, r_irq7, 0);
+	SETGATE(idt[IRQ_OFFSET + 8], 0, GD_KT, r_irq8, 0);
+	SETGATE(idt[IRQ_OFFSET + 9], 0, GD_KT, r_irq9, 0);
+	SETGATE(idt[IRQ_OFFSET + 10], 0, GD_KT, r_irq10, 0);
+	SETGATE(idt[IRQ_OFFSET + 11], 0, GD_KT, r_irq11, 0);
+	SETGATE(idt[IRQ_OFFSET + 12], 0, GD_KT, r_irq12, 0);
+	SETGATE(idt[IRQ_OFFSET + 13], 0, GD_KT, r_irq13, 0);
+	SETGATE(idt[IRQ_OFFSET + 14], 0, GD_KT, r_irq14, 0);
+	SETGATE(idt[IRQ_OFFSET + 15], 0, GD_KT, r_irq15, 0);
+    // Per-CPU setup 
+    trap_init_percpu();
+}
+
+// Initialize and load the per-CPU TSS and IDT
+    void
+trap_init_percpu(void)
+{
+    // The example code here sets up the Task State Segment (TSS) and
+    // the TSS descriptor for CPU 0. But it is incorrect if we are
+    // running on other CPUs because each CPU has its own kernel stack.
+    // Fix the code so that it works for all CPUs.
+    //
+    // Hints:
+    //   - The macro "thiscpu" always refers to the current CPU's
+    //     struct CpuInfo;
+    //   - The ID of the current CPU is given by cpunum() or
+    //     thiscpu->cpu_id;
+    //   - Use "thiscpu->cpu_ts" as the TSS for the current CPU,
+    //     rather than the global "ts" variable;
+    //   - Use gdt[(GD_TSS0 >> 3) + i] for CPU i's TSS descriptor;
+    //   - You mapped the per-CPU kernel stacks in mem_init_mp()
+    //
+    // ltr sets a 'busy' flag in the TSS selector, so if you
+    // accidentally load the same TSS on more than one CPU, you'll
+    // get a triple fault.  If you set up an individual CPU's TSS
+    // wrong, you may not get a fault until you try to return from
+    // user space on that CPU.
+    //
+    // LAB 4: Your code here:
+    int i = thiscpu->cpu_id;
+
+    thiscpu->cpu_ts.ts_esp0 = KSTACKTOP - i * (KSTKSIZE + KSTKGAP);
+    thiscpu->cpu_ts.ts_ss0 = GD_KD;
+
+    // Initialize the TSS slot of the gdt.
+    gdt[(GD_TSS0 >> 3) + i] = SEG16(STS_T32A, (uint32_t) (&thiscpu->cpu_ts), sizeof(struct Taskstate), 0); 
+
+    gdt[(GD_TSS0 >> 3) + i].sd_s = 0;
+
+    // Load the TSS selector (like other segment selectors, the
+    // bottom three bits are special; we leave them 0)
+    ltr(GD_TSS0+ (i<<3));
+
+    // Load the IDT
+    lidt(&idt_pd);
+}
+
+    void
+print_trapframe(struct Trapframe *tf)
+{
+    cprintf("TRAP frame at %p from CPU %d\n", tf, cpunum());
+    print_regs(&tf->tf_regs);
+    cprintf("  es   0x----%04x\n", tf->tf_es);
+    cprintf("  ds   0x----%04x\n", tf->tf_ds);
+    cprintf("  trap 0x%08x %s\n", tf->tf_trapno, trapname(tf->tf_trapno));
+    // If this trap was a page fault that just happened
+    // (so %cr2 is meaningful), print the faulting linear address.
+    if (tf == last_tf && tf->tf_trapno == T_PGFLT)
+	cprintf("  cr2  0x%08x\n", rcr2());
+    cprintf("  err  0x%08x", tf->tf_err);
+    // For page faults, print decoded fault error code:
+    // U/K=fault occurred in user/kernel mode
+    // W/R=a write/read caused the fault
+    // PR=a protection violation caused the fault (NP=page not present).
+    if (tf->tf_trapno == T_PGFLT)
+	cprintf(" [%s, %s, %s]\n",
+		tf->tf_err & 4 ? "user" : "kernel",
+		tf->tf_err & 2 ? "write" : "read",
+		tf->tf_err & 1 ? "protection" : "not-present");
+    else
+	cprintf("\n");
+    cprintf("  eip  0x%08x\n", tf->tf_eip);
+    cprintf("  cs   0x----%04x\n", tf->tf_cs);
+    cprintf("  flag 0x%08x\n", tf->tf_eflags);
+    if ((tf->tf_cs & 3) != 0) {
+	cprintf("  esp  0x%08x\n", tf->tf_esp);
+	cprintf("  ss   0x----%04x\n", tf->tf_ss);
+    }
+}
+
+    void
+print_regs(struct PushRegs *regs)
+{
+
+    cprintf("  esi  0x%08x\n", regs->reg_esi);
+    cprintf("  ebp  0x%08x\n", regs->reg_ebp);
+    cprintf("  oesp 0x%08x\n", regs->reg_oesp);
+    cprintf("  ebx  0x%08x\n", regs->reg_ebx);
+    cprintf("  edx  0x%08x\n", regs->reg_edx);
+    cprintf("  ecx  0x%08x\n", regs->reg_ecx);
+    cprintf("  eax  0x%08x\n", regs->reg_eax);
+}
+
+    static void
+trap_dispatch(struct Trapframe *tf)
+{
+<<<<<<< HEAD
+	// Handle processor exceptions.
+	// LAB 3: Your code here.
+
+	// Handle spurious interrupts
+	// The hardware sometimes raises these because of noise on the
+	// IRQ line or other reasons. We don't care.
+	if (tf->tf_trapno == IRQ_OFFSET + IRQ_SPURIOUS) {
+		cprintf("Spurious interrupt on irq 7\n");
+		print_trapframe(tf);
+		return;
+	}
+
+	// Handle clock interrupts. Don't forget to acknowledge the
+	// interrupt using lapic_eoi() before calling the scheduler!
+	// LAB 4: Your code here.
+
+	// Handle keyboard and serial interrupts.
+	// LAB 5: Your code here.
+
+	// Unexpected trap: The user process or the kernel has a bug.
+=======
+    // Handle processor exceptions.
+    // LAB 3: Your code here.
+    switch (tf->tf_trapno) {
+	case T_DEBUG:
+	case T_BRKPT:
+	    monitor(tf);
+	    return;
+	case T_PGFLT:
+	    page_fault_handler(tf);
+	    return;
+	case T_SYSCALL:
+	    tf->tf_regs.reg_eax = 
+		syscall(tf->tf_regs.reg_eax, tf->tf_regs.reg_edx, tf->tf_regs.reg_ecx, tf->tf_regs.reg_ebx, tf->tf_regs.reg_edi, tf->tf_regs.reg_esi);
+	    return;
+    }
+
+    // Handle spurious interrupts
+    // The hardware sometimes raises these because of noise on the
+    // IRQ line or other reasons. We don't care.
+    if (tf->tf_trapno == IRQ_OFFSET + IRQ_SPURIOUS) {
+	cprintf("Spurious interrupt on irq 7\n");
+>>>>>>> lab4
+	print_trapframe(tf);
+	return;
+    }
+
+    // Handle clock interrupts. Don't forget to acknowledge the
+    // interrupt using lapic_eoi() before calling the scheduler!
+    // LAB 4: Your code here.
+    if (tf->tf_trapno == IRQ_OFFSET + IRQ_TIMER) {
+	lapic_eoi();
+	sched_yield();
+    }
+
+    // Unexpected trap: The user process or the kernel has a bug.
+    print_trapframe(tf);
+    if (tf->tf_cs == GD_KT)
+	panic("unhandled trap in kernel");
+    else {
+	lock(&curenv->lock);
+	env_destroy(curenv);
+	return;
+    }
+}
+    void
+trap(struct Trapframe *tf)
+{
+    // The environment may have set DF and some versions
+    // of GCC rely on DF being clear
+    asm volatile("cld" ::: "cc");
+
+    // Halt the CPU if some other CPU has called panic()
+    extern char *panicstr;
+    if (panicstr)
+	asm volatile("hlt");
+
+    // Re-acqurie the big kernel lock if we were halted in
+    // sched_yield()
+
+    // Check that interrupts are disabled.  If this assertion
+    // fails, DO NOT be tempted to fix it by inserting a "cli" in
+    // the interrupt path.
+    assert(!(read_eflags() & FL_IF));
+
+    if ((tf->tf_cs & 3) == 3) {
+	// Trapped from user mode.
+	// Acquire the big kernel lock before doing any
+	// serious kernel work.
+	// LAB 4: Your code here.
+	assert(curenv);
+	curenv->env_in_kernel = 1;
+
+	// Garbage collect if current enviroment is a zombie
+	lock(&curenv->lock);
+	if (curenv->env_status == ENV_DYING) {
+	    env_free(curenv);
+	    unlock(&curenv->lock);
+	    curenv = NULL;
+	    sched_yield();
+	}
+
+	// Copy trap frame (which is currently on the stack)
+	// into 'curenv->env_tf', so that running the environment
+	// will restart at the trap point.
+	curenv->env_tf = *tf;
+	// The trapframe on the stack should be ignored from here on.
+	tf = &curenv->env_tf;
+	unlock(&curenv->lock);
+    }
+
+    // Record that tf is the last real trapframe so
+    // print_trapframe can print some additional information.
+    last_tf = tf;
+
+    // Dispatch based on what type of trap occurred
+    trap_dispatch(tf);
+
+    // If we made it to this point, then no other environment was
+    // scheduled, so we should return to the current environment
+    // if doing so makes sense.
+    if (curenv) {
+	lock(&curenv->lock);
+	if (curenv->env_status == ENV_RUNNING) {
+	    env_run(curenv);
+	}
+	unlock(&curenv->lock);
+    }
+    sched_yield();
+}
+
+    void
+page_fault_handler(struct Trapframe *tf)
+{
+<<<<<<< HEAD
+	uint32_t fault_va;
+
+	// Read processor's CR2 register to find the faulting address
+	fault_va = rcr2();
+
+	// Handle kernel-mode page faults.
+
+	// LAB 3: Your code here.
+
+	// We've already handled kernel-mode exceptions, so if we get here,
+	// the page fault happened in user mode.
+
+	// Call the environment's page fault upcall, if one exists.  Set up a
+	// page fault stack frame on the user exception stack (below
+	// UXSTACKTOP), then branch to curenv->env_pgfault_upcall.
+	//
+	// The page fault upcall might cause another page fault, in which case
+	// we branch to the page fault upcall recursively, pushing another
+	// page fault stack frame on top of the user exception stack.
+	//
+	// It is convenient for our code which returns from a page fault
+	// (lib/pfentry.S) to have one word of scratch space at the top of the
+	// trap-time stack; it allows us to more easily restore the eip/esp. In
+	// the non-recursive case, we don't have to worry about this because
+	// the top of the regular user stack is free.  In the recursive case,
+	// this means we have to leave an extra word between the current top of
+	// the exception stack and the new stack frame because the exception
+	// stack _is_ the trap-time stack.
+	//
+	// If there's no page fault upcall, the environment didn't allocate a
+	// page for its exception stack or can't write to it, or the exception
+	// stack overflows, then destroy the environment that caused the fault.
+	// Note that the grade script assumes you will first check for the page
+	// fault upcall and print the "user fault va" message below if there is
+	// none.  The remaining three checks can be combined into a single test.
+	//
+	// Hints:
+	//   user_mem_assert() and env_run() are useful here.
+	//   To change what the user environment runs, modify 'curenv->env_tf'
+	//   (the 'tf' variable points at 'curenv->env_tf').
+
+	// LAB 4: Your code here.
+
+	// Destroy the environment that caused the fault.
+	cprintf("[%08x] user fault va %08x ip %08x\n",
+		curenv->env_id, fault_va, tf->tf_eip);
+	print_trapframe(tf);
+	env_destroy(curenv);
+=======
+    uint32_t fault_va;
+
+    // Read processor's CR2 register to find the faulting address
+    fault_va = rcr2();
+
+    // Handle kernel-mode page faults.
+
+    // LAB 3: Your code here.
+    if (!(tf->tf_cs & 3))
+	panic("a page fault happens in kernel mode\n");
+
+    // We've already handled kernel-mode exceptions, so if we get here,
+    // the page fault happened in user mode.
+
+    // Call the environment's page fault upcall, if one exists.  Set up a
+    // page fault stack frame on the user exception stack (below
+    // UXSTACKTOP), then branch to curenv->env_pgfault_upcall.
+    //
+    // The page fault upcall might cause another page fault, in which case
+    // we branch to the page fault upcall recursively, pushing another
+    // page fault stack frame on top of the user exception stack.
+    //
+    // The trap handler needs one word of scratch space at the top of the
+    // trap-time stack in order to return.  In the non-recursive case, we
+    // don't have to worry about this because the top of the regular user
+    // stack is free.  In the recursive case, this means we have to leave
+    // an extra word between the current top of the exception stack and
+    // the new stack frame because the exception stack _is_ the trap-time
+    // stack.
+    //
+    // If there's no page fault upcall, the environment didn't allocate a
+    // page for its exception stack or can't write to it, or the exception
+    // stack overflows, then destroy the environment that caused the fault.
+    // Note that the grade script assumes you will first check for the page
+    // fault upcall and print the "user fault va" message below if there is
+    // none.  The remaining three checks can be combined into a single test.
+    //
+    // Hints:
+    //   user_mem_assert() and env_run() are useful here.
+    //   To change what the user environment runs, modify 'curenv->env_tf'
+    //   (the 'tf' variable points at 'curenv->env_tf').
+
+    // LAB 4: Your code here.
+    struct UTrapframe *utf;
+    uint32_t esp = tf->tf_esp;
+
+    if (curenv->env_pgfault_upcall) {
+	if (esp < UXSTACKTOP - PGSIZE || esp >= UXSTACKTOP) tf->tf_esp = UXSTACKTOP+4; 
+	utf = (struct UTrapframe*)(tf->tf_esp - 4 - sizeof(struct UTrapframe));
+	user_mem_assert(curenv, (const void*)utf, 1, PTE_W|PTE_U);
+	//lcr3(PADDR(curenv->env_pgdir));
+	utf->utf_fault_va = fault_va;
+	utf->utf_err = tf->tf_err;
+	utf->utf_regs = tf->tf_regs;
+	utf->utf_eip = tf->tf_eip;
+	utf->utf_eflags = tf->tf_eflags;
+	utf->utf_esp = esp;
+	tf->tf_esp = (uint32_t)utf;
+	tf->tf_eip = (uint32_t)curenv->env_pgfault_upcall;
+	lock(&curenv->lock);
+	env_run(curenv);
+    }
+
+    // Destroy the environment that caused the fault.
+    cprintf("[%08x] user fault va %08x ip %08x\n",
+	    curenv->env_id, fault_va, tf->tf_eip);
+    print_trapframe(tf);
+    lock(&curenv->lock);
+    env_destroy(curenv);
+>>>>>>> lab4
+}
+
diff --git a/kern.old/trap.h b/kern.old/trap.h
new file mode 100755
index 0000000..36b8758
--- /dev/null
+++ b/kern.old/trap.h
@@ -0,0 +1,23 @@
+/* See COPYRIGHT for copyright information. */
+
+#ifndef JOS_KERN_TRAP_H
+#define JOS_KERN_TRAP_H
+#ifndef JOS_KERNEL
+# error "This is a JOS kernel header; user programs should not #include it"
+#endif
+
+#include <inc/trap.h>
+#include <inc/mmu.h>
+
+/* The kernel's interrupt descriptor table */
+extern struct Gatedesc idt[];
+extern struct Pseudodesc idt_pd;
+
+void trap_init(void);
+void trap_init_percpu(void);
+void print_regs(struct PushRegs *regs);
+void print_trapframe(struct Trapframe *tf);
+void page_fault_handler(struct Trapframe *);
+void backtrace(struct Trapframe *);
+
+#endif /* JOS_KERN_TRAP_H */
diff --git a/kern.old/trapentry.S b/kern.old/trapentry.S
new file mode 100755
index 0000000..d38b614
--- /dev/null
+++ b/kern.old/trapentry.S
@@ -0,0 +1,103 @@
+/* See COPYRIGHT for copyright information. */
+
+#include <inc/mmu.h>
+#include <inc/memlayout.h>
+#include <inc/trap.h>
+
+#include <kern/picirq.h>
+
+
+###################################################################
+# exceptions/interrupts
+###################################################################
+
+/* TRAPHANDLER defines a globally-visible function for handling a trap.
+ * It pushes a trap number onto the stack, then jumps to _alltraps.
+ * Use TRAPHANDLER for traps where the CPU automatically pushes an error code.
+ *
+ * You shouldn't call a TRAPHANDLER function from C, but you may
+ * need to _declare_ one in C (for instance, to get a function pointer
+ * during IDT setup).  You can declare the function with
+ *   void NAME();
+ * where NAME is the argument passed to TRAPHANDLER.
+ */
+#define TRAPHANDLER(name, num)                      \
+    .globl name;        /* define global symbol for 'name' */   \
+    .type name, @function;  /* symbol type is function */       \
+    .align 2;       /* align function definition */     \
+    name:           /* function starts here */      \
+    pushl $(num);                           \
+    jmp _alltraps
+
+/* Use TRAPHANDLER_NOEC for traps where the CPU doesn't push an error code.
+ * It pushes a 0 in place of the error code, so the trap frame has the same
+ * format in either case.
+ */
+#define TRAPHANDLER_NOEC(name, num)                 \
+    .globl name;                            \
+    .type name, @function;                      \
+    .align 2;                           \
+    name:                               \
+    pushl $0;                           \
+    pushl $(num);                           \
+    jmp _alltraps
+
+.text
+
+/*
+ * Lab 3: Your code here for generating entry points for the different traps.
+ */
+ TRAPHANDLER_NOEC(r_divide, T_DIVIDE)
+ TRAPHANDLER_NOEC(r_debug, T_DEBUG)
+ TRAPHANDLER_NOEC(r_nmi, T_NMI)
+ TRAPHANDLER_NOEC(r_brkpt, T_BRKPT)
+ TRAPHANDLER_NOEC(r_oflow, T_OFLOW)
+ TRAPHANDLER_NOEC(r_bound, T_BOUND)
+ TRAPHANDLER_NOEC(r_illop, T_ILLOP)
+ TRAPHANDLER_NOEC(r_device, T_DEVICE)
+ TRAPHANDLER(r_dblflt, T_DBLFLT)
+ TRAPHANDLER(r_tss, T_TSS)
+ TRAPHANDLER(r_segnp, T_SEGNP)
+ TRAPHANDLER(r_stack, T_STACK)
+ TRAPHANDLER(r_gpflt, T_GPFLT)
+ TRAPHANDLER(r_pgflt, T_PGFLT)
+ TRAPHANDLER_NOEC(r_fperr, T_FPERR)
+ TRAPHANDLER(r_align, T_ALIGN)
+ TRAPHANDLER_NOEC(r_mchk, T_MCHK)
+ TRAPHANDLER_NOEC(r_simderr, T_SIMDERR)
+ TRAPHANDLER_NOEC(r_syscall, T_SYSCALL)
+ TRAPHANDLER_NOEC(r_irq0, IRQ_OFFSET + 0);
+ TRAPHANDLER_NOEC(r_irq1, IRQ_OFFSET + 1);
+ TRAPHANDLER_NOEC(r_irq2, IRQ_OFFSET + 2);
+ TRAPHANDLER_NOEC(r_irq3, IRQ_OFFSET + 3);
+ TRAPHANDLER_NOEC(r_irq4, IRQ_OFFSET + 4);
+ TRAPHANDLER_NOEC(r_irq5, IRQ_OFFSET + 5);
+ TRAPHANDLER_NOEC(r_irq6, IRQ_OFFSET + 6);
+ TRAPHANDLER_NOEC(r_irq7, IRQ_OFFSET + 7);
+ TRAPHANDLER_NOEC(r_irq8, IRQ_OFFSET + 8);
+ TRAPHANDLER_NOEC(r_irq9, IRQ_OFFSET + 9);
+ TRAPHANDLER_NOEC(r_irq10, IRQ_OFFSET + 10);
+ TRAPHANDLER_NOEC(r_irq11, IRQ_OFFSET + 11);
+ TRAPHANDLER_NOEC(r_irq12, IRQ_OFFSET + 12);
+ TRAPHANDLER_NOEC(r_irq13, IRQ_OFFSET + 13);
+ TRAPHANDLER_NOEC(r_irq14, IRQ_OFFSET + 14);
+ TRAPHANDLER_NOEC(r_irq15, IRQ_OFFSET + 15);
+
+
+/*
+ * Lab 3: Your code here for _alltraps
+ */
+_alltraps:
+
+    pushw $0x0
+    pushw %ds 
+    pushw $0x0
+    pushw %es 
+    pushal
+
+    movl $GD_KD, %eax
+    movw %ax, %ds
+    movw %ax, %es
+
+    pushl %esp
+    call trap
diff --git a/kern/.pmap.c.swp b/kern/.pmap.c.swp
new file mode 100755
index 0000000..efcbb66
Binary files /dev/null and b/kern/.pmap.c.swp differ
diff --git a/kern/COPYRIGHT b/kern/COPYRIGHT
old mode 100644
new mode 100755
diff --git a/kern/Makefrag b/kern/Makefrag
old mode 100644
new mode 100755
diff --git a/kern/console.c b/kern/console.c
old mode 100644
new mode 100755
index dad94fd..513b271
--- a/kern/console.c
+++ b/kern/console.c
@@ -5,6 +5,7 @@
 #include <inc/kbdreg.h>
 #include <inc/string.h>
 #include <inc/assert.h>
+#include <inc/color.h>
 
 #include <kern/console.h>
 #include <kern/trap.h>
@@ -169,8 +170,7 @@ cga_putc(int c)
 {
 	// if no attribute given, then use black on white
 	if (!(c & ~0xFF))
-		c |= 0x0700;
-
+	   	c |= COLOR;
 	switch (c & 0xff) {
 	case '\b':
 		if (crt_pos > 0) {
@@ -196,7 +196,7 @@ cga_putc(int c)
 		break;
 	}
 
-	// What is the purpose of this?
+	// What is the purpose of this? sol: lab 1 report P15
 	if (crt_pos >= CRT_SIZE) {
 		int i;
 
diff --git a/kern/console.h b/kern/console.h
old mode 100644
new mode 100755
diff --git a/kern/cpu.h b/kern/cpu.h
old mode 100644
new mode 100755
diff --git a/kern/entry.S b/kern/entry.S
old mode 100644
new mode 100755
diff --git a/kern/entrypgdir.c b/kern/entrypgdir.c
old mode 100644
new mode 100755
diff --git a/kern/env.c b/kern/env.c
old mode 100644
new mode 100755
index 5771aa5..a43c085
--- a/kern/env.c
+++ b/kern/env.c
@@ -17,7 +17,7 @@
 
 struct Env *envs = NULL;		// All environments
 static struct Env *env_free_list;	// Free environment list
-					// (linked by Env->env_link)
+// (linked by Env->env_link)
 
 #define ENVGENSHIFT	12		// >= LOGNENV
 
@@ -38,28 +38,28 @@ static struct Env *env_free_list;	// Free environment list
 //
 struct Segdesc gdt[NCPU + 5] =
 {
-	// 0x0 - unused (always faults -- for trapping NULL far pointers)
-	SEG_NULL,
+    // 0x0 - unused (always faults -- for trapping NULL far pointers)
+    SEG_NULL,
 
-	// 0x8 - kernel code segment
-	[GD_KT >> 3] = SEG(STA_X | STA_R, 0x0, 0xffffffff, 0),
+    // 0x8 - kernel code segment
+    [GD_KT >> 3] = SEG(STA_X | STA_R, 0x0, 0xffffffff, 0),
 
-	// 0x10 - kernel data segment
-	[GD_KD >> 3] = SEG(STA_W, 0x0, 0xffffffff, 0),
+    // 0x10 - kernel data segment
+    [GD_KD >> 3] = SEG(STA_W, 0x0, 0xffffffff, 0),
 
-	// 0x18 - user code segment
-	[GD_UT >> 3] = SEG(STA_X | STA_R, 0x0, 0xffffffff, 3),
+    // 0x18 - user code segment
+    [GD_UT >> 3] = SEG(STA_X | STA_R, 0x0, 0xffffffff, 3),
 
-	// 0x20 - user data segment
-	[GD_UD >> 3] = SEG(STA_W, 0x0, 0xffffffff, 3),
+    // 0x20 - user data segment
+    [GD_UD >> 3] = SEG(STA_W, 0x0, 0xffffffff, 3),
 
-	// Per-CPU TSS descriptors (starting from GD_TSS0) are initialized
-	// in trap_init_percpu()
-	[GD_TSS0 >> 3] = SEG_NULL
+    // Per-CPU TSS descriptors (starting from GD_TSS0) are initialized
+    // in trap_init_percpu()
+    [GD_TSS0 >> 3] = SEG_NULL
 };
 
 struct Pseudodesc gdt_pd = {
-	sizeof(gdt) - 1, (unsigned long) gdt
+    sizeof(gdt) - 1, (unsigned long) gdt
 };
 
 //
@@ -72,40 +72,43 @@ struct Pseudodesc gdt_pd = {
 //   On success, sets *env_store to the environment.
 //   On error, sets *env_store to NULL.
 //
-int
+    int
 envid2env(envid_t envid, struct Env **env_store, bool checkperm)
 {
-	struct Env *e;
+    struct Env *e;
 
-	// If envid is zero, return the current environment.
-	if (envid == 0) {
+    // If envid is zero, return the current environment.
+    if (envid == 0) 
+    {
 		*env_store = curenv;
-		return 0;
-	}
-
-	// Look up the Env structure via the index part of the envid,
-	// then check the env_id field in that struct Env
-	// to ensure that the envid is not stale
-	// (i.e., does not refer to a _previous_ environment
-	// that used the same slot in the envs[] array).
-	e = &envs[ENVX(envid)];
-	if (e->env_status == ENV_FREE || e->env_id != envid) {
+	return 0;
+    }
+
+    // Look up the Env structure via the index part of the envid,
+    // then check the env_id field in that struct Env
+    // to ensure that the envid is not stale
+    // (i.e., does not refer to a _previous_ environment
+    // that used the same slot in the envs[] array).
+    e = &envs[ENVX(envid)];
+    if (e->env_status == ENV_FREE || e->env_id != envid) 
+    {
 		*env_store = 0;
 		return -E_BAD_ENV;
-	}
-
-	// Check that the calling environment has legitimate permission
-	// to manipulate the specified environment.
-	// If checkperm is set, the specified environment
-	// must be either the current environment
-	// or an immediate child of the current environment.
-	if (checkperm && e != curenv && e->env_parent_id != curenv->env_id) {
+    }
+
+    // Check that the calling environment has legitimate permission
+    // to manipulate the specified environment.
+    // If checkperm is set, the specified environment
+    // must be either the current environment
+    // or an immediate child of the current environment.
+    if (checkperm && e != curenv && e->env_parent_id != curenv->env_id) 
+    {
 		*env_store = 0;
 		return -E_BAD_ENV;
-	}
+    }
 
-	*env_store = e;
-	return 0;
+    *env_store = e;
+    return 0;
 }
 
 // Mark all environments in 'envs' as free, set their env_ids to 0,
@@ -114,37 +117,60 @@ envid2env(envid_t envid, struct Env **env_store, bool checkperm)
 // they are in the envs array (i.e., so that the first call to
 // env_alloc() returns envs[0]).
 //
-void
+    void
 env_init(void)
 {
-	// Set up envs array
-	// LAB 3: Your code here.
-
-	// Per-CPU part of the initialization
-	env_init_percpu();
+    // Set up envs array
+    // LAB 3: Your code here.
+    int i;
+    env_free_list = NULL;
+    for (i = NENV - 1; i >= 0; i--) 
+    {
+		envs[i].env_id = 0;
+		envs[i].env_link = env_free_list;
+		env_free_list = &(envs[i]);
+    }
+
+    // Per-CPU part of the initialization
+    env_init_percpu();
 }
 
 // Load GDT and segment descriptors.
-void
+    void
 env_init_percpu(void)
 {
-	lgdt(&gdt_pd);
-	// The kernel never uses GS or FS, so we leave those set to
-	// the user data segment.
-	asm volatile("movw %%ax,%%gs" : : "a" (GD_UD|3));
-	asm volatile("movw %%ax,%%fs" : : "a" (GD_UD|3));
-	// The kernel does use ES, DS, and SS.  We'll change between
-	// the kernel and user data segments as needed.
-	asm volatile("movw %%ax,%%es" : : "a" (GD_KD));
-	asm volatile("movw %%ax,%%ds" : : "a" (GD_KD));
-	asm volatile("movw %%ax,%%ss" : : "a" (GD_KD));
-	// Load the kernel text segment into CS.
-	asm volatile("ljmp %0,$1f\n 1:\n" : : "i" (GD_KT));
-	// For good measure, clear the local descriptor table (LDT),
-	// since we don't use it.
-	lldt(0);
+    lgdt(&gdt_pd);
+    // The kernel never uses GS or FS, so we leave those set to
+    // the user data segment.
+    asm volatile("movw %%ax,%%gs" : : "a" (GD_UD|3));
+    asm volatile("movw %%ax,%%fs" : : "a" (GD_UD|3));
+    // The kernel does use ES, DS, and SS.  We'll change between
+    // the kernel and user data segments as needed.
+    asm volatile("movw %%ax,%%es" : : "a" (GD_KD));
+    asm volatile("movw %%ax,%%ds" : : "a" (GD_KD));
+    asm volatile("movw %%ax,%%ss" : : "a" (GD_KD));
+    // Load the kernel text segment into CS.
+    asm volatile("ljmp %0,$1f\n 1:\n" : : "i" (GD_KT));
+    // For good measure, clear the local descriptor table (LDT),
+    // since we don't use it.
+    lldt(0);
+}
+
+
+
+    static void
+boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
+{
+    int i;
+    for (i = 0; i < size; i += PGSIZE) 
+    {
+		pte_t *pte = pgdir_walk(pgdir, (void*)(va + i), 1);
+	if (pte) 
+		*pte = (pa + i) | perm | PTE_P;
+    }
 }
 
+
 //
 // Initialize the kernel virtual memory layout for environment e.
 // Allocate a page directory, set e->env_pgdir accordingly,
@@ -155,39 +181,44 @@ env_init_percpu(void)
 // Returns 0 on success, < 0 on error.  Errors include:
 //	-E_NO_MEM if page directory or table could not be allocated.
 //
-static int
+    static int
 env_setup_vm(struct Env *e)
 {
-	int i;
-	struct PageInfo *p = NULL;
+    int i;
+    struct PageInfo *p = NULL;
 
-	// Allocate a page for the page directory
-	if (!(p = page_alloc(ALLOC_ZERO)))
+    // Allocate a page for the page directory
+    if (!(p = page_alloc(ALLOC_ZERO)))
 		return -E_NO_MEM;
 
-	// Now, set e->env_pgdir and initialize the page directory.
-	//
-	// Hint:
-	//    - The VA space of all envs is identical above UTOP
-	//	(except at UVPT, which we've set below).
-	//	See inc/memlayout.h for permissions and layout.
-	//	Can you use kern_pgdir as a template?  Hint: Yes.
-	//	(Make sure you got the permissions right in Lab 2.)
-	//    - The initial VA below UTOP is empty.
-	//    - You do not need to make any more calls to page_alloc.
-	//    - Note: In general, pp_ref is not maintained for
-	//	physical pages mapped only above UTOP, but env_pgdir
-	//	is an exception -- you need to increment env_pgdir's
-	//	pp_ref for env_free to work correctly.
-	//    - The functions in kern/pmap.h are handy.
-
-	// LAB 3: Your code here.
-
-	// UVPT maps the env's own page table read-only.
-	// Permissions: kernel R, user R
-	e->env_pgdir[PDX(UVPT)] = PADDR(e->env_pgdir) | PTE_P | PTE_U;
-
-	return 0;
+    // Now, set e->env_pgdir and initialize the page directory.
+    //
+    // Hint:
+    //    - The VA space of all envs is identical above UTOP
+    //	(except at UVPT, which we've set below).
+    //	See inc/memlayout.h for permissions and layout.
+    //	Can you use kern_pgdir as a template?  Hint: Yes.
+    //	(Make sure you got the permissions right in Lab 2.)
+    //    - The initial VA below UTOP is empty.
+    //    - You do not need to make any more calls to page_alloc.
+    //    - Note: In general, pp_ref is not maintained for
+    //	physical pages mapped only above UTOP, but env_pgdir
+    //	is an exception -- you need to increment env_pgdir's
+    //	pp_ref for env_free to work correctly.
+    //    - The functions in kern/pmap.h are handy.
+
+    // LAB 3: Your code here.
+    e->env_pgdir = (pde_t*)page2kva(p);
+    memcpy(e->env_pgdir, kern_pgdir, PGSIZE);
+    memset(e->env_pgdir, 0, PDX(UTOP) * sizeof(pte_t));
+    p->pp_ref++;
+
+
+    // UVPT maps the env's own page table read-only.
+    // Permissions: kernel R, user R
+    e->env_pgdir[PDX(UVPT)] = PADDR(e->env_pgdir) | PTE_P | PTE_U;
+
+    return 0;
 }
 
 //
@@ -198,68 +229,70 @@ env_setup_vm(struct Env *e)
 //	-E_NO_FREE_ENV if all NENVS environments are allocated
 //	-E_NO_MEM on memory exhaustion
 //
-int
+    int
 env_alloc(struct Env **newenv_store, envid_t parent_id)
 {
-	int32_t generation;
-	int r;
-	struct Env *e;
+    int32_t generation;
+    int r;
+    struct Env *e;
 
-	if (!(e = env_free_list))
+    if (!(e = env_free_list))
 		return -E_NO_FREE_ENV;
 
-	// Allocate and set up the page directory for this environment.
-	if ((r = env_setup_vm(e)) < 0)
+    // Allocate and set up the page directory for this environment.
+    if ((r = env_setup_vm(e)) < 0)
 		return r;
 
-	// Generate an env_id for this environment.
-	generation = (e->env_id + (1 << ENVGENSHIFT)) & ~(NENV - 1);
-	if (generation <= 0)	// Don't create a negative env_id.
+    // Generate an env_id for this environment.
+    generation = (e->env_id + (1 << ENVGENSHIFT)) & ~(NENV - 1);
+    if (generation <= 0)	// Don't create a negative env_id.
 		generation = 1 << ENVGENSHIFT;
-	e->env_id = generation | (e - envs);
-
-	// Set the basic status variables.
-	e->env_parent_id = parent_id;
-	e->env_type = ENV_TYPE_USER;
-	e->env_status = ENV_RUNNABLE;
-	e->env_runs = 0;
-
-	// Clear out all the saved register state,
-	// to prevent the register values
-	// of a prior environment inhabiting this Env structure
-	// from "leaking" into our new environment.
-	memset(&e->env_tf, 0, sizeof(e->env_tf));
-
-	// Set up appropriate initial values for the segment registers.
-	// GD_UD is the user data segment selector in the GDT, and
-	// GD_UT is the user text segment selector (see inc/memlayout.h).
-	// The low 2 bits of each segment register contains the
-	// Requestor Privilege Level (RPL); 3 means user mode.  When
-	// we switch privilege levels, the hardware does various
-	// checks involving the RPL and the Descriptor Privilege Level
-	// (DPL) stored in the descriptors themselves.
-	e->env_tf.tf_ds = GD_UD | 3;
-	e->env_tf.tf_es = GD_UD | 3;
-	e->env_tf.tf_ss = GD_UD | 3;
-	e->env_tf.tf_esp = USTACKTOP;
-	e->env_tf.tf_cs = GD_UT | 3;
-	// You will set e->env_tf.tf_eip later.
-
-	// Enable interrupts while in user mode.
-	// LAB 4: Your code here.
-
-	// Clear the page fault handler until user installs one.
-	e->env_pgfault_upcall = 0;
-
-	// Also clear the IPC receiving flag.
-	e->env_ipc_recving = 0;
-
-	// commit the allocation
-	env_free_list = e->env_link;
-	*newenv_store = e;
-
-	// cprintf("[%08x] new env %08x\n", curenv ? curenv->env_id : 0, e->env_id);
-	return 0;
+    e->env_id = generation | (e - envs);
+
+    // Set the basic status variables.
+    e->env_parent_id = parent_id;
+    e->env_type = ENV_TYPE_USER;
+    e->env_status = ENV_RUNNABLE;
+    e->env_runs = 0;
+
+    // Clear out all the saved register state,
+    // to prevent the register values
+    // of a prior environment inhabiting this Env structure
+    // from "leaking" into our new environment.
+    memset(&e->env_tf, 0, sizeof(e->env_tf));
+
+    // Set up appropriate initial values for the segment registers.
+    // GD_UD is the user data segment selector in the GDT, and
+    // GD_UT is the user text segment selector (see inc/memlayout.h).
+    // The low 2 bits of each segment register contains the
+    // Requestor Privilege Level (RPL); 3 means user mode.  When
+    // we switch privilege levels, the hardware does various
+    // checks involving the RPL and the Descriptor Privilege Level
+    // (DPL) stored in the descriptors themselves.
+    e->env_tf.tf_ds = GD_UD | 3;
+    e->env_tf.tf_es = GD_UD | 3;
+    e->env_tf.tf_ss = GD_UD | 3;
+    e->env_tf.tf_esp = USTACKTOP;
+    e->env_tf.tf_cs = GD_UT | 3;
+    // You will set e->env_tf.tf_eip later.
+
+    // Enable interrupts while in user mode.
+    // LAB 4: Your code here.
+    e->env_tf.tf_eflags |= FL_IF;
+
+
+    // Clear the page fault handler until user installs one.
+    e->env_pgfault_upcall = 0;
+
+    // Also clear the IPC receiving flag.
+    e->env_ipc_recving = 0;
+
+    // commit the allocation
+    env_free_list = e->env_link;
+    *newenv_store = e;
+
+    cprintf("[%08x] new env %08x\n", curenv ? curenv->env_id : 0, e->env_id);
+    return 0;
 }
 
 //
@@ -269,16 +302,28 @@ env_alloc(struct Env **newenv_store, envid_t parent_id)
 // Pages should be writable by user and kernel.
 // Panic if any allocation attempt fails.
 //
-static void
+    static void
 region_alloc(struct Env *e, void *va, size_t len)
 {
-	// LAB 3: Your code here.
-	// (But only if you need it for load_icode.)
-	//
-	// Hint: It is easier to use region_alloc if the caller can pass
-	//   'va' and 'len' values that are not page-aligned.
-	//   You should round va down, and round (va + len) up.
-	//   (Watch out for corner-cases!)
+    // LAB 3: Your code here.
+    // (But only if you need it for load_icode.)
+    //
+    // Hint: It is easier to use region_alloc if the caller can pass
+    //   'va' and 'len' values that are not page-aligned.
+    //   You should round va down, and round (va + len) up.
+    //   (Watch out for corner-cases!)
+    int l = 0, va_ = (uintptr_t)va;
+    struct PageInfo *p;
+    va = (void*)ROUNDDOWN(va_, PGSIZE);
+    len = ROUNDUP(va_ + len, PGSIZE) - (uintptr_t)va;
+    for (; l < len; l += PGSIZE) 
+    {
+		p = page_alloc(0);
+	if (!p) 
+		panic("Panic: region_alloc()\n");
+	if (page_insert(e->env_pgdir, p, va + l, PTE_U | PTE_W))
+	    panic("Panic: region_alloc()\n");
+    }
 }
 
 //
@@ -303,43 +348,64 @@ region_alloc(struct Env *e, void *va, size_t len)
 // load_icode panics if it encounters problems.
 //  - How might load_icode fail?  What might be wrong with the given input?
 //
-static void
+    static void
 load_icode(struct Env *e, uint8_t *binary)
 {
-	// Hints:
-	//  Load each program segment into virtual memory
-	//  at the address specified in the ELF segment header.
-	//  You should only load segments with ph->p_type == ELF_PROG_LOAD.
-	//  Each segment's virtual address can be found in ph->p_va
-	//  and its size in memory can be found in ph->p_memsz.
-	//  The ph->p_filesz bytes from the ELF binary, starting at
-	//  'binary + ph->p_offset', should be copied to virtual address
-	//  ph->p_va.  Any remaining memory bytes should be cleared to zero.
-	//  (The ELF header should have ph->p_filesz <= ph->p_memsz.)
-	//  Use functions from the previous lab to allocate and map pages.
-	//
-	//  All page protection bits should be user read/write for now.
-	//  ELF segments are not necessarily page-aligned, but you can
-	//  assume for this function that no two segments will touch
-	//  the same virtual page.
-	//
-	//  You may find a function like region_alloc useful.
-	//
-	//  Loading the segments is much simpler if you can move data
-	//  directly into the virtual addresses stored in the ELF binary.
-	//  So which page directory should be in force during
-	//  this function?
-	//
-	//  You must also do something with the program's entry point,
-	//  to make sure that the environment starts executing there.
-	//  What?  (See env_run() and env_pop_tf() below.)
-
-	// LAB 3: Your code here.
-
-	// Now map one page for the program's initial stack
-	// at virtual address USTACKTOP - PGSIZE.
-
-	// LAB 3: Your code here.
+    // Hints:
+    //  Load each program segment into virtual memory
+    //  at the address specified in the ELF section header.
+    //  You should only load segments with ph->p_type == ELF_PROG_LOAD.
+    //  Each segment's virtual address can be found in ph->p_va
+    //  and its size in memory can be found in ph->p_memsz.
+    //  The ph->p_filesz bytes from the ELF binary, starting at
+    //  'binary + ph->p_offset', should be copied to virtual address
+    //  ph->p_va.  Any remaining memory bytes should be cleared to zero.
+    //  (The ELF header should have ph->p_filesz <= ph->p_memsz.)
+    //  Use functions from the previous lab to allocate and map pages.
+    //
+    //  All page protection bits should be user read/write for now.
+    //  ELF segments are not necessarily page-aligned, but you can
+    //  assume for this function that no two segments will touch
+    //  the same virtual page.
+    //
+    //  You may find a function like region_alloc useful.
+    //
+    //  Loading the segments is much simpler if you can move data
+    //  directly into the virtual addresses stored in the ELF binary.
+    //  So which page directory should be in force during
+    //  this function?
+    //
+    //  You must also do something with the program's entry point,
+    //  to make sure that the environment starts executing there.
+    //  What?  (See env_run() and env_pop_tf() below.)
+
+    // LAB 3: Your code here.
+    struct Elf *elf = (struct Elf*)binary;
+    struct Proghdr *ph, *eph;
+    struct PageInfo *pp;
+    unsigned i, va, sz, delta;
+
+    if (elf->e_magic != ELF_MAGIC) 
+		panic("Panic: load_icode() ELF_MAGIC\n");
+    ph = (struct Proghdr*)(binary + elf->e_phoff);
+    eph = ph + elf->e_phnum;
+    lcr3(PADDR(e->env_pgdir));
+    for (; ph < eph; ph++) 
+    {
+		if (ph->p_type != ELF_PROG_LOAD) 
+			continue;
+		region_alloc(e, (void*)ph->p_va, ph->p_memsz);
+		memset((void*)ph->p_va, 0, ph->p_memsz);
+		memcpy((void*)ph->p_va, binary + ph->p_offset, ph->p_filesz); 
+    }
+    lcr3(PADDR(kern_pgdir));
+    e->env_tf.tf_eip = elf->e_entry;
+
+    // Now map one page for the program's initial stack
+    // at virtual address USTACKTOP - PGSIZE.
+
+    // LAB 3: Your code here.
+    region_alloc(e, (void*)(USTACKTOP - PGSIZE), PGSIZE);
 }
 
 //
@@ -349,66 +415,74 @@ load_icode(struct Env *e, uint8_t *binary)
 // before running the first user-mode environment.
 // The new env's parent ID is set to 0.
 //
-void
+    void
 env_create(uint8_t *binary, enum EnvType type)
 {
-	// LAB 3: Your code here.
-
-	// If this is the file server (type == ENV_TYPE_FS) give it I/O privileges.
-	// LAB 5: Your code here.
+    // LAB 3: Your code here.
+    struct Env *e;
+    env_alloc(&e, 0);
+    load_icode(e, binary);
+    e->env_type = type;
+
+    // If this is the file server (type == ENV_TYPE_FS) give it I/O privileges.
+    // LAB 5: Your code here.
+    e->env_tf.tf_eflags &= ~FL_IOPL_MASK;
+    if (type == ENV_TYPE_FS)
+		e->env_tf.tf_eflags |= FL_IOPL_3;
+    else
+		e->env_tf.tf_eflags |= FL_IOPL_0;
 }
-
 //
 // Frees env e and all memory it uses.
 //
-void
+    void
 env_free(struct Env *e)
 {
-	pte_t *pt;
-	uint32_t pdeno, pteno;
-	physaddr_t pa;
-
-	// If freeing the current environment, switch to kern_pgdir
-	// before freeing the page directory, just in case the page
-	// gets reused.
-	if (e == curenv)
+    pte_t *pt;
+    uint32_t pdeno, pteno;
+    physaddr_t pa;
+
+    // If freeing the current environment, switch to kern_pgdir
+    // before freeing the page directory, just in case the page
+    // gets reused.
+    if (e == curenv)
 		lcr3(PADDR(kern_pgdir));
 
-	// Note the environment's demise.
-	// cprintf("[%08x] free env %08x\n", curenv ? curenv->env_id : 0, e->env_id);
-
-	// Flush all mapped pages in the user portion of the address space
-	static_assert(UTOP % PTSIZE == 0);
-	for (pdeno = 0; pdeno < PDX(UTOP); pdeno++) {
+    // Note the environment's demise.
+    cprintf("[%08x] free env %08x\n", curenv ? curenv->env_id : 0, e->env_id);
 
-		// only look at mapped page tables
-		if (!(e->env_pgdir[pdeno] & PTE_P))
-			continue;
+    // Flush all mapped pages in the user portion of the address space
+    static_assert(UTOP % PTSIZE == 0);
+    for (pdeno = 0; pdeno < PDX(UTOP); pdeno++) {
 
-		// find the pa and va of the page table
-		pa = PTE_ADDR(e->env_pgdir[pdeno]);
-		pt = (pte_t*) KADDR(pa);
+	// only look at mapped page tables
+	if (!(e->env_pgdir[pdeno] & PTE_P))
+	    continue;
 
-		// unmap all PTEs in this page table
-		for (pteno = 0; pteno <= PTX(~0); pteno++) {
-			if (pt[pteno] & PTE_P)
-				page_remove(e->env_pgdir, PGADDR(pdeno, pteno, 0));
-		}
+	// find the pa and va of the page table
+	pa = PTE_ADDR(e->env_pgdir[pdeno]);
+	pt = (pte_t*) KADDR(pa);
 
-		// free the page table itself
-		e->env_pgdir[pdeno] = 0;
-		page_decref(pa2page(pa));
+	// unmap all PTEs in this page table
+	for (pteno = 0; pteno <= PTX(~0); pteno++) {
+	    if (pt[pteno] & PTE_P)
+		page_remove(e->env_pgdir, PGADDR(pdeno, pteno, 0));
 	}
 
-	// free the page directory
-	pa = PADDR(e->env_pgdir);
-	e->env_pgdir = 0;
+	// free the page table itself
+	e->env_pgdir[pdeno] = 0;
 	page_decref(pa2page(pa));
+    }
 
-	// return the environment to the free list
-	e->env_status = ENV_FREE;
-	e->env_link = env_free_list;
-	env_free_list = e;
+    // free the page directory
+    pa = PADDR(e->env_pgdir);
+    e->env_pgdir = 0;
+    page_decref(pa2page(pa));
+
+    // return the environment to the free list
+    e->env_status = ENV_FREE;
+    e->env_link = env_free_list;
+    env_free_list = e;
 }
 
 //
@@ -416,23 +490,25 @@ env_free(struct Env *e)
 // If e was the current env, then runs a new environment (and does not return
 // to the caller).
 //
-void
+    void
 env_destroy(struct Env *e)
 {
-	// If e is currently running on other CPUs, we change its state to
-	// ENV_DYING. A zombie environment will be freed the next time
-	// it traps to the kernel.
-	if (e->env_status == ENV_RUNNING && curenv != e) {
+    // If e is currently running on other CPUs, we change its state to
+    // ENV_DYING. A zombie environment will be freed the next time
+    // it traps to the kernel.
+    if (e->env_status == ENV_RUNNING && curenv != e) 
+    {
 		e->env_status = ENV_DYING;
 		return;
-	}
+    }
 
-	env_free(e);
+    env_free(e);
 
-	if (curenv == e) {
+    if (curenv == e) 
+    {
 		curenv = NULL;
 		sched_yield();
-	}
+    }
 }
 
 
@@ -442,21 +518,23 @@ env_destroy(struct Env *e)
 //
 // This function does not return.
 //
-void
+    void
 env_pop_tf(struct Trapframe *tf)
 {
-	// Record the CPU we are running on for user-space debugging
-	curenv->env_cpunum = cpunum();
-
-	asm volatile(
-		"\tmovl %0,%%esp\n"
-		"\tpopal\n"
-		"\tpopl %%es\n"
-		"\tpopl %%ds\n"
-		"\taddl $0x8,%%esp\n" /* skip tf_trapno and tf_errcode */
-		"\tiret\n"
-		: : "g" (tf) : "memory");
-	panic("iret failed");  /* mostly to placate the compiler */
+    // Record the CPU we are running on for user-space debugging
+    curenv->env_cpunum = cpunum();
+    unlock_kernel();
+
+
+    asm volatile(
+	    "\tmovl %0,%%esp\n"
+	    "\tpopal\n"
+	    "\tpopl %%es\n"
+	    "\tpopl %%ds\n"
+	    "\taddl $0x8,%%esp\n" /* skip tf_trapno and tf_errcode */
+	    "\tiret\n"
+	    : : "g" (tf) : "memory");
+    panic("iret failed");  /* mostly to placate the compiler */
 }
 
 //
@@ -465,28 +543,37 @@ env_pop_tf(struct Trapframe *tf)
 //
 // This function does not return.
 //
-void
+    void
 env_run(struct Env *e)
 {
-	// Step 1: If this is a context switch (a new environment is running):
-	//	   1. Set the current environment (if any) back to
-	//	      ENV_RUNNABLE if it is ENV_RUNNING (think about
-	//	      what other states it can be in),
-	//	   2. Set 'curenv' to the new environment,
-	//	   3. Set its status to ENV_RUNNING,
-	//	   4. Update its 'env_runs' counter,
-	//	   5. Use lcr3() to switch to its address space.
-	// Step 2: Use env_pop_tf() to restore the environment's
-	//	   registers and drop into user mode in the
-	//	   environment.
-
-	// Hint: This function loads the new environment's state from
-	//	e->env_tf.  Go back through the code you wrote above
-	//	and make sure you have set the relevant parts of
-	//	e->env_tf to sensible values.
-
-	// LAB 3: Your code here.
-
-	panic("env_run not yet implemented");
+    // Step 1: If this is a context switch (a new environment is running):
+    //	   1. Set the current environment (if any) back to
+    //	      ENV_RUNNABLE if it is ENV_RUNNING (think about
+    //	      what other states it can be in),
+    //	   2. Set 'curenv' to the new environment,
+    //	   3. Set its status to ENV_RUNNING,
+    //	   4. Update its 'env_runs' counter,
+    //	   5. Use lcr3() to switch to its address space.
+    // Step 2: Use env_pop_tf() to restore the environment's
+    //	   registers and drop into user mode in the
+    //	   environment.
+
+    // Hint: This function loads the new environment's state from
+    //	e->env_tf.  Go back through the code you wrote above
+    //	and make sure you have set the relevant parts of
+    //	e->env_tf to sensible values.
+
+    // LAB 3: Your code here.
+    if (curenv) 
+    {
+		if (curenv->env_status == ENV_RUNNING)
+	    	curenv->env_status = ENV_RUNNABLE;
+    }
+    curenv = e;
+    curenv->env_status = ENV_RUNNING;
+    curenv->env_runs++;
+    lcr3(PADDR(e->env_pgdir));
+
+    env_pop_tf(&e->env_tf);
 }
 
diff --git a/kern/env.h b/kern/env.h
old mode 100644
new mode 100755
diff --git a/kern/grade-lab1 b/kern/grade-lab1
new file mode 100755
index 0000000..94bcb0f
--- /dev/null
+++ b/kern/grade-lab1
@@ -0,0 +1,44 @@
+#!/usr/bin/env python
+
+import re
+from gradelib import *
+
+r = Runner(save("jos.out"),
+           stop_breakpoint("readline"))
+
+@test(0, "running JOS")
+def test_jos():
+    r.run_qemu()
+
+@test(20, parent=test_jos)
+def test_printf():
+    r.match("6828 decimal is 15254 octal!")
+
+BACKTRACE_RE = r"^ *ebp +f01[0-9a-z]{5} +eip +f0100[0-9a-z]{3} +args +([0-9a-z]+)"
+
+@test(10, parent=test_jos)
+def test_backtrace_count():
+    matches = re.findall(BACKTRACE_RE, r.qemu.output, re.MULTILINE)
+    assert_equal(len(matches), 8)
+
+@test(10, parent=test_jos)
+def test_backtrace_arguments():
+    matches = re.findall(BACKTRACE_RE, r.qemu.output, re.MULTILINE)
+    assert_equal("\n".join(matches[:7]),
+                 "\n".join("%08x" % n for n in [0,0,1,2,3,4,5]))
+
+@test(5, parent=test_jos)
+def test_backtrace_symbols():
+    matches = re.findall(r"kern/init.c:[0-9]+: +([^+]*)\+", r.qemu.output)
+    assert_equal("\n".join(matches[:7]),
+                 "\n".join(["test_backtrace"] * 6 + ["i386_init"]))
+
+@test(5, parent=test_jos)
+def test_backtrace_lines():
+    matches = re.findall(r"([^ ]*init.c:([0-9]+):) +test_backtrace\+", r.qemu.output)
+    assert matches, "No line numbers"
+    if any(int(m[1]) < 5 or int(m[1]) > 50 for m in matches):
+        assert_equal("\n".join(m[0] for m in matches),
+                     "Line numbers between 5 and 50")
+
+run_tests()
diff --git a/kern/init.c b/kern/init.c
old mode 100644
new mode 100755
index f00fd99..38d1cd3
--- a/kern/init.c
+++ b/kern/init.c
@@ -18,58 +18,62 @@
 static void boot_aps(void);
 
 
-void
+    void
 i386_init(void)
 {
-	extern char edata[], end[];
+    extern char edata[], end[];
 
-	// Before doing anything else, complete the ELF loading process.
-	// Clear the uninitialized global data (BSS) section of our program.
-	// This ensures that all static/global variables start out zero.
-	memset(edata, 0, end - edata);
+    // Before doing anything else, complete the ELF loading process.
+    // Clear the uninitialized global data (BSS) section of our program.
+    // This ensures that all static/global variables start out zero.
+    memset(edata, 0, end - edata);
 
-	// Initialize the console.
-	// Can't call cprintf until after we do this!
-	cons_init();
+    // Initialize the console.
+    // Can't call cprintf until after we do this!
+    cons_init();
 
-	cprintf("6828 decimal is %o octal!\n", 6828);
+    cprintf("6828 decimal is %o octal!\n", 6828);
 
-	// Lab 2 memory management initialization functions
-	mem_init();
+    // Lab 2 memory management initialization functions
+    mem_init();
 
-	// Lab 3 user environment initialization functions
-	env_init();
-	trap_init();
+    // Lab 3 user environment initialization functions
+    env_init();
+    trap_init();
 
-	// Lab 4 multiprocessor initialization functions
-	mp_init();
-	lapic_init();
+    // Lab 4 multiprocessor initialization functions
+    mp_init();
+    lapic_init();
 
-	// Lab 4 multitasking initialization functions
-	pic_init();
+    // Lab 4 multitasking initialization functions
+    pic_init();
 
-	// Acquire the big kernel lock before waking up APs
-	// Your code here:
+    // Acquire the big kernel lock before waking up APs
+    // Your code here:
+    spin_initlock(&kernel_lock);
+    lock_kernel();
 
-	// Starting non-boot CPUs
-	boot_aps();
+    // Starting non-boot CPUs
+    boot_aps();
 
-	// Start fs.
-	ENV_CREATE(fs_fs, ENV_TYPE_FS);
+
+
+    // Start fs.
+    ENV_CREATE(fs_fs, ENV_TYPE_FS);
 
 #if defined(TEST)
-	// Don't touch -- used by grading script!
-	ENV_CREATE(TEST, ENV_TYPE_USER);
+    // Don't touch -- used by grading script!
+    ENV_CREATE(TEST, ENV_TYPE_USER);
 #else
-	// Touch all you want.
-	ENV_CREATE(user_icode, ENV_TYPE_USER);
+    // Touch all you want.
+    ENV_CREATE(user_icode, ENV_TYPE_USER);
 #endif // TEST*
 
-	// Should not be necessary - drains keyboard because interrupt has given up.
-	kbd_intr();
+    // Should not be necessary - drains keyboard because interrupt has given up.
+    kbd_intr();
 
-	// Schedule and run the first user environment!
-	sched_yield();
+    // Schedule and run the first user environment!
+    sched_yield();
 }
 
 // While boot_aps is booting a given CPU, it communicates the per-core
@@ -78,53 +82,53 @@ i386_init(void)
 void *mpentry_kstack;
 
 // Start the non-boot (AP) processors.
-static void
+    static void
 boot_aps(void)
 {
-	extern unsigned char mpentry_start[], mpentry_end[];
-	void *code;
-	struct CpuInfo *c;
-
-	// Write entry code to unused memory at MPENTRY_PADDR
-	code = KADDR(MPENTRY_PADDR);
-	memmove(code, mpentry_start, mpentry_end - mpentry_start);
-
-	// Boot each AP one at a time
-	for (c = cpus; c < cpus + ncpu; c++) {
-		if (c == cpus + cpunum())  // We've started already.
-			continue;
-
-		// Tell mpentry.S what stack to use 
-		mpentry_kstack = percpu_kstacks[c - cpus] + KSTKSIZE;
-		// Start the CPU at mpentry_start
-		lapic_startap(c->cpu_id, PADDR(code));
-		// Wait for the CPU to finish some basic setup in mp_main()
-		while(c->cpu_status != CPU_STARTED)
-			;
-	}
+    extern unsigned char mpentry_start[], mpentry_end[];
+    void *code;
+    struct CpuInfo *c;
+
+    // Write entry code to unused memory at MPENTRY_PADDR
+    code = KADDR(MPENTRY_PADDR);
+    memmove(code, mpentry_start, mpentry_end - mpentry_start);
+
+    // Boot each AP one at a time
+    for (c = cpus; c < cpus + ncpu; c++) {
+	if (c == cpus + cpunum())  // We've started already.
+	    continue;
+
+	// Tell mpentry.S what stack to use 
+	mpentry_kstack = percpu_kstacks[c - cpus] + KSTKSIZE;
+	// Start the CPU at mpentry_start
+	lapic_startap(c->cpu_id, PADDR(code));
+	// Wait for the CPU to finish some basic setup in mp_main()
+	while(c->cpu_status != CPU_STARTED)
+	    ;
+    }
 }
 
 // Setup code for APs
-void
+    void
 mp_main(void)
 {
-	// We are in high EIP now, safe to switch to kern_pgdir 
-	lcr3(PADDR(kern_pgdir));
-	cprintf("SMP: CPU %d starting\n", cpunum());
-
-	lapic_init();
-	env_init_percpu();
-	trap_init_percpu();
-	xchg(&thiscpu->cpu_status, CPU_STARTED); // tell boot_aps() we're up
-
-	// Now that we have finished some basic setup, call sched_yield()
-	// to start running processes on this CPU.  But make sure that
-	// only one CPU can enter the scheduler at a time!
-	//
-	// Your code here:
-
-	// Remove this after you finish Exercise 4
-	for (;;);
+    // We are in high EIP now, safe to switch to kern_pgdir 
+    lcr3(PADDR(kern_pgdir));
+    cprintf("SMP: CPU %d starting\n", cpunum());
+
+    lapic_init();
+    env_init_percpu();
+    trap_init_percpu();
+    xchg(&thiscpu->cpu_status, CPU_STARTED); // tell boot_aps() we're up
+
+    // Now that we have finished some basic setup, call sched_yield()
+    // to start running processes on this CPU.  But make sure that
+    // only one CPU can enter the scheduler at a time!
+    //
+    // Your code here:
+    lock_kernel();
+
+    sched_yield();
 }
 
 /*
@@ -137,39 +141,39 @@ const char *panicstr;
  * Panic is called on unresolvable fatal errors.
  * It prints "panic: mesg", and then enters the kernel monitor.
  */
-void
+    void
 _panic(const char *file, int line, const char *fmt,...)
 {
-	va_list ap;
+    va_list ap;
 
-	if (panicstr)
-		goto dead;
-	panicstr = fmt;
+    if (panicstr)
+	goto dead;
+    panicstr = fmt;
 
-	// Be extra sure that the machine is in as reasonable state
-	asm volatile("cli; cld");
+    // Be extra sure that the machine is in as reasonable state
+    asm volatile("cli; cld");
 
-	va_start(ap, fmt);
-	cprintf("kernel panic on CPU %d at %s:%d: ", cpunum(), file, line);
-	vcprintf(fmt, ap);
-	cprintf("\n");
-	va_end(ap);
+    va_start(ap, fmt);
+    cprintf("kernel panic on CPU %d at %s:%d: ", cpunum(), file, line);
+    vcprintf(fmt, ap);
+    cprintf("\n");
+    va_end(ap);
 
 dead:
-	/* break into the kernel monitor */
-	while (1)
-		monitor(NULL);
+    /* break into the kernel monitor */
+    while (1)
+	monitor(NULL);
 }
 
 /* like panic, but don't */
-void
+    void
 _warn(const char *file, int line, const char *fmt,...)
 {
-	va_list ap;
+    va_list ap;
 
-	va_start(ap, fmt);
-	cprintf("kernel warning at %s:%d: ", file, line);
-	vcprintf(fmt, ap);
-	cprintf("\n");
-	va_end(ap);
+    va_start(ap, fmt);
+    cprintf("kernel warning at %s:%d: ", file, line);
+    vcprintf(fmt, ap);
+    cprintf("\n");
+    va_end(ap);
 }
diff --git a/kern/kclock.c b/kern/kclock.c
old mode 100644
new mode 100755
diff --git a/kern/kclock.h b/kern/kclock.h
old mode 100644
new mode 100755
diff --git a/kern/kdebug.c b/kern/kdebug.c
old mode 100644
new mode 100755
index f4ee8ee..640408a
--- a/kern/kdebug.c
+++ b/kern/kdebug.c
@@ -13,10 +13,10 @@ extern const char __STABSTR_BEGIN__[];		// Beginning of string table
 extern const char __STABSTR_END__[];		// End of string table
 
 struct UserStabData {
-	const struct Stab *stabs;
-	const struct Stab *stab_end;
-	const char *stabstr;
-	const char *stabstr_end;
+    const struct Stab *stabs;
+    const struct Stab *stab_end;
+    const char *stabstr;
+    const char *stabstr_end;
 };
 
 
@@ -56,50 +56,50 @@ struct UserStabData {
 //		stab_binsearch(stabs, &left, &right, N_SO, 0xf0100184);
 //	will exit setting left = 118, right = 554.
 //
-static void
+    static void
 stab_binsearch(const struct Stab *stabs, int *region_left, int *region_right,
-	       int type, uintptr_t addr)
+	int type, uintptr_t addr)
 {
-	int l = *region_left, r = *region_right, any_matches = 0;
-
-	while (l <= r) {
-		int true_m = (l + r) / 2, m = true_m;
-
-		// search for earliest stab with right type
-		while (m >= l && stabs[m].n_type != type)
-			m--;
-		if (m < l) {	// no match in [l, m]
-			l = true_m + 1;
-			continue;
-		}
-
-		// actual binary search
-		any_matches = 1;
-		if (stabs[m].n_value < addr) {
-			*region_left = m;
-			l = true_m + 1;
-		} else if (stabs[m].n_value > addr) {
-			*region_right = m - 1;
-			r = m - 1;
-		} else {
-			// exact match for 'addr', but continue loop to find
-			// *region_right
-			*region_left = m;
-			l = m;
-			addr++;
-		}
+    int l = *region_left, r = *region_right, any_matches = 0;
+
+    while (l <= r) {
+	int true_m = (l + r) / 2, m = true_m;
+
+	// search for earliest stab with right type
+	while (m >= l && stabs[m].n_type != type)
+	    m--;
+	if (m < l) {	// no match in [l, m]
+	    l = true_m + 1;
+	    continue;
 	}
 
-	if (!any_matches)
-		*region_right = *region_left - 1;
-	else {
-		// find rightmost region containing 'addr'
-		for (l = *region_right;
-		     l > *region_left && stabs[l].n_type != type;
-		     l--)
-			/* do nothing */;
-		*region_left = l;
+	// actual binary search
+	any_matches = 1;
+	if (stabs[m].n_value < addr) {
+	    *region_left = m;
+	    l = true_m + 1;
+	} else if (stabs[m].n_value > addr) {
+	    *region_right = m - 1;
+	    r = m - 1;
+	} else {
+	    // exact match for 'addr', but continue loop to find
+	    // *region_right
+	    *region_left = m;
+	    l = m;
+	    addr++;
 	}
+    }
+
+    if (!any_matches)
+	*region_right = *region_left - 1;
+    else {
+	// find rightmost region containing 'addr'
+	for (l = *region_right;
+		l > *region_left && stabs[l].n_type != type;
+		l--)
+	    /* do nothing */;
+	*region_left = l;
+    }
 }
 
 
@@ -110,122 +110,139 @@ stab_binsearch(const struct Stab *stabs, int *region_left, int *region_right,
 //	negative if not.  But even if it returns negative it has stored some
 //	information into '*info'.
 //
-int
+    int
 debuginfo_eip(uintptr_t addr, struct Eipdebuginfo *info)
 {
-	const struct Stab *stabs, *stab_end;
-	const char *stabstr, *stabstr_end;
-	int lfile, rfile, lfun, rfun, lline, rline;
-
-	// Initialize *info
-	info->eip_file = "<unknown>";
-	info->eip_line = 0;
-	info->eip_fn_name = "<unknown>";
-	info->eip_fn_namelen = 9;
-	info->eip_fn_addr = addr;
-	info->eip_fn_narg = 0;
-
-	// Find the relevant set of stabs
-	if (addr >= ULIM) {
+    const struct Stab *stabs, *stab_end;
+    const char *stabstr, *stabstr_end;
+    int lfile, rfile, lfun, rfun, lline, rline;
+
+    // Initialize *info
+    info->eip_file = "<unknown>";
+    info->eip_line = 0;
+    info->eip_fn_name = "<unknown>";
+    info->eip_fn_namelen = 9;
+    info->eip_fn_addr = addr;
+    info->eip_fn_narg = 0;
+
+    // Find the relevant set of stabs
+    if (addr >= ULIM) 
+    {
 		stabs = __STAB_BEGIN__;
 		stab_end = __STAB_END__;
 		stabstr = __STABSTR_BEGIN__;
 		stabstr_end = __STABSTR_END__;
-	} else {
-		// The user-application linker script, user/user.ld,
-		// puts information about the application's stabs (equivalent
-		// to __STAB_BEGIN__, __STAB_END__, __STABSTR_BEGIN__, and
-		// __STABSTR_END__) in a structure located at virtual address
-		// USTABDATA.
-		const struct UserStabData *usd = (const struct UserStabData *) USTABDATA;
-
-		// Make sure this memory is valid.
-		// Return -1 if it is not.  Hint: Call user_mem_check.
-		// LAB 3: Your code here.
-
-		stabs = usd->stabs;
-		stab_end = usd->stab_end;
-		stabstr = usd->stabstr;
-		stabstr_end = usd->stabstr_end;
-
-		// Make sure the STABS and string table memory is valid.
-		// LAB 3: Your code here.
-	}
-
-	// String table validity checks
-	if (stabstr_end <= stabstr || stabstr_end[-1] != 0)
+    } 
+    else 
+    {
+	// The user-application linker script, user/user.ld,
+	// puts information about the application's stabs (equivalent
+	// to __STAB_BEGIN__, __STAB_END__, __STABSTR_BEGIN__, and
+	// __STABSTR_END__) in a structure located at virtual address
+	// USTABDATA.
+	const struct UserStabData *usd = (const struct UserStabData *) USTABDATA;
+
+	// Make sure this memory is valid.
+	// Return -1 if it is not.  Hint: Call user_mem_check.
+	// LAB 3: Your code here.
+	if (user_mem_check(curenv, usd, sizeof(struct UserStabData), PTE_U) < 0)
+	    return -1;
+
+	stabs = usd->stabs;
+	stab_end = usd->stab_end;
+	stabstr = usd->stabstr;
+	stabstr_end = usd->stabstr_end;
+
+	// Make sure the STABS and string table memory is valid.
+	// LAB 3: Your code here.
+	if (user_mem_check(curenv, stabs, stab_end - stabs, PTE_U) < 0) 
 		return -1;
-
-	// Now we find the right stabs that define the function containing
-	// 'eip'.  First, we find the basic source file containing 'eip'.
-	// Then, we look in that source file for the function.  Then we look
-	// for the line number.
-
-	// Search the entire set of stabs for the source file (type N_SO).
-	lfile = 0;
-	rfile = (stab_end - stabs) - 1;
-	stab_binsearch(stabs, &lfile, &rfile, N_SO, addr);
-	if (lfile == 0)
+	if (user_mem_check(curenv, stabstr, stabstr_end - stabstr, PTE_U) < 0) 
+		return -1;
+    }
+
+    // String table validity checks
+    if (stabstr_end <= stabstr || stabstr_end[-1] != 0)
+	return -1;
+
+    // Now we find the right stabs that define the function containing
+    // 'eip'.  First, we find the basic source file containing 'eip'.
+    // Then, we look in that source file for the function.  Then we look
+    // for the line number.
+
+    // Search the entire set of stabs for the source file (type N_SO).
+    lfile = 0;
+    rfile = (stab_end - stabs) - 1;
+    stab_binsearch(stabs, &lfile, &rfile, N_SO, addr);
+    if (lfile == 0)
 		return -1;
 
-	// Search within that file's stabs for the function definition
-	// (N_FUN).
-	lfun = lfile;
-	rfun = rfile;
-	stab_binsearch(stabs, &lfun, &rfun, N_FUN, addr);
+    // Search within that file's stabs for the function definition
+    // (N_FUN).
+    lfun = lfile;
+    rfun = rfile;
+    stab_binsearch(stabs, &lfun, &rfun, N_FUN, addr);
 
-	if (lfun <= rfun) {
-		// stabs[lfun] points to the function name
-		// in the string table, but check bounds just in case.
+    if (lfun <= rfun) 
+    {
+	// stabs[lfun] points to the function name
+	// in the string table, but check bounds just in case.
 		if (stabs[lfun].n_strx < stabstr_end - stabstr)
-			info->eip_fn_name = stabstr + stabs[lfun].n_strx;
+	    	info->eip_fn_name = stabstr + stabs[lfun].n_strx;
 		info->eip_fn_addr = stabs[lfun].n_value;
 		addr -= info->eip_fn_addr;
 		// Search within the function definition for the line number.
 		lline = lfun;
 		rline = rfun;
-	} else {
+    } 
+    else 
+    {
 		// Couldn't find function stab!  Maybe we're in an assembly
 		// file.  Search the whole file for the line number.
 		info->eip_fn_addr = addr;
 		lline = lfile;
 		rline = rfile;
-	}
-	// Ignore stuff after the colon.
-	info->eip_fn_namelen = strfind(info->eip_fn_name, ':') - info->eip_fn_name;
-
-
-	// Search within [lline, rline] for the line number stab.
-	// If found, set info->eip_line to the right line number.
-	// If not found, return -1.
-	//
-	// Hint:
-	//	There's a particular stabs type used for line numbers.
-	//	Look at the STABS documentation and <inc/stab.h> to find
-	//	which one.
-	// Your code here.
-
-
-	// Search backwards from the line number for the relevant filename
-	// stab.
-	// We can't just use the "lfile" stab because inlined functions
-	// can interpolate code from a different file!
-	// Such included source files use the N_SOL stab type.
-	while (lline >= lfile
-	       && stabs[lline].n_type != N_SOL
-	       && (stabs[lline].n_type != N_SO || !stabs[lline].n_value))
-		lline--;
-	if (lline >= lfile && stabs[lline].n_strx < stabstr_end - stabstr)
+    }
+    // Ignore stuff after the colon.
+    info->eip_fn_namelen = strfind(info->eip_fn_name, ':') - info->eip_fn_name;
+
+
+    // Search within [lline, rline] for the line number stab.
+    // If found, set info->eip_line to the right line number.
+    // If not found, return -1.
+    //
+    // Hint:
+    //	There's a particular stabs type used for line numbers.
+    //	Look at the STABS documentation and <inc/stab.h> to find
+    //	which one.
+    // Your code here.
+    stab_binsearch(stabs, &lline, &rline, N_SLINE, addr);
+    if (lline <= rline) 
+    	info->eip_line = lline - lfun;
+    else 
+    	return -1;
+
+
+    // Search backwards from the line number for the relevant filename
+    // stab.
+    // We can't just use the "lfile" stab because inlined functions
+    // can interpolate code from a different file!
+    // Such included source files use the N_SOL stab type.
+    while (lline >= lfile
+	    && stabs[lline].n_type != N_SOL
+	    && (stabs[lline].n_type != N_SO || !stabs[lline].n_value))
+	lline--;
+    if (lline >= lfile && stabs[lline].n_strx < stabstr_end - stabstr)
 		info->eip_file = stabstr + stabs[lline].n_strx;
 
 
-	// Set eip_fn_narg to the number of arguments taken by the function,
-	// or 0 if there was no containing function.
-	if (lfun < rfun)
+    // Set eip_fn_narg to the number of arguments taken by the function,
+    // or 0 if there was no containing function.
+    if (lfun < rfun)
 		for (lline = lfun + 1;
-		     lline < rfun && stabs[lline].n_type == N_PSYM;
-		     lline++)
-			info->eip_fn_narg++;
+			lline < rfun && stabs[lline].n_type == N_PSYM;
+			lline++)
+	    	info->eip_fn_narg++;
 
-	return 0;
+    return 0;
 }
diff --git a/kern/kdebug.h b/kern/kdebug.h
old mode 100644
new mode 100755
diff --git a/kern/kernel.ld b/kern/kernel.ld
old mode 100644
new mode 100755
diff --git a/kern/lapic.c b/kern/lapic.c
old mode 100644
new mode 100755
index dc05777..d4984a4
--- a/kern/lapic.c
+++ b/kern/lapic.c
@@ -16,28 +16,28 @@
 #define TPR     (0x0080/4)   // Task Priority
 #define EOI     (0x00B0/4)   // EOI
 #define SVR     (0x00F0/4)   // Spurious Interrupt Vector
-	#define ENABLE     0x00000100   // Unit Enable
+#define ENABLE     0x00000100   // Unit Enable
 #define ESR     (0x0280/4)   // Error Status
 #define ICRLO   (0x0300/4)   // Interrupt Command
-	#define INIT       0x00000500   // INIT/RESET
-	#define STARTUP    0x00000600   // Startup IPI
-	#define DELIVS     0x00001000   // Delivery status
-	#define ASSERT     0x00004000   // Assert interrupt (vs deassert)
-	#define DEASSERT   0x00000000
-	#define LEVEL      0x00008000   // Level triggered
-	#define BCAST      0x00080000   // Send to all APICs, including self.
-	#define OTHERS     0x000C0000   // Send to all APICs, excluding self.
-	#define BUSY       0x00001000
-	#define FIXED      0x00000000
+#define INIT       0x00000500   // INIT/RESET
+#define STARTUP    0x00000600   // Startup IPI
+#define DELIVS     0x00001000   // Delivery status
+#define ASSERT     0x00004000   // Assert interrupt (vs deassert)
+#define DEASSERT   0x00000000
+#define LEVEL      0x00008000   // Level triggered
+#define BCAST      0x00080000   // Send to all APICs, including self.
+#define OTHERS     0x000C0000   // Send to all APICs, excluding self.
+#define BUSY       0x00001000
+#define FIXED      0x00000000
 #define ICRHI   (0x0310/4)   // Interrupt Command [63:32]
 #define TIMER   (0x0320/4)   // Local Vector Table 0 (TIMER)
-	#define X1         0x0000000B   // divide counts by 1
-	#define PERIODIC   0x00020000   // Periodic
+#define X1         0x0000000B   // divide counts by 1
+#define PERIODIC   0x00020000   // Periodic
 #define PCINT   (0x0340/4)   // Performance Counter LVT
 #define LINT0   (0x0350/4)   // Local Vector Table 1 (LINT0)
 #define LINT1   (0x0360/4)   // Local Vector Table 2 (LINT1)
 #define ERROR   (0x0370/4)   // Local Vector Table 3 (ERROR)
-	#define MASKED     0x00010000   // Interrupt masked
+#define MASKED     0x00010000   // Interrupt masked
 #define TICR    (0x0380/4)   // Timer Initial Count
 #define TCCR    (0x0390/4)   // Timer Current Count
 #define TDCR    (0x03E0/4)   // Timer Divide Configuration
diff --git a/kern/mergedep.pl b/kern/mergedep.pl
new file mode 100755
index 0000000..1730d53
--- /dev/null
+++ b/kern/mergedep.pl
@@ -0,0 +1,86 @@
+#!/usr/bin/perl
+# Copyright 2003 Bryan Ford
+# Distributed under the GNU General Public License.
+#
+# Usage: mergedep <main-depfile> [<new-depfiles> ...]
+#
+# This script merges the contents of all <new-depfiles> specified
+# on the command line into the single file <main-depfile>,
+# which may or may not previously exist.
+# Dependencies in the <new-depfiles> will override
+# any existing dependencies for the same targets in <main-depfile>.
+# The <new-depfiles> are deleted after <main-depfile> is updated.
+#
+# The <new-depfiles> are typically generated by GCC with the -MD option,
+# and the <main-depfile> is typically included from a Makefile,
+# as shown here for GNU 'make':
+#
+#	.deps: $(wildcard *.d)
+#		perl mergedep $@ $^
+#	-include .deps
+#
+# This script properly handles multiple dependencies per <new-depfile>,
+# including dependencies having no target,
+# so it is compatible with GCC3's -MP option.
+#
+
+sub readdeps {
+	my $filename = shift;
+
+	open(DEPFILE, $filename) or return 0;
+	while (<DEPFILE>) {
+		if (/([^:]*):([^\\:]*)([\\]?)$/) {
+			my $target = $1;
+			my $deplines = $2;
+			my $slash = $3;
+			while ($slash ne '') {
+				$_ = <DEPFILE>;
+				defined($_) or die
+					"Unterminated dependency in $filename";
+				/(^[ \t][^\\]*)([\\]?)$/ or die
+					"Bad continuation line in $filename";
+				$deplines = "$deplines\\\n$1";
+				$slash = $2;
+			}
+			#print "DEPENDENCY [[$target]]: [[$deplines]]\n";
+			$dephash{$target} = $deplines;
+		} elsif (/^[#]?[ \t]*$/) {
+			# ignore blank lines and comments
+		} else {
+			die "Bad dependency line in $filename: $_";
+		}
+	}
+	close DEPFILE;
+	return 1;
+}
+
+
+if ($#ARGV < 0) {
+	print "Usage: mergedep <main-depfile> [<new-depfiles> ..]\n";
+	exit(1);
+}
+
+%dephash = ();
+
+# Read the main dependency file
+$maindeps = $ARGV[0];
+readdeps($maindeps);
+
+# Read and merge in the new dependency files
+foreach $i (1 .. $#ARGV) {
+	readdeps($ARGV[$i]) or die "Can't open $ARGV[$i]";
+}
+
+# Update the main dependency file
+open(DEPFILE, ">$maindeps.tmp") or die "Can't open output file $maindeps.tmp";
+foreach $target (keys %dephash) {
+	print DEPFILE "$target:$dephash{$target}";
+}
+close DEPFILE;
+rename("$maindeps.tmp", "$maindeps") or die "Can't overwrite $maindeps";
+
+# Finally, delete the new dependency files
+foreach $i (1 .. $#ARGV) {
+	unlink($ARGV[$i]) or print "Error removing $ARGV[$i]\n";
+}
+
diff --git a/kern/monitor.c b/kern/monitor.c
old mode 100644
new mode 100755
index 4e00796..2b69900
--- a/kern/monitor.c
+++ b/kern/monitor.c
@@ -11,57 +11,189 @@
 #include <kern/monitor.h>
 #include <kern/kdebug.h>
 #include <kern/trap.h>
+#include <kern/pmap.h>
+
 
 #define CMDBUF_SIZE	80	// enough for one VGA text line
 
+int
+mon_pgmap(int argc, char **argv, struct Trapframe *tf);
+int
+mon_memdump(int argc, char **argv, struct Trapframe *tf);
+int
+mon_pgperm(int argc, char **argv, struct Trapframe *tf);
+int
+mon_continue(int argc, char **argv, struct Trapframe *tf);
+int
+mon_stepins(int argc, char **argv, struct Trapframe *tf);
+
+
 
 struct Command {
-	const char *name;
-	const char *desc;
-	// return -1 to force monitor to exit
-	int (*func)(int argc, char** argv, struct Trapframe* tf);
+    const char *name;
+    const char *desc;
+    // return -1 to force monitor to exit
+    int (*func)(int argc, char** argv, struct Trapframe* tf);
 };
 
 static struct Command commands[] = {
-	{ "help", "Display this list of commands", mon_help },
-	{ "kerninfo", "Display information about the kernel", mon_kerninfo },
+    { "help", "Display this list of commands", mon_help },
+    { "kerninfo", "Display information about the kernel", mon_kerninfo },
+    { "pgmap", "Display the physical page mappings", mon_pgmap },
+    { "pgperm", "set, clear, or change the permissions", mon_pgperm },
+    { "memdump", "Dump the contents of a range of memory", mon_memdump },
+    { "backtrace", "Backtrace", mon_backtrace },
+    { "si", "single-step one instruction at a time", mon_stepins },
+    { "c", "continue", mon_continue },
 };
 
+
 /***** Implementations of basic kernel monitor commands *****/
 
-int
+    int
 mon_help(int argc, char **argv, struct Trapframe *tf)
 {
-	int i;
+    int i;
 
-	for (i = 0; i < ARRAY_SIZE(commands); i++)
-		cprintf("%s - %s\n", commands[i].name, commands[i].desc);
-	return 0;
+    for (i = 0; i < ARRAY_SIZE(commands); i++)
+	   cprintf("%s - %s\n", commands[i].name, commands[i].desc);
+    return 0;
 }
 
-int
+    int
 mon_kerninfo(int argc, char **argv, struct Trapframe *tf)
 {
-	extern char _start[], entry[], etext[], edata[], end[];
-
-	cprintf("Special kernel symbols:\n");
-	cprintf("  _start                  %08x (phys)\n", _start);
-	cprintf("  entry  %08x (virt)  %08x (phys)\n", entry, entry - KERNBASE);
-	cprintf("  etext  %08x (virt)  %08x (phys)\n", etext, etext - KERNBASE);
-	cprintf("  edata  %08x (virt)  %08x (phys)\n", edata, edata - KERNBASE);
-	cprintf("  end    %08x (virt)  %08x (phys)\n", end, end - KERNBASE);
-	cprintf("Kernel executable memory footprint: %dKB\n",
-		ROUNDUP(end - entry, 1024) / 1024);
-	return 0;
+    extern char _start[], entry[], etext[], edata[], end[];
+
+    cprintf("Special kernel symbols:\n");
+    cprintf("  _start                  %08x (phys)\n", _start);
+    cprintf("  entry  %08x (virt)  %08x (phys)\n", entry, entry - KERNBASE);
+    cprintf("  etext  %08x (virt)  %08x (phys)\n", etext, etext - KERNBASE);
+    cprintf("  edata  %08x (virt)  %08x (phys)\n", edata, edata - KERNBASE);
+    cprintf("  end    %08x (virt)  %08x (phys)\n", end, end - KERNBASE);
+    cprintf("Kernel executable memory footprint: %dKB\n",
+	    ROUNDUP(end - entry, 1024) / 1024);
+    return 0;
 }
 
-int
+    int
 mon_backtrace(int argc, char **argv, struct Trapframe *tf)
 {
-	// Your code here.
+    int *ebp, eip, *old_ebp;
+    int ary[5]={};
+
+    cprintf("Stack backtrace:\n");
+
+    ebp=(int *)read_ebp();
+    while((int)ebp!=0)
+    {
+	   old_ebp=(int *)*(ebp);
+	   eip=*(ebp+1);
+	   for(int i=0;i<5;++i)
+	   {
+	       int j=i+2;
+	       ary[i]=*(ebp+j);
+	   }
+	   struct Eipdebuginfo eip_info;
+	   debuginfo_eip((uintptr_t)eip, &eip_info);
+	   cprintf("\033[16ebp %08x eip %08x args %08x %08x %08x %08x %08x\n",ebp,eip,ary[0],ary[1],ary[2],ary[3],ary[4]);
+	   cprintf("\033[28	%s:%d:", eip_info.eip_file, eip_info.eip_line);
+	   cprintf("\033[3a %.*s+%d\n", eip_info.eip_fn_namelen, eip_info.eip_fn_name, eip - eip_info.eip_fn_addr);
+	   ebp=old_ebp;
+    }
+
+    return 0;
+}
+
+
+
+
+    int
+mon_pgmap(int argc, char **argv, struct Trapframe *tf)
+{
+    uintptr_t va1, va2, va;
+    struct PageInfo *pg;
+    pte_t *pte;
+    if (argc != 3) 
+    {
+	   cprintf("Usage: pgmap va1 va2\n Display physical memory mapping from virtual memory va1 to va2\nva1 and va2 are hex\n");
+	   return 0;
+    }
+    else 
+    {
+	   for (va1 = strtol(argv[1], 0, 16), va2 = strtol(argv[2], 0, 16); va1 < va2; va1 += PGSIZE) 
+       {
+        va = va1 & ~0xfff;
+	    pg = page_lookup(kern_pgdir, (void*)va, 0);
+	    pte = pgdir_walk(kern_pgdir, (void* )va,0);
+	    if (pg)
+        {
+            cprintf("[%x, %x) ---> [%x, %x)    ", va, va + PGSIZE, page2pa(pg), page2pa(pg) + PGSIZE);
+            if(*pte & PTE_U)
+                cprintf("user: ");
+            else 
+                cprintf("kernel: ");
+            if(*pte &PTE_W)
+                cprintf("read/write ");
+            else 
+                cprintf("read only ");
+	    }
+        else
+            cprintf("[%x, %x) ---> NULL    ", va, va + PGSIZE);
+	    cprintf("\n");                                                                                       
+	   }
+    }
+    return 0;
+}
+
+
+    int
+mon_pgperm(int argc, char **argv, struct Trapframe *tf)
+{
+    uintptr_t va, perm;
+    if (argc != 4) {
+	cprintf("Usage: pgperm +/-/= perm va\nset perm of page which contains va, va is hex\n");
 	return 0;
+    }
+    else {
+	va = strtol(argv[3], 0, 16);
+	perm = strtol(argv[2], 0, 16);
+	pte_t *pte = pgdir_walk(kern_pgdir, (void*)va, 0);
+	if (!pte) {
+	    cprintf("0x%x is not mapped\n", va);
+	}
+	else {
+	    if (argv[1][0] == '+') *pte |= perm;
+	    if (argv[1][0] == '0') *pte &= ~perm;
+	    if (argv[1][0] == '=') *pte = PTE_ADDR(*pte) | perm;
+	}
+    }
+    return 0;
 }
 
+    int
+mon_memdump(int argc, char **argv, struct Trapframe *tf)
+{
+    uintptr_t a1, a2, a;
+    struct PageInfo *pg;
+    if (argc != 4) 
+    {
+	   cprintf("Usage: memdump p/v a1 a2\n Dump memory content via virtual or physical address\na1 and a2 are hex\n");
+	   return 0;
+    }
+    else 
+    {
+	   a1 = strtol(argv[2], 0, 16), a2 = strtol(argv[3], 0, 16);
+	   if (argv[1][0] == 'p') a1 = (int)KADDR(a1), a2 = (int)KADDR(a2);
+	   for (a = a1; a < a2 && a >= KERNBASE; a += 4) 
+       {
+	       if (!((a - a1) & 0xf)) cprintf("\n%x:\t", a);
+	       cprintf(" %x", *(int*)(a));
+	   }
+	   cprintf("\n");
+    }
+    return 0;
+}
 
 
 /***** Kernel monitor command interpreter *****/
@@ -69,60 +201,83 @@ mon_backtrace(int argc, char **argv, struct Trapframe *tf)
 #define WHITESPACE "\t\r\n "
 #define MAXARGS 16
 
-static int
+    static int
 runcmd(char *buf, struct Trapframe *tf)
 {
-	int argc;
-	char *argv[MAXARGS];
-	int i;
-
-	// Parse the command buffer into whitespace-separated arguments
-	argc = 0;
-	argv[argc] = 0;
-	while (1) {
-		// gobble whitespace
-		while (*buf && strchr(WHITESPACE, *buf))
-			*buf++ = 0;
-		if (*buf == 0)
-			break;
-
-		// save and scan past next arg
-		if (argc == MAXARGS-1) {
-			cprintf("Too many arguments (max %d)\n", MAXARGS);
-			return 0;
-		}
-		argv[argc++] = buf;
-		while (*buf && !strchr(WHITESPACE, *buf))
-			buf++;
-	}
-	argv[argc] = 0;
-
-	// Lookup and invoke the command
-	if (argc == 0)
-		return 0;
-	for (i = 0; i < ARRAY_SIZE(commands); i++) {
-		if (strcmp(argv[0], commands[i].name) == 0)
-			return commands[i].func(argc, argv, tf);
+    int argc;
+    char *argv[MAXARGS];
+    int i;
+
+    // Parse the command buffer into whitespace-separated arguments
+    argc = 0;
+    argv[argc] = 0;
+    while (1) {
+	// gobble whitespace
+	while (*buf && strchr(WHITESPACE, *buf))
+	    *buf++ = 0;
+	if (*buf == 0)
+	    break;
+
+	// save and scan past next arg
+	if (argc == MAXARGS-1) {
+	    cprintf("Too many arguments (max %d)\n", MAXARGS);
+	    return 0;
 	}
-	cprintf("Unknown command '%s'\n", argv[0]);
-	return 0;
+	argv[argc++] = buf;
+	while (*buf && !strchr(WHITESPACE, *buf))
+	    buf++;
+    }
+    argv[argc] = 0;
+
+    // Lookup and invoke the command
+    if (argc == 0)
+	   return 0;
+    for (i = 0; i < ARRAY_SIZE(commands); i++) {
+	   if (strcmp(argv[0], commands[i].name) == 0)
+	       return commands[i].func(argc, argv, tf);
+    }
+    cprintf("Unknown command '%s'\n", argv[0]);
+    return 0;
 }
 
-void
+    void
 monitor(struct Trapframe *tf)
 {
-	char *buf;
+    char *buf;
 
-	cprintf("Welcome to the JOS kernel monitor!\n");
-	cprintf("Type 'help' for a list of commands.\n");
+    cprintf("Welcome to the JOS kernel monitor!\n");
+    cprintf("Type 'help' for a list of commands.\n");
 
-	if (tf != NULL)
-		print_trapframe(tf);
+    if (tf != NULL)
+	print_trapframe(tf);
 
-	while (1) {
-		buf = readline("K> ");
-		if (buf != NULL)
-			if (runcmd(buf, tf) < 0)
-				break;
-	}
+    while (1) {
+	buf = readline("K> ");
+	if (buf != NULL)
+	    if (runcmd(buf, tf) < 0)
+		break;
+    }
+}
+
+extern void env_pop_tf(struct Trapframe *tf);
+    int
+mon_continue(int argc, char **argv, struct Trapframe *tf)
+{
+    if (tf->tf_trapno == T_BRKPT || tf->tf_trapno == T_DEBUG) {
+	   tf->tf_eflags &= ~FL_TF;
+	   env_pop_tf(tf);
+    }
+    return 0;
 }
+
+    int
+mon_stepins(int argc, char **argv, struct Trapframe *tf)
+{
+    if (tf->tf_trapno == T_BRKPT || tf->tf_trapno == T_DEBUG) {
+	   tf->tf_eflags |= FL_TF;
+	   env_pop_tf(tf);
+    }
+    return 0;
+}
+
+
diff --git a/kern/monitor.h b/kern/monitor.h
old mode 100644
new mode 100755
diff --git a/kern/mpconfig.c b/kern/mpconfig.c
old mode 100644
new mode 100755
diff --git a/kern/mpentry.S b/kern/mpentry.S
old mode 100644
new mode 100755
diff --git a/kern/picirq.c b/kern/picirq.c
old mode 100644
new mode 100755
diff --git a/kern/picirq.h b/kern/picirq.h
old mode 100644
new mode 100755
diff --git a/kern/pmap.c b/kern/pmap.c
old mode 100644
new mode 100755
index c04d014..53760b7
--- a/kern/pmap.c
+++ b/kern/pmap.c
@@ -20,42 +20,41 @@ pde_t *kern_pgdir;		// Kernel's initial page directory
 struct PageInfo *pages;		// Physical page state array
 static struct PageInfo *page_free_list;	// Free list of physical pages
 
-
 // --------------------------------------------------------------
 // Detect machine's physical memory setup.
 // --------------------------------------------------------------
 
-static int
+    static int
 nvram_read(int r)
 {
-	return mc146818_read(r) | (mc146818_read(r + 1) << 8);
+    return mc146818_read(r) | (mc146818_read(r + 1) << 8);
 }
 
-static void
+    static void
 i386_detect_memory(void)
 {
-	size_t basemem, extmem, ext16mem, totalmem;
-
-	// Use CMOS calls to measure available base & extended memory.
-	// (CMOS calls return results in kilobytes.)
-	basemem = nvram_read(NVRAM_BASELO);
-	extmem = nvram_read(NVRAM_EXTLO);
-	ext16mem = nvram_read(NVRAM_EXT16LO) * 64;
-
-	// Calculate the number of physical pages available in both base
-	// and extended memory.
-	if (ext16mem)
-		totalmem = 16 * 1024 + ext16mem;
-	else if (extmem)
-		totalmem = 1 * 1024 + extmem;
-	else
-		totalmem = basemem;
-
-	npages = totalmem / (PGSIZE / 1024);
-	npages_basemem = basemem / (PGSIZE / 1024);
-
-	cprintf("Physical memory: %uK available, base = %uK, extended = %uK\n",
-		totalmem, basemem, totalmem - basemem);
+    size_t basemem, extmem, ext16mem, totalmem;
+
+    // Use CMOS calls to measure available base & extended memory.
+    // (CMOS calls return results in kilobytes.)
+    basemem = nvram_read(NVRAM_BASELO);
+    extmem = nvram_read(NVRAM_EXTLO);
+    ext16mem = nvram_read(NVRAM_EXT16LO) * 64;
+
+    // Calculate the number of physical pages available in both base
+    // and extended memory.
+    if (ext16mem)
+	   totalmem = 16 * 1024 + ext16mem;
+    else if (extmem)
+	   totalmem = 1 * 1024 + extmem;
+    else
+	   totalmem = basemem;
+
+    npages = totalmem / (PGSIZE / 1024);
+    npages_basemem = basemem / (PGSIZE / 1024);
+
+    cprintf("Physical memory: %uK available, base = %uK, extended = %uK\n",
+	    totalmem, basemem, totalmem - basemem);
 }
 
 
@@ -84,29 +83,38 @@ static void check_page_installed_pgdir(void);
 // If we're out of memory, boot_alloc should panic.
 // This function may ONLY be used during initialization,
 // before the page_free_list list has been set up.
-static void *
+    static void *
 boot_alloc(uint32_t n)
 {
-	static char *nextfree;	// virtual address of next byte of free memory
-	char *result;
-
-	// Initialize nextfree if this is the first time.
-	// 'end' is a magic symbol automatically generated by the linker,
-	// which points to the end of the kernel's bss segment:
-	// the first virtual address that the linker did *not* assign
-	// to any kernel code or global variables.
-	if (!nextfree) {
-		extern char end[];
-		nextfree = ROUNDUP((char *) end, PGSIZE);
-	}
-
-	// Allocate a chunk large enough to hold 'n' bytes, then update
-	// nextfree.  Make sure nextfree is kept aligned
-	// to a multiple of PGSIZE.
-	//
-	// LAB 2: Your code here.
-
-	return NULL;
+    static char *nextfree;	// virtual address of next byte of free memory
+    char *result;
+
+    // Initialize nextfree if this is the first time.
+    // 'end' is a magic symbol automatically generated by the linker,
+    // which points to the end of the kernel's bss segment:
+    // the first virtual address that the linker did *not* assign
+    // to any kernel code or global variables.
+    if (!nextfree) 
+    {
+        extern char end[];
+        nextfree = ROUNDUP((char *) end, PGSIZE);
+    }
+
+    // Allocate a chunk large enough to hold 'n' bytes, then update
+    // nextfree.  Make sure nextfree is kept aligned
+    // to a multiple of PGSIZE.
+    // LAB 2: Your code here.
+    if (n == 0) 
+        return (void*)nextfree;
+    n = ROUNDUP(n, PGSIZE);
+    if (PADDR(nextfree + n) > npages * PGSIZE)
+    {
+        panic("kern/pmap.c: boot_alloc()");
+        return NULL;
+    }
+    result = nextfree;
+    nextfree += n;
+    return result;
 }
 
 // Set up a two-level page table:
@@ -118,147 +126,160 @@ boot_alloc(uint32_t n)
 //
 // From UTOP to ULIM, the user is allowed to read but not write.
 // Above ULIM the user cannot read or write.
-void
+    void
 mem_init(void)
 {
-	uint32_t cr0;
-	size_t n;
-
-	// Find out how much memory the machine has (npages & npages_basemem).
-	i386_detect_memory();
-
-	// Remove this line when you're ready to test this function.
-	panic("mem_init: This function is not finished\n");
-
-	//////////////////////////////////////////////////////////////////////
-	// create initial page directory.
-	kern_pgdir = (pde_t *) boot_alloc(PGSIZE);
-	memset(kern_pgdir, 0, PGSIZE);
-
-	//////////////////////////////////////////////////////////////////////
-	// Recursively insert PD in itself as a page table, to form
-	// a virtual page table at virtual address UVPT.
-	// (For now, you don't have understand the greater purpose of the
-	// following line.)
-
-	// Permissions: kernel R, user R
-	kern_pgdir[PDX(UVPT)] = PADDR(kern_pgdir) | PTE_U | PTE_P;
-
-	//////////////////////////////////////////////////////////////////////
-	// Allocate an array of npages 'struct PageInfo's and store it in 'pages'.
-	// The kernel uses this array to keep track of physical pages: for
-	// each physical page, there is a corresponding struct PageInfo in this
-	// array.  'npages' is the number of physical pages in memory.  Use memset
-	// to initialize all fields of each struct PageInfo to 0.
-	// Your code goes here:
-
-
-	//////////////////////////////////////////////////////////////////////
-	// Make 'envs' point to an array of size 'NENV' of 'struct Env'.
-	// LAB 3: Your code here.
-
-	//////////////////////////////////////////////////////////////////////
-	// Now that we've allocated the initial kernel data structures, we set
-	// up the list of free physical pages. Once we've done so, all further
-	// memory management will go through the page_* functions. In
-	// particular, we can now map memory using boot_map_region
-	// or page_insert
-	page_init();
-
-	check_page_free_list(1);
-	check_page_alloc();
-	check_page();
-
-	//////////////////////////////////////////////////////////////////////
-	// Now we set up virtual memory
-
-	//////////////////////////////////////////////////////////////////////
-	// Map 'pages' read-only by the user at linear address UPAGES
-	// Permissions:
-	//    - the new image at UPAGES -- kernel R, user R
-	//      (ie. perm = PTE_U | PTE_P)
-	//    - pages itself -- kernel RW, user NONE
-	// Your code goes here:
-
-	//////////////////////////////////////////////////////////////////////
-	// Map the 'envs' array read-only by the user at linear address UENVS
-	// (ie. perm = PTE_U | PTE_P).
-	// Permissions:
-	//    - the new image at UENVS  -- kernel R, user R
-	//    - envs itself -- kernel RW, user NONE
-	// LAB 3: Your code here.
-
-	//////////////////////////////////////////////////////////////////////
-	// Use the physical memory that 'bootstack' refers to as the kernel
-	// stack.  The kernel stack grows down from virtual address KSTACKTOP.
-	// We consider the entire range from [KSTACKTOP-PTSIZE, KSTACKTOP)
-	// to be the kernel stack, but break this into two pieces:
-	//     * [KSTACKTOP-KSTKSIZE, KSTACKTOP) -- backed by physical memory
-	//     * [KSTACKTOP-PTSIZE, KSTACKTOP-KSTKSIZE) -- not backed; so if
-	//       the kernel overflows its stack, it will fault rather than
-	//       overwrite memory.  Known as a "guard page".
-	//     Permissions: kernel RW, user NONE
-	// Your code goes here:
-
-	//////////////////////////////////////////////////////////////////////
-	// Map all of physical memory at KERNBASE.
-	// Ie.  the VA range [KERNBASE, 2^32) should map to
-	//      the PA range [0, 2^32 - KERNBASE)
-	// We might not have 2^32 - KERNBASE bytes of physical memory, but
-	// we just set up the mapping anyway.
-	// Permissions: kernel RW, user NONE
-	// Your code goes here:
-
-	// Initialize the SMP-related parts of the memory map
-	mem_init_mp();
-
-	// Check that the initial page directory has been set up correctly.
-	check_kern_pgdir();
-
-	// Switch from the minimal entry page directory to the full kern_pgdir
-	// page table we just created.	Our instruction pointer should be
-	// somewhere between KERNBASE and KERNBASE+4MB right now, which is
-	// mapped the same way by both page tables.
-	//
-	// If the machine reboots at this point, you've probably set up your
-	// kern_pgdir wrong.
-	lcr3(PADDR(kern_pgdir));
-
-	check_page_free_list(0);
-
-	// entry.S set the really important flags in cr0 (including enabling
-	// paging).  Here we configure the rest of the flags that we care about.
-	cr0 = rcr0();
-	cr0 |= CR0_PE|CR0_PG|CR0_AM|CR0_WP|CR0_NE|CR0_MP;
-	cr0 &= ~(CR0_TS|CR0_EM);
-	lcr0(cr0);
-
-	// Some more checks, only possible after kern_pgdir is installed.
-	check_page_installed_pgdir();
+    uint32_t cr0;
+    size_t n;
+
+    // Find out how much memory the machine has (npages & npages_basemem).
+    i386_detect_memory();
+
+    // Remove this line when you're ready to test this function.
+    //panic("mem_init: This function is not finished\n");
+
+    //////////////////////////////////////////////////////////////////////
+    // create initial page directory.
+    kern_pgdir = (pde_t *) boot_alloc(PGSIZE);
+    memset(kern_pgdir, 0, PGSIZE);
+
+    //////////////////////////////////////////////////////////////////////
+    // Recursively insert PD in itself as a page table, to form
+    // a virtual page table at virtual address UVPT.
+    // (For now, you don't have understand the greater purpose of the
+    // following line.)
+
+    // Permissions: kernel R, user R
+    kern_pgdir[PDX(UVPT)] = PADDR(kern_pgdir) | PTE_U | PTE_P;
+
+    //////////////////////////////////////////////////////////////////////
+    // Allocate an array of npages 'struct PageInfo's and store it in 'pages'.
+    // The kernel uses this array to keep track of physical pages: for
+    // each physical page, there is a corresponding struct PageInfo in this
+    // array.  'npages' is the number of physical pages in memory.  Use memset
+    // to initialize all fields of each struct PageInfo to 0.
+    // Your code goes here:
+    pages = (struct PageInfo*)boot_alloc(npages * sizeof(struct PageInfo));
+    memset(pages, 0, npages * sizeof(struct PageInfo));
+
+    //////////////////////////////////////////////////////////////////////
+    // Make 'envs' point to an array of size 'NENV' of 'struct Env'.
+    // LAB 3: Your code here.
+    envs = (struct Env*)boot_alloc(NENV * sizeof(struct Env));
+
+    //////////////////////////////////////////////////////////////////////
+    // Now that we've allocated the initial kernel data structures, we set
+    // up the list of free physical pages. Once we've done so, all further
+    // memory management will go through the page_* functions. In
+    // particular, we can now map memory using boot_map_region
+    // or page_insert
+    page_init();
+
+    check_page_free_list(1);
+    check_page_alloc();
+    check_page();
+
+    //////////////////////////////////////////////////////////////////////
+    // Now we set up virtual memory
+
+    //////////////////////////////////////////////////////////////////////
+    // Map 'pages' read-only by the user at linear address UPAGES
+    // Permissions:
+    //    - the new image at UPAGES -- kernel R, user R
+    //      (ie. perm = PTE_U | PTE_P)
+    //    - pages itself -- kernel RW, user NONE
+    // Your code goes here:
+    boot_map_region(kern_pgdir, UPAGES, ROUNDUP(sizeof(struct PageInfo)* npages, PGSIZE), PADDR(pages), PTE_U);
+
+    //////////////////////////////////////////////////////////////////////
+    // Map the 'envs' array read-only by the user at linear address UENVS
+    // (ie. perm = PTE_U | PTE_P).
+    // Permissions:
+    //    - the new image at UENVS  -- kernel R, user R
+    //    - envs itself -- kernel RW, user NONE
+    // LAB 3: Your code here.
+    boot_map_region(kern_pgdir, UENVS, ROUNDUP(sizeof(struct Env) * NENV, PGSIZE), PADDR(envs), PTE_U);	
+
+    //////////////////////////////////////////////////////////////////////
+    // Use the physical memory that 'bootstack' refers to as the kernel
+    // stack.  The kernel stack grows down from virtual address KSTACKTOP.
+    // We consider the entire range from [KSTACKTOP-PTSIZE, KSTACKTOP)
+    // to be the kernel stack, but break this into two pieces:
+    //     * [KSTACKTOP-KSTKSIZE, KSTACKTOP) -- backed by physical memory
+    //     * [KSTACKTOP-PTSIZE, KSTACKTOP-KSTKSIZE) -- not backed; so if
+    //       the kernel overflows its stack, it will fault rather than
+    //       overwrite memory.  Known as a "guard page".
+    //     Permissions: kernel RW, user NONE
+    // Your code goes here:
+    boot_map_region(kern_pgdir, KSTACKTOP - KSTKSIZE, ROUNDUP(KSTKSIZE, PGSIZE), PADDR(bootstack), PTE_W);
+
+    //////////////////////////////////////////////////////////////////////
+    // Map all of physical memory at KERNBASE.
+    // Ie.  the VA range [KERNBASE, 2^32) should map to
+    //      the PA range [0, 2^32 - KERNBASE)
+    // We might not have 2^32 - KERNBASE bytes of physical memory, but
+    // we just set up the mapping anyway.
+    // Permissions: kernel RW, user NONE
+    // Your code goes here:
+    boot_map_region(kern_pgdir, (uintptr_t)KERNBASE , -KERNBASE, (physaddr_t)0, PTE_W);
+
+
+    // Initialize the SMP-related parts of the memory map
+    mem_init_mp();
+
+    // Check that the initial page directory has been set up correctly.
+    check_kern_pgdir();
+
+    // Switch from the minimal entry page directory to the full kern_pgdir
+    // page table we just created.	Our instruction pointer should be
+    // somewhere between KERNBASE and KERNBASE+4MB right now, which is
+    // mapped the same way by both page tables.
+    //
+    // If the machine reboots at this point, you've probably set up your
+    // kern_pgdir wrong.
+    lcr3(PADDR(kern_pgdir));
+
+    check_page_free_list(0);
+
+    // entry.S set the really important flags in cr0 (including enabling
+    // paging).  Here we configure the rest of the flags that we care about.
+    cr0 = rcr0();
+    cr0 |= CR0_PE|CR0_PG|CR0_AM|CR0_WP|CR0_NE|CR0_MP;
+    cr0 &= ~(CR0_TS|CR0_EM);
+    lcr0(cr0);
+
+    // Some more checks, only possible after kern_pgdir is installed.
+    check_page_installed_pgdir();
 }
 
 // Modify mappings in kern_pgdir to support SMP
 //   - Map the per-CPU stacks in the region [KSTACKTOP-PTSIZE, KSTACKTOP)
 //
-static void
+    static void
 mem_init_mp(void)
 {
-	// Map per-CPU stacks starting at KSTACKTOP, for up to 'NCPU' CPUs.
-	//
-	// For CPU i, use the physical memory that 'percpu_kstacks[i]' refers
-	// to as its kernel stack. CPU i's kernel stack grows down from virtual
-	// address kstacktop_i = KSTACKTOP - i * (KSTKSIZE + KSTKGAP), and is
-	// divided into two pieces, just like the single stack you set up in
-	// mem_init:
-	//     * [kstacktop_i - KSTKSIZE, kstacktop_i)
-	//          -- backed by physical memory
-	//     * [kstacktop_i - (KSTKSIZE + KSTKGAP), kstacktop_i - KSTKSIZE)
-	//          -- not backed; so if the kernel overflows its stack,
-	//             it will fault rather than overwrite another CPU's stack.
-	//             Known as a "guard page".
-	//     Permissions: kernel RW, user NONE
-	//
-	// LAB 4: Your code here:
+    // Map per-CPU stacks starting at KSTACKTOP, for up to 'NCPU' CPUs.
+    //
+    // For CPU i, use the physical memory that 'percpu_kstacks[i]' refers
+    // to as its kernel stack. CPU i's kernel stack grows down from virtual
+    // address kstacktop_i = KSTACKTOP - i * (KSTKSIZE + KSTKGAP), and is
+    // divided into two pieces, just like the single stack you set up in
+    // mem_init:
+    //     * [kstacktop_i - KSTKSIZE, kstacktop_i)
+    //          -- backed by physical memory
+    //     * [kstacktop_i - (KSTKSIZE + KSTKGAP), kstacktop_i - KSTKSIZE)
+    //          -- not backed; so if the kernel overflows its stack,
+    //             it will fault rather than overwrite another CPU's stack.
+    //             Known as a "guard page".
+    //     Permissions: kernel RW, user NONE
+    //
+    // LAB 4: Your code here:
+    int c;
+    for (c = 0; c < NCPU; ++c) 
+    {
+        boot_map_region(kern_pgdir, KSTACKTOP - c * (KSTKSIZE + KSTKGAP) - KSTKSIZE,
+            ROUNDUP(KSTKSIZE, PGSIZE), PADDR(percpu_kstacks[c]), PTE_W);
+    }
 
 }
 
@@ -274,36 +295,41 @@ mem_init_mp(void)
 // allocator functions below to allocate and deallocate physical
 // memory via the page_free_list.
 //
-void
+    void
 page_init(void)
 {
-	// LAB 4:
-	// Change your code to mark the physical page at MPENTRY_PADDR
-	// as in use
-
-	// The example code here marks all physical pages as free.
-	// However this is not truly the case.  What memory is free?
-	//  1) Mark physical page 0 as in use.
-	//     This way we preserve the real-mode IDT and BIOS structures
-	//     in case we ever need them.  (Currently we don't, but...)
-	//  2) The rest of base memory, [PGSIZE, npages_basemem * PGSIZE)
-	//     is free.
-	//  3) Then comes the IO hole [IOPHYSMEM, EXTPHYSMEM), which must
-	//     never be allocated.
-	//  4) Then extended memory [EXTPHYSMEM, ...).
-	//     Some of it is in use, some is free. Where is the kernel
-	//     in physical memory?  Which pages are already in use for
-	//     page tables and other data structures?
-	//
-	// Change the code to reflect this.
-	// NB: DO NOT actually touch the physical memory corresponding to
-	// free pages!
-	size_t i;
-	for (i = 0; i < npages; i++) {
-		pages[i].pp_ref = 0;
-		pages[i].pp_link = page_free_list;
-		page_free_list = &pages[i];
-	}
+    // LAB 4:
+    // Change your code to mark the physical page at MPENTRY_PADDR
+    // as in use
+
+    // The example code here marks all physical pages as free.
+    // However this is not truly the case.  What memory is free?
+    //  1) Mark physical page 0 as in use.
+    //     This way we preserve the real-mode IDT and BIOS structures
+    //     in case we ever need them.  (Currently we don't, but...)
+    //  2) The rest of base memory, [PGSIZE, npages_basemem * PGSIZE)
+    //     is free.
+    //  3) Then comes the IO hole [IOPHYSMEM, EXTPHYSMEM), which must
+    //     never be allocated.
+    //  4) Then extended memory [EXTPHYSMEM, ...).
+    //     Some of it is in use, some is free. Where is the kernel
+    //     in physical memory?  Which pages are already in use for
+    //     page tables and other data structures?
+    //
+    // Change the code to reflect this.
+    // NB: DO NOT actually touch the physical memory corresponding to
+    // free pages!
+    size_t i;
+    assert(page_free_list == 0);
+    unsigned used_top = PADDR(boot_alloc(0));
+    for (i = 0; i < npages; i++) 
+    {
+        if (i == 0 || (page2pa(&pages[i]) >= IOPHYSMEM && page2pa(&pages[i]) < used_top)||(page2pa(&pages[i]) == MPENTRY_PADDR))
+            continue;
+        pages[i].pp_ref = 0;
+        pages[i].pp_link = page_free_list;
+        page_free_list = &pages[i];
+    }
 }
 
 //
@@ -318,34 +344,51 @@ page_init(void)
 // Returns NULL if out of free memory.
 //
 // Hint: use page2kva and memset
-struct PageInfo *
+    struct PageInfo *
 page_alloc(int alloc_flags)
 {
-	// Fill this function in
-	return 0;
+    // Fill this function in
+    if (page_free_list == NULL) 
+        return NULL;
+    struct PageInfo* ret = page_free_list;
+    page_free_list = ret->pp_link;
+    if (alloc_flags & ALLOC_ZERO) 
+	   memset(page2kva(ret), 0, PGSIZE);
+    ret->pp_link = NULL;
+    return ret;
 }
 
 //
 // Return a page to the free list.
 // (This function should only be called when pp->pp_ref reaches 0.)
 //
-void
+    void
 page_free(struct PageInfo *pp)
 {
-	// Fill this function in
-	// Hint: You may want to panic if pp->pp_ref is nonzero or
-	// pp->pp_link is not NULL.
+    // Fill this function in
+    // Hint: You may want to panic if pp->pp_ref is nonzero or
+    // pp->pp_link is not NULL.
+    if(pp->pp_ref == 0)
+    {
+        pp->pp_link = page_free_list;
+        page_free_list = pp;
+    }
+    else
+    {
+        panic("pp->pp_ref is not zero. Wrong call of the page_free!!!");
+    }
 }
 
+
 //
 // Decrement the reference count on a page,
 // freeing it if there are no more refs.
 //
-void
+    void
 page_decref(struct PageInfo* pp)
 {
-	if (--pp->pp_ref == 0)
-		page_free(pp);
+    if (--pp->pp_ref == 0)
+        page_free(pp);
 }
 
 // Given 'pgdir', a pointer to a page directory, pgdir_walk returns
@@ -370,11 +413,21 @@ page_decref(struct PageInfo* pp)
 // Hint 3: look at inc/mmu.h for useful macros that mainipulate page
 // table and page directory entries.
 //
-pte_t *
+    pte_t *
 pgdir_walk(pde_t *pgdir, const void *va, int create)
 {
-	// Fill this function in
-	return NULL;
+    // Fill this function in
+    if (!(pgdir[PDX(va)] & PTE_P)) 
+    {
+        if (!create) 
+            return NULL;
+        struct PageInfo *page = page_alloc(ALLOC_ZERO);
+        if (!page) 
+            return NULL;
+        page->pp_ref = 1;
+        pgdir[PDX(va)] = page2pa(page) | PTE_P | PTE_U | PTE_W;
+    }
+    return KADDR(PTE_ADDR(pgdir[PDX(va)])) + PTX(va) * sizeof(pte_t*);
 }
 
 //
@@ -388,12 +441,20 @@ pgdir_walk(pde_t *pgdir, const void *va, int create)
 // mapped pages.
 //
 // Hint: the TA solution uses pgdir_walk
-static void
+    static void
 boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm)
 {
-	// Fill this function in
+    // Fill this function in
+    int i;
+    for (i = 0; i < size; i += PGSIZE) 
+    {
+        pte_t *pte = pgdir_walk(pgdir, (void*)(va + i), 1);
+        if (pte) 
+            *pte = (pa + i) | perm | PTE_P;
+    }
 }
 
+
 //
 // Map the physical page 'pp' at virtual address 'va'.
 // The permissions (the low 12 bits) of the page table entry
@@ -419,11 +480,28 @@ boot_map_region(pde_t *pgdir, uintptr_t va, size_t size, physaddr_t pa, int perm
 // Hint: The TA solution is implemented using pgdir_walk, page_remove,
 // and page2pa.
 //
-int
+    int
 page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
 {
-	// Fill this function in
-	return 0;
+    // Fill this function in
+    pte_t *pte = pgdir_walk(pgdir, va, 1);
+    if (pte == NULL) 
+        return -E_NO_MEM;
+    if (*pte & PTE_P) 
+    {
+        if (PTE_ADDR(*pte) == page2pa(pp)) 
+        {
+            pp->pp_ref--;
+            tlb_invalidate(pgdir, va);
+        }
+        else 
+        {
+            page_remove(pgdir, va);
+        }
+    }
+    *pte = page2pa(pp) | perm | PTE_P;
+    pp->pp_ref++;
+    return 0;
 }
 
 //
@@ -437,17 +515,22 @@ page_insert(pde_t *pgdir, struct PageInfo *pp, void *va, int perm)
 //
 // Hint: the TA solution uses pgdir_walk and pa2page.
 //
-struct PageInfo *
+    struct PageInfo *
 page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
 {
-	// Fill this function in
-	return NULL;
+    // Fill this function in
+    pte_t *pte = pgdir_walk(pgdir, va, 0);
+    if (pte_store != NULL) 
+        *pte_store = pte;
+    if (pte == NULL || !(*pte & PTE_P)) 
+        return NULL;
+    return pa2page(PTE_ADDR(*pte));
 }
 
 //
 // Unmaps the physical page at virtual address 'va'.
 // If there is no physical page at that address, silently does nothing.
-//
+// 
 // Details:
 //   - The ref count on the physical page should decrement.
 //   - The physical page should be freed if the refcount reaches 0.
@@ -459,22 +542,31 @@ page_lookup(pde_t *pgdir, void *va, pte_t **pte_store)
 // Hint: The TA solution is implemented using page_lookup,
 // 	tlb_invalidate, and page_decref.
 //
-void
+    void
 page_remove(pde_t *pgdir, void *va)
 {
-	// Fill this function in
+    // Fill this function in
+    struct PageInfo *page = page_lookup(pgdir, va, 0);
+    pte_t *pte = pgdir_walk(pgdir, va, 0);
+    if (page != NULL) 
+        page_decref(page);
+    if (pte != NULL) 
+    {
+        *pte = 0;
+        tlb_invalidate(pgdir, va);
+    }
 }
 
 //
 // Invalidate a TLB entry, but only if the page tables being
 // edited are the ones currently in use by the processor.
 //
-void
+    void
 tlb_invalidate(pde_t *pgdir, void *va)
 {
-	// Flush the entry only if we're modifying the current address space.
-	if (!curenv || curenv->env_pgdir == pgdir)
-		invlpg(va);
+    // Flush the entry only if we're modifying the current address space.
+    if (!curenv || curenv->env_pgdir == pgdir)
+        invlpg(va);
 }
 
 //
@@ -482,34 +574,40 @@ tlb_invalidate(pde_t *pgdir, void *va)
 // location.  Return the base of the reserved region.  size does *not*
 // have to be multiple of PGSIZE.
 //
-void *
+    void *
 mmio_map_region(physaddr_t pa, size_t size)
 {
-	// Where to start the next region.  Initially, this is the
-	// beginning of the MMIO region.  Because this is static, its
-	// value will be preserved between calls to mmio_map_region
-	// (just like nextfree in boot_alloc).
-	static uintptr_t base = MMIOBASE;
-
-	// Reserve size bytes of virtual memory starting at base and
-	// map physical pages [pa,pa+size) to virtual addresses
-	// [base,base+size).  Since this is device memory and not
-	// regular DRAM, you'll have to tell the CPU that it isn't
-	// safe to cache access to this memory.  Luckily, the page
-	// tables provide bits for this purpose; simply create the
-	// mapping with PTE_PCD|PTE_PWT (cache-disable and
-	// write-through) in addition to PTE_W.  (If you're interested
-	// in more details on this, see section 10.5 of IA32 volume
-	// 3A.)
-	//
-	// Be sure to round size up to a multiple of PGSIZE and to
-	// handle if this reservation would overflow MMIOLIM (it's
-	// okay to simply panic if this happens).
-	//
-	// Hint: The staff solution uses boot_map_region.
-	//
-	// Your code here:
-	panic("mmio_map_region not implemented");
+    // Where to start the next region.  Initially, this is the
+    // beginning of the MMIO region.  Because this is static, its
+    // value will be preserved between calls to mmio_map_region
+    // (just like nextfree in boot_alloc).
+    static uintptr_t base = MMIOBASE;
+
+    // Reserve size bytes of virtual memory starting at base and
+    // map physical pages [pa,pa+size) to virtual addresses
+    // [base,base+size).  Since this is device memory and not
+    // regular DRAM, you'll have to tell the CPU that it isn't
+    // safe to cache access to this memory.  Luckily, the page
+    // tables provide bits for this purpose; simply create the
+    // mapping with PTE_PCD|PTE_PWT (cache-disable and
+    // write-through) in addition to PTE_W.  (If you're interested
+    // in more details on this, see section 10.5 of IA32 volume
+    // 3A.)
+    //
+    // Be sure to round size up to a multiple of PGSIZE and to
+    // handle if this reservation would overflow MMIOLIM (it's
+    // okay to simply panic if this happens).
+    //
+    // Hint: The staff solution uses boot_map_region.
+    //
+    // Your code here:
+    size = ROUNDUP(size, PGSIZE);
+    if (base + size > MMIOLIM)
+        panic("mmio_map_region(): out of memory\n");
+    boot_map_region(kern_pgdir, base, size, pa, PTE_PCD | PTE_PWT | PTE_W);
+    base += size;
+    return (void*)(base - size);
+    //panic("mmio_map_region not implemented");
 }
 
 static uintptr_t user_mem_check_addr;
@@ -532,12 +630,25 @@ static uintptr_t user_mem_check_addr;
 // Returns 0 if the user program can access this range of addresses,
 // and -E_FAULT otherwise.
 //
-int
+    int
 user_mem_check(struct Env *env, const void *va, size_t len, int perm)
 {
-	// LAB 3: Your code here.
-
-	return 0;
+    // LAB 3: Your code here.
+
+    uintptr_t va1 = (uintptr_t)va, va2 = va1 + len;
+    pte_t *pte;
+    for (; va1 < va2; va1 = ROUNDDOWN(va1 + PGSIZE, PGSIZE)) {
+	if (va1 >= ULIM) {
+	    user_mem_check_addr = va1;
+	    return -E_FAULT;
+	}
+	pte = pgdir_walk(env->env_pgdir, (void*)va1, 0);
+	if (pte == NULL||(*pte & (perm | PTE_P)) != (perm | PTE_P)) {
+	    user_mem_check_addr = va1;
+	    return -E_FAULT;
+	}
+    }
+    return 0;
 }
 
 //
@@ -547,14 +658,14 @@ user_mem_check(struct Env *env, const void *va, size_t len, int perm)
 // If it cannot, 'env' is destroyed and, if env is the current
 // environment, this function will not return.
 //
-void
+    void
 user_mem_assert(struct Env *env, const void *va, size_t len, int perm)
 {
-	if (user_mem_check(env, va, len, perm | PTE_U) < 0) {
-		cprintf("[%08x] user_mem_check assertion failure for "
-			"va %08x\n", env->env_id, user_mem_check_addr);
-		env_destroy(env);	// may not return
-	}
+    if (user_mem_check(env, va, len, perm | PTE_U) < 0) {
+	cprintf("[%08x] user_mem_check assertion failure for "
+		"va %08x\n", env->env_id, user_mem_check_addr);
+	env_destroy(env);	// may not return
+    }
 }
 
 
@@ -565,142 +676,141 @@ user_mem_assert(struct Env *env, const void *va, size_t len, int perm)
 //
 // Check that the pages on the page_free_list are reasonable.
 //
-static void
+    static void
 check_page_free_list(bool only_low_memory)
 {
-	struct PageInfo *pp;
-	unsigned pdx_limit = only_low_memory ? 1 : NPDENTRIES;
-	int nfree_basemem = 0, nfree_extmem = 0;
-	char *first_free_page;
-
-	if (!page_free_list)
-		panic("'page_free_list' is a null pointer!");
-
-	if (only_low_memory) {
-		// Move pages with lower addresses first in the free
-		// list, since entry_pgdir does not map all pages.
-		struct PageInfo *pp1, *pp2;
-		struct PageInfo **tp[2] = { &pp1, &pp2 };
-		for (pp = page_free_list; pp; pp = pp->pp_link) {
-			int pagetype = PDX(page2pa(pp)) >= pdx_limit;
-			*tp[pagetype] = pp;
-			tp[pagetype] = &pp->pp_link;
-		}
-		*tp[1] = 0;
-		*tp[0] = pp2;
-		page_free_list = pp1;
-	}
-
-	// if there's a page that shouldn't be on the free list,
-	// try to make sure it eventually causes trouble.
-	for (pp = page_free_list; pp; pp = pp->pp_link)
-		if (PDX(page2pa(pp)) < pdx_limit)
-			memset(page2kva(pp), 0x97, 128);
-
-	first_free_page = (char *) boot_alloc(0);
+    struct PageInfo *pp;
+    unsigned pdx_limit = only_low_memory ? 1 : NPDENTRIES;
+    int nfree_basemem = 0, nfree_extmem = 0;
+    char *first_free_page;
+
+    if (!page_free_list)
+	panic("'page_free_list' is a null pointer!");
+
+    if (only_low_memory) {
+	// Move pages with lower addresses first in the free
+	// list, since entry_pgdir does not map all pages.
+	struct PageInfo *pp1, *pp2;
+	struct PageInfo **tp[2] = { &pp1, &pp2 };
 	for (pp = page_free_list; pp; pp = pp->pp_link) {
-		// check that we didn't corrupt the free list itself
-		assert(pp >= pages);
-		assert(pp < pages + npages);
-		assert(((char *) pp - (char *) pages) % sizeof(*pp) == 0);
-
-		// check a few pages that shouldn't be on the free list
-		assert(page2pa(pp) != 0);
-		assert(page2pa(pp) != IOPHYSMEM);
-		assert(page2pa(pp) != EXTPHYSMEM - PGSIZE);
-		assert(page2pa(pp) != EXTPHYSMEM);
-		assert(page2pa(pp) < EXTPHYSMEM || (char *) page2kva(pp) >= first_free_page);
-		// (new test for lab 4)
-		assert(page2pa(pp) != MPENTRY_PADDR);
-
-		if (page2pa(pp) < EXTPHYSMEM)
-			++nfree_basemem;
-		else
-			++nfree_extmem;
+	    int pagetype = PDX(page2pa(pp)) >= pdx_limit;
+	    *tp[pagetype] = pp;
+	    tp[pagetype] = &pp->pp_link;
 	}
+	*tp[1] = 0;
+	*tp[0] = pp2;
+	page_free_list = pp1;
+    }
+
+    // if there's a page that shouldn't be on the free list,
+    // try to make sure it eventually causes trouble.
+    for (pp = page_free_list; pp; pp = pp->pp_link)
+	if (PDX(page2pa(pp)) < pdx_limit)
+	    memset(page2kva(pp), 0x97, 128);
+
+    first_free_page = (char *) boot_alloc(0);
+    for (pp = page_free_list; pp; pp = pp->pp_link) {
+	// check that we didn't corrupt the free list itself
+	assert(pp >= pages);
+	assert(pp < pages + npages);
+	assert(((char *) pp - (char *) pages) % sizeof(*pp) == 0);
+
+	// check a few pages that shouldn't be on the free list
+	assert(page2pa(pp) != 0);
+	assert(page2pa(pp) != IOPHYSMEM);
+	assert(page2pa(pp) != EXTPHYSMEM - PGSIZE);
+	assert(page2pa(pp) != EXTPHYSMEM);
+	assert(page2pa(pp) < EXTPHYSMEM || (char *) page2kva(pp) >= first_free_page);
+	// (new test for lab 4)
+	assert(page2pa(pp) != MPENTRY_PADDR);
+
+	if (page2pa(pp) < EXTPHYSMEM)
+	    ++nfree_basemem;
+	else
+	    ++nfree_extmem;
+    }
+    assert(nfree_basemem > 0);
+    assert(nfree_extmem > 0);
 
-	assert(nfree_basemem > 0);
-	assert(nfree_extmem > 0);
-
-	cprintf("check_page_free_list() succeeded!\n");
+    cprintf("check_page_free_list() succeeded!\n");
 }
 
 //
 // Check the physical page allocator (page_alloc(), page_free(),
 // and page_init()).
 //
-static void
+    static void
 check_page_alloc(void)
 {
-	struct PageInfo *pp, *pp0, *pp1, *pp2;
-	int nfree;
-	struct PageInfo *fl;
-	char *c;
-	int i;
-
-	if (!pages)
-		panic("'pages' is a null pointer!");
-
-	// check number of free pages
-	for (pp = page_free_list, nfree = 0; pp; pp = pp->pp_link)
-		++nfree;
-
-	// should be able to allocate three pages
-	pp0 = pp1 = pp2 = 0;
-	assert((pp0 = page_alloc(0)));
-	assert((pp1 = page_alloc(0)));
-	assert((pp2 = page_alloc(0)));
-
-	assert(pp0);
-	assert(pp1 && pp1 != pp0);
-	assert(pp2 && pp2 != pp1 && pp2 != pp0);
-	assert(page2pa(pp0) < npages*PGSIZE);
-	assert(page2pa(pp1) < npages*PGSIZE);
-	assert(page2pa(pp2) < npages*PGSIZE);
-
-	// temporarily steal the rest of the free pages
-	fl = page_free_list;
-	page_free_list = 0;
-
-	// should be no free memory
-	assert(!page_alloc(0));
-
-	// free and re-allocate?
-	page_free(pp0);
-	page_free(pp1);
-	page_free(pp2);
-	pp0 = pp1 = pp2 = 0;
-	assert((pp0 = page_alloc(0)));
-	assert((pp1 = page_alloc(0)));
-	assert((pp2 = page_alloc(0)));
-	assert(pp0);
-	assert(pp1 && pp1 != pp0);
-	assert(pp2 && pp2 != pp1 && pp2 != pp0);
-	assert(!page_alloc(0));
-
-	// test flags
-	memset(page2kva(pp0), 1, PGSIZE);
-	page_free(pp0);
-	assert((pp = page_alloc(ALLOC_ZERO)));
-	assert(pp && pp0 == pp);
-	c = page2kva(pp);
-	for (i = 0; i < PGSIZE; i++)
-		assert(c[i] == 0);
-
-	// give free list back
-	page_free_list = fl;
-
-	// free the pages we took
-	page_free(pp0);
-	page_free(pp1);
-	page_free(pp2);
-
-	// number of free pages should be the same
-	for (pp = page_free_list; pp; pp = pp->pp_link)
-		--nfree;
-	assert(nfree == 0);
-
-	cprintf("check_page_alloc() succeeded!\n");
+    struct PageInfo *pp, *pp0, *pp1, *pp2;
+    int nfree;
+    struct PageInfo *fl;
+    char *c;
+    int i;
+
+    if (!pages)
+	panic("'pages' is a null pointer!");
+
+    // check number of free pages
+    for (pp = page_free_list, nfree = 0; pp; pp = pp->pp_link)
+	++nfree;
+
+    // should be able to allocate three pages
+    pp0 = pp1 = pp2 = 0;
+    assert((pp0 = page_alloc(0)));
+    assert((pp1 = page_alloc(0)));
+    assert((pp2 = page_alloc(0)));
+
+    assert(pp0);
+    assert(pp1 && pp1 != pp0);
+    assert(pp2 && pp2 != pp1 && pp2 != pp0);
+    assert(page2pa(pp0) < npages*PGSIZE);
+    assert(page2pa(pp1) < npages*PGSIZE);
+    assert(page2pa(pp2) < npages*PGSIZE);
+
+    // temporarily steal the rest of the free pages
+    fl = page_free_list;
+    page_free_list = 0;
+
+    // should be no free memory
+    assert(!page_alloc(0));
+
+    // free and re-allocate?
+    page_free(pp0);
+    page_free(pp1);
+    page_free(pp2);
+    pp0 = pp1 = pp2 = 0;
+    assert((pp0 = page_alloc(0)));
+    assert((pp1 = page_alloc(0)));
+    assert((pp2 = page_alloc(0)));
+    assert(pp0);
+    assert(pp1 && pp1 != pp0);
+    assert(pp2 && pp2 != pp1 && pp2 != pp0);
+    assert(!page_alloc(0));
+
+    // test flags
+    memset(page2kva(pp0), 1, PGSIZE);
+    page_free(pp0);
+    assert((pp = page_alloc(ALLOC_ZERO)));
+    assert(pp && pp0 == pp);
+    c = page2kva(pp);
+    for (i = 0; i < PGSIZE; i++)
+	assert(c[i] == 0);
+
+    // give free list back
+    page_free_list = fl;
+
+    // free the pages we took
+    page_free(pp0);
+    page_free(pp1);
+    page_free(pp2);
+
+    // number of free pages should be the same
+    for (pp = page_free_list; pp; pp = pp->pp_link)
+	--nfree;
+    assert(nfree == 0);
+
+    cprintf("check_page_alloc() succeeded!\n");
 }
 
 //
@@ -711,59 +821,59 @@ check_page_alloc(void)
 // but it is a pretty good sanity check.
 //
 
-static void
+    static void
 check_kern_pgdir(void)
 {
-	uint32_t i, n;
-	pde_t *pgdir;
-
-	pgdir = kern_pgdir;
-
-	// check pages array
-	n = ROUNDUP(npages*sizeof(struct PageInfo), PGSIZE);
-	for (i = 0; i < n; i += PGSIZE)
-		assert(check_va2pa(pgdir, UPAGES + i) == PADDR(pages) + i);
-
-	// check envs array (new test for lab 3)
-	n = ROUNDUP(NENV*sizeof(struct Env), PGSIZE);
-	for (i = 0; i < n; i += PGSIZE)
-		assert(check_va2pa(pgdir, UENVS + i) == PADDR(envs) + i);
-
-	// check phys mem
-	for (i = 0; i < npages * PGSIZE; i += PGSIZE)
-		assert(check_va2pa(pgdir, KERNBASE + i) == i);
-
-	// check kernel stack
-	// (updated in lab 4 to check per-CPU kernel stacks)
-	for (n = 0; n < NCPU; n++) {
-		uint32_t base = KSTACKTOP - (KSTKSIZE + KSTKGAP) * (n + 1);
-		for (i = 0; i < KSTKSIZE; i += PGSIZE)
-			assert(check_va2pa(pgdir, base + KSTKGAP + i)
-				== PADDR(percpu_kstacks[n]) + i);
-		for (i = 0; i < KSTKGAP; i += PGSIZE)
-			assert(check_va2pa(pgdir, base + i) == ~0);
-	}
-
-	// check PDE permissions
-	for (i = 0; i < NPDENTRIES; i++) {
-		switch (i) {
-		case PDX(UVPT):
-		case PDX(KSTACKTOP-1):
-		case PDX(UPAGES):
-		case PDX(UENVS):
-		case PDX(MMIOBASE):
-			assert(pgdir[i] & PTE_P);
-			break;
-		default:
-			if (i >= PDX(KERNBASE)) {
-				assert(pgdir[i] & PTE_P);
-				assert(pgdir[i] & PTE_W);
-			} else
-				assert(pgdir[i] == 0);
-			break;
-		}
+    uint32_t i, n;
+    pde_t *pgdir;
+
+    pgdir = kern_pgdir;
+
+    // check pages array
+    n = ROUNDUP(npages*sizeof(struct PageInfo), PGSIZE);
+    for (i = 0; i < n; i += PGSIZE)
+	assert(check_va2pa(pgdir, UPAGES + i) == PADDR(pages) + i);
+
+    // check envs array (new test for lab 3)
+    n = ROUNDUP(NENV*sizeof(struct Env), PGSIZE);
+    for (i = 0; i < n; i += PGSIZE)
+	assert(check_va2pa(pgdir, UENVS + i) == PADDR(envs) + i);
+
+    // check phys mem
+    for (i = 0; i < npages * PGSIZE; i += PGSIZE)
+	assert(check_va2pa(pgdir, KERNBASE + i) == i);
+
+    // check kernel stack
+    // (updated in lab 4 to check per-CPU kernel stacks)
+    for (n = 0; n < NCPU; n++) {
+	uint32_t base = KSTACKTOP - (KSTKSIZE + KSTKGAP) * (n + 1);
+	for (i = 0; i < KSTKSIZE; i += PGSIZE)
+	    assert(check_va2pa(pgdir, base + KSTKGAP + i)
+		    == PADDR(percpu_kstacks[n]) + i);
+	for (i = 0; i < KSTKGAP; i += PGSIZE)
+	    assert(check_va2pa(pgdir, base + i) == ~0);
+    }
+
+    // check PDE permissions
+    for (i = 0; i < NPDENTRIES; i++) {
+	switch (i) {
+	    case PDX(UVPT):
+	    case PDX(KSTACKTOP-1):
+	    case PDX(UPAGES):
+	    case PDX(UENVS):
+	    case PDX(MMIOBASE):
+		assert(pgdir[i] & PTE_P);
+		break;
+	    default:
+		if (i >= PDX(KERNBASE)) {
+		    assert(pgdir[i] & PTE_P);
+		    assert(pgdir[i] & PTE_W);
+		} else
+		    assert(pgdir[i] == 0);
+		break;
 	}
-	cprintf("check_kern_pgdir() succeeded!\n");
+    }
+    cprintf("check_kern_pgdir() succeeded!\n");
 }
 
 // This function returns the physical address of the page containing 'va',
@@ -771,236 +881,236 @@ check_kern_pgdir(void)
 // this functionality for us!  We define our own version to help check
 // the check_kern_pgdir() function; it shouldn't be used elsewhere.
 
-static physaddr_t
+    static physaddr_t
 check_va2pa(pde_t *pgdir, uintptr_t va)
 {
-	pte_t *p;
-
-	pgdir = &pgdir[PDX(va)];
-	if (!(*pgdir & PTE_P))
-		return ~0;
-	p = (pte_t*) KADDR(PTE_ADDR(*pgdir));
-	if (!(p[PTX(va)] & PTE_P))
-		return ~0;
-	return PTE_ADDR(p[PTX(va)]);
+    pte_t *p;
+
+    pgdir = &pgdir[PDX(va)];
+    if (!(*pgdir & PTE_P))
+	return ~0;
+    p = (pte_t*) KADDR(PTE_ADDR(*pgdir));
+    if (!(p[PTX(va)] & PTE_P))
+	return ~0;
+    return PTE_ADDR(p[PTX(va)]);
 }
 
 
 // check page_insert, page_remove, &c
-static void
+    static void
 check_page(void)
 {
-	struct PageInfo *pp, *pp0, *pp1, *pp2;
-	struct PageInfo *fl;
-	pte_t *ptep, *ptep1;
-	void *va;
-	uintptr_t mm1, mm2;
-	int i;
-	extern pde_t entry_pgdir[];
-
-	// should be able to allocate three pages
-	pp0 = pp1 = pp2 = 0;
-	assert((pp0 = page_alloc(0)));
-	assert((pp1 = page_alloc(0)));
-	assert((pp2 = page_alloc(0)));
-
-	assert(pp0);
-	assert(pp1 && pp1 != pp0);
-	assert(pp2 && pp2 != pp1 && pp2 != pp0);
-
-	// temporarily steal the rest of the free pages
-	fl = page_free_list;
-	page_free_list = 0;
-
-	// should be no free memory
-	assert(!page_alloc(0));
-
-	// there is no page allocated at address 0
-	assert(page_lookup(kern_pgdir, (void *) 0x0, &ptep) == NULL);
-
-	// there is no free memory, so we can't allocate a page table
-	assert(page_insert(kern_pgdir, pp1, 0x0, PTE_W) < 0);
-
-	// free pp0 and try again: pp0 should be used for page table
-	page_free(pp0);
-	assert(page_insert(kern_pgdir, pp1, 0x0, PTE_W) == 0);
-	assert(PTE_ADDR(kern_pgdir[0]) == page2pa(pp0));
-	assert(check_va2pa(kern_pgdir, 0x0) == page2pa(pp1));
-	assert(pp1->pp_ref == 1);
-	assert(pp0->pp_ref == 1);
-
-	// should be able to map pp2 at PGSIZE because pp0 is already allocated for page table
-	assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W) == 0);
-	assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp2));
-	assert(pp2->pp_ref == 1);
-
-	// should be no free memory
-	assert(!page_alloc(0));
-
-	// should be able to map pp2 at PGSIZE because it's already there
-	assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W) == 0);
-	assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp2));
-	assert(pp2->pp_ref == 1);
-
-	// pp2 should NOT be on the free list
-	// could happen in ref counts are handled sloppily in page_insert
-	assert(!page_alloc(0));
-
-	// check that pgdir_walk returns a pointer to the pte
-	ptep = (pte_t *) KADDR(PTE_ADDR(kern_pgdir[PDX(PGSIZE)]));
-	assert(pgdir_walk(kern_pgdir, (void*)PGSIZE, 0) == ptep+PTX(PGSIZE));
-
-	// should be able to change permissions too.
-	assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W|PTE_U) == 0);
-	assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp2));
-	assert(pp2->pp_ref == 1);
-	assert(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_U);
-	assert(kern_pgdir[0] & PTE_U);
-
-	// should be able to remap with fewer permissions
-	assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W) == 0);
-	assert(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_W);
-	assert(!(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_U));
-
-	// should not be able to map at PTSIZE because need free page for page table
-	assert(page_insert(kern_pgdir, pp0, (void*) PTSIZE, PTE_W) < 0);
-
-	// insert pp1 at PGSIZE (replacing pp2)
-	assert(page_insert(kern_pgdir, pp1, (void*) PGSIZE, PTE_W) == 0);
-	assert(!(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_U));
-
-	// should have pp1 at both 0 and PGSIZE, pp2 nowhere, ...
-	assert(check_va2pa(kern_pgdir, 0) == page2pa(pp1));
-	assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp1));
-	// ... and ref counts should reflect this
-	assert(pp1->pp_ref == 2);
-	assert(pp2->pp_ref == 0);
-
-	// pp2 should be returned by page_alloc
-	assert((pp = page_alloc(0)) && pp == pp2);
-
-	// unmapping pp1 at 0 should keep pp1 at PGSIZE
-	page_remove(kern_pgdir, 0x0);
-	assert(check_va2pa(kern_pgdir, 0x0) == ~0);
-	assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp1));
-	assert(pp1->pp_ref == 1);
-	assert(pp2->pp_ref == 0);
-
-	// test re-inserting pp1 at PGSIZE
-	assert(page_insert(kern_pgdir, pp1, (void*) PGSIZE, 0) == 0);
-	assert(pp1->pp_ref);
-	assert(pp1->pp_link == NULL);
-
-	// unmapping pp1 at PGSIZE should free it
-	page_remove(kern_pgdir, (void*) PGSIZE);
-	assert(check_va2pa(kern_pgdir, 0x0) == ~0);
-	assert(check_va2pa(kern_pgdir, PGSIZE) == ~0);
-	assert(pp1->pp_ref == 0);
-	assert(pp2->pp_ref == 0);
-
-	// so it should be returned by page_alloc
-	assert((pp = page_alloc(0)) && pp == pp1);
-
-	// should be no free memory
-	assert(!page_alloc(0));
-
-	// forcibly take pp0 back
-	assert(PTE_ADDR(kern_pgdir[0]) == page2pa(pp0));
-	kern_pgdir[0] = 0;
-	assert(pp0->pp_ref == 1);
-	pp0->pp_ref = 0;
-
-	// check pointer arithmetic in pgdir_walk
-	page_free(pp0);
-	va = (void*)(PGSIZE * NPDENTRIES + PGSIZE);
-	ptep = pgdir_walk(kern_pgdir, va, 1);
-	ptep1 = (pte_t *) KADDR(PTE_ADDR(kern_pgdir[PDX(va)]));
-	assert(ptep == ptep1 + PTX(va));
-	kern_pgdir[PDX(va)] = 0;
-	pp0->pp_ref = 0;
-
-	// check that new page tables get cleared
-	memset(page2kva(pp0), 0xFF, PGSIZE);
-	page_free(pp0);
-	pgdir_walk(kern_pgdir, 0x0, 1);
-	ptep = (pte_t *) page2kva(pp0);
-	for(i=0; i<NPTENTRIES; i++)
-		assert((ptep[i] & PTE_P) == 0);
-	kern_pgdir[0] = 0;
-	pp0->pp_ref = 0;
-
-	// give free list back
-	page_free_list = fl;
-
-	// free the pages we took
-	page_free(pp0);
-	page_free(pp1);
-	page_free(pp2);
-
-	// test mmio_map_region
-	mm1 = (uintptr_t) mmio_map_region(0, 4097);
-	mm2 = (uintptr_t) mmio_map_region(0, 4096);
-	// check that they're in the right region
-	assert(mm1 >= MMIOBASE && mm1 + 8096 < MMIOLIM);
-	assert(mm2 >= MMIOBASE && mm2 + 8096 < MMIOLIM);
-	// check that they're page-aligned
-	assert(mm1 % PGSIZE == 0 && mm2 % PGSIZE == 0);
-	// check that they don't overlap
-	assert(mm1 + 8096 <= mm2);
-	// check page mappings
-	assert(check_va2pa(kern_pgdir, mm1) == 0);
-	assert(check_va2pa(kern_pgdir, mm1+PGSIZE) == PGSIZE);
-	assert(check_va2pa(kern_pgdir, mm2) == 0);
-	assert(check_va2pa(kern_pgdir, mm2+PGSIZE) == ~0);
-	// check permissions
-	assert(*pgdir_walk(kern_pgdir, (void*) mm1, 0) & (PTE_W|PTE_PWT|PTE_PCD));
-	assert(!(*pgdir_walk(kern_pgdir, (void*) mm1, 0) & PTE_U));
-	// clear the mappings
-	*pgdir_walk(kern_pgdir, (void*) mm1, 0) = 0;
-	*pgdir_walk(kern_pgdir, (void*) mm1 + PGSIZE, 0) = 0;
-	*pgdir_walk(kern_pgdir, (void*) mm2, 0) = 0;
-
-	cprintf("check_page() succeeded!\n");
+    struct PageInfo *pp, *pp0, *pp1, *pp2;
+    struct PageInfo *fl;
+    pte_t *ptep, *ptep1;
+    void *va;
+    uintptr_t mm1, mm2;
+    int i;
+    extern pde_t entry_pgdir[];
+
+    // should be able to allocate three pages
+    pp0 = pp1 = pp2 = 0;
+    assert((pp0 = page_alloc(0)));
+    assert((pp1 = page_alloc(0)));
+    assert((pp2 = page_alloc(0)));
+
+    assert(pp0);
+    assert(pp1 && pp1 != pp0);
+    assert(pp2 && pp2 != pp1 && pp2 != pp0);
+
+    // temporarily steal the rest of the free pages
+    fl = page_free_list;
+    page_free_list = 0;
+
+    // should be no free memory
+    assert(!page_alloc(0));
+
+    // there is no page allocated at address 0
+    assert(page_lookup(kern_pgdir, (void *) 0x0, &ptep) == NULL);
+
+    // there is no free memory, so we can't allocate a page table
+    assert(page_insert(kern_pgdir, pp1, 0x0, PTE_W) < 0);
+
+    // free pp0 and try again: pp0 should be used for page table
+    page_free(pp0);
+    assert(page_insert(kern_pgdir, pp1, 0x0, PTE_W) == 0);
+    assert(PTE_ADDR(kern_pgdir[0]) == page2pa(pp0));
+    assert(check_va2pa(kern_pgdir, 0x0) == page2pa(pp1));
+    assert(pp1->pp_ref == 1);
+    assert(pp0->pp_ref == 1);
+
+    // should be able to map pp2 at PGSIZE because pp0 is already allocated for page table
+    assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W) == 0);
+    assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp2));
+    assert(pp2->pp_ref == 1);
+
+    // should be no free memory
+    assert(!page_alloc(0));
+
+    // should be able to map pp2 at PGSIZE because it's already there
+    assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W) == 0);
+    assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp2));
+    assert(pp2->pp_ref == 1);
+
+    // pp2 should NOT be on the free list
+    // could happen in ref counts are handled sloppily in page_insert
+    assert(!page_alloc(0));
+
+    // check that pgdir_walk returns a pointer to the pte
+    ptep = (pte_t *) KADDR(PTE_ADDR(kern_pgdir[PDX(PGSIZE)]));
+    assert(pgdir_walk(kern_pgdir, (void*)PGSIZE, 0) == ptep+PTX(PGSIZE));
+
+    // should be able to change permissions too.
+    assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W|PTE_U) == 0);
+    assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp2));
+    assert(pp2->pp_ref == 1);
+    assert(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_U);
+    assert(kern_pgdir[0] & PTE_U);
+
+    // should be able to remap with fewer permissions
+    assert(page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W) == 0);
+    assert(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_W);
+    assert(!(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_U));
+
+    // should not be able to map at PTSIZE because need free page for page table
+    assert(page_insert(kern_pgdir, pp0, (void*) PTSIZE, PTE_W) < 0);
+
+    // insert pp1 at PGSIZE (replacing pp2)
+    assert(page_insert(kern_pgdir, pp1, (void*) PGSIZE, PTE_W) == 0);
+    assert(!(*pgdir_walk(kern_pgdir, (void*) PGSIZE, 0) & PTE_U));
+
+    // should have pp1 at both 0 and PGSIZE, pp2 nowhere, ...
+    assert(check_va2pa(kern_pgdir, 0) == page2pa(pp1));
+    assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp1));
+    // ... and ref counts should reflect this
+    assert(pp1->pp_ref == 2);
+    assert(pp2->pp_ref == 0);
+
+    // pp2 should be returned by page_alloc
+    assert((pp = page_alloc(0)) && pp == pp2);
+
+    // unmapping pp1 at 0 should keep pp1 at PGSIZE
+    page_remove(kern_pgdir, 0x0);
+    assert(check_va2pa(kern_pgdir, 0x0) == ~0);
+    assert(check_va2pa(kern_pgdir, PGSIZE) == page2pa(pp1));
+    assert(pp1->pp_ref == 1);
+    assert(pp2->pp_ref == 0);
+
+    // test re-inserting pp1 at PGSIZE
+    assert(page_insert(kern_pgdir, pp1, (void*) PGSIZE, 0) == 0);
+    assert(pp1->pp_ref);
+    assert(pp1->pp_link == NULL);
+
+    // unmapping pp1 at PGSIZE should free it
+    page_remove(kern_pgdir, (void*) PGSIZE);
+    assert(check_va2pa(kern_pgdir, 0x0) == ~0);
+    assert(check_va2pa(kern_pgdir, PGSIZE) == ~0);
+    assert(pp1->pp_ref == 0);
+    assert(pp2->pp_ref == 0);
+
+    // so it should be returned by page_alloc
+    assert((pp = page_alloc(0)) && pp == pp1);
+
+    // should be no free memory
+    assert(!page_alloc(0));
+
+    // forcibly take pp0 back
+    assert(PTE_ADDR(kern_pgdir[0]) == page2pa(pp0));
+    kern_pgdir[0] = 0;
+    assert(pp0->pp_ref == 1);
+    pp0->pp_ref = 0;
+
+    // check pointer arithmetic in pgdir_walk
+    page_free(pp0);
+    va = (void*)(PGSIZE * NPDENTRIES + PGSIZE);
+    ptep = pgdir_walk(kern_pgdir, va, 1);
+    ptep1 = (pte_t *) KADDR(PTE_ADDR(kern_pgdir[PDX(va)]));
+    assert(ptep == ptep1 + PTX(va));
+    kern_pgdir[PDX(va)] = 0;
+    pp0->pp_ref = 0;
+
+    // check that new page tables get cleared
+    memset(page2kva(pp0), 0xFF, PGSIZE);
+    page_free(pp0);
+    pgdir_walk(kern_pgdir, 0x0, 1);
+    ptep = (pte_t *) page2kva(pp0);
+    for(i=0; i<NPTENTRIES; i++)
+	assert((ptep[i] & PTE_P) == 0);
+    kern_pgdir[0] = 0;
+    pp0->pp_ref = 0;
+
+    // give free list back
+    page_free_list = fl;
+
+    // free the pages we took
+    page_free(pp0);
+    page_free(pp1);
+    page_free(pp2);
+
+    // test mmio_map_region
+    mm1 = (uintptr_t) mmio_map_region(0, 4097);
+    mm2 = (uintptr_t) mmio_map_region(0, 4096);
+    // check that they're in the right region
+    assert(mm1 >= MMIOBASE && mm1 + 8096 < MMIOLIM);
+    assert(mm2 >= MMIOBASE && mm2 + 8096 < MMIOLIM);
+    // check that they're page-aligned
+    assert(mm1 % PGSIZE == 0 && mm2 % PGSIZE == 0);
+    // check that they don't overlap
+    assert(mm1 + 8096 <= mm2);
+    // check page mappings
+    assert(check_va2pa(kern_pgdir, mm1) == 0);
+    assert(check_va2pa(kern_pgdir, mm1+PGSIZE) == PGSIZE);
+    assert(check_va2pa(kern_pgdir, mm2) == 0);
+    assert(check_va2pa(kern_pgdir, mm2+PGSIZE) == ~0);
+    // check permissions
+    assert(*pgdir_walk(kern_pgdir, (void*) mm1, 0) & (PTE_W|PTE_PWT|PTE_PCD));
+    assert(!(*pgdir_walk(kern_pgdir, (void*) mm1, 0) & PTE_U));
+    // clear the mappings
+    *pgdir_walk(kern_pgdir, (void*) mm1, 0) = 0;
+    *pgdir_walk(kern_pgdir, (void*) mm1 + PGSIZE, 0) = 0;
+    *pgdir_walk(kern_pgdir, (void*) mm2, 0) = 0;
+
+    cprintf("check_page() succeeded!\n");
 }
 
 // check page_insert, page_remove, &c, with an installed kern_pgdir
-static void
+    static void
 check_page_installed_pgdir(void)
 {
-	struct PageInfo *pp, *pp0, *pp1, *pp2;
-	struct PageInfo *fl;
-	pte_t *ptep, *ptep1;
-	uintptr_t va;
-	int i;
-
-	// check that we can read and write installed pages
-	pp1 = pp2 = 0;
-	assert((pp0 = page_alloc(0)));
-	assert((pp1 = page_alloc(0)));
-	assert((pp2 = page_alloc(0)));
-	page_free(pp0);
-	memset(page2kva(pp1), 1, PGSIZE);
-	memset(page2kva(pp2), 2, PGSIZE);
-	page_insert(kern_pgdir, pp1, (void*) PGSIZE, PTE_W);
-	assert(pp1->pp_ref == 1);
-	assert(*(uint32_t *)PGSIZE == 0x01010101U);
-	page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W);
-	assert(*(uint32_t *)PGSIZE == 0x02020202U);
-	assert(pp2->pp_ref == 1);
-	assert(pp1->pp_ref == 0);
-	*(uint32_t *)PGSIZE = 0x03030303U;
-	assert(*(uint32_t *)page2kva(pp2) == 0x03030303U);
-	page_remove(kern_pgdir, (void*) PGSIZE);
-	assert(pp2->pp_ref == 0);
-
-	// forcibly take pp0 back
-	assert(PTE_ADDR(kern_pgdir[0]) == page2pa(pp0));
-	kern_pgdir[0] = 0;
-	assert(pp0->pp_ref == 1);
-	pp0->pp_ref = 0;
-
-	// free the pages we took
-	page_free(pp0);
-
-	cprintf("check_page_installed_pgdir() succeeded!\n");
+    struct PageInfo *pp, *pp0, *pp1, *pp2;
+    struct PageInfo *fl;
+    pte_t *ptep, *ptep1;
+    uintptr_t va;
+    int i;
+
+    // check that we can read and write installed pages
+    pp1 = pp2 = 0;
+    assert((pp0 = page_alloc(0)));
+    assert((pp1 = page_alloc(0)));
+    assert((pp2 = page_alloc(0)));
+    page_free(pp0);
+    memset(page2kva(pp1), 1, PGSIZE);
+    memset(page2kva(pp2), 2, PGSIZE);
+    page_insert(kern_pgdir, pp1, (void*) PGSIZE, PTE_W);
+    assert(pp1->pp_ref == 1);
+    assert(*(uint32_t *)PGSIZE == 0x01010101U);
+    page_insert(kern_pgdir, pp2, (void*) PGSIZE, PTE_W);
+    assert(*(uint32_t *)PGSIZE == 0x02020202U);
+    assert(pp2->pp_ref == 1);
+    assert(pp1->pp_ref == 0);
+    *(uint32_t *)PGSIZE = 0x03030303U;
+    assert(*(uint32_t *)page2kva(pp2) == 0x03030303U);
+    page_remove(kern_pgdir, (void*) PGSIZE);
+    assert(pp2->pp_ref == 0);
+
+    // forcibly take pp0 back
+    assert(PTE_ADDR(kern_pgdir[0]) == page2pa(pp0));
+    kern_pgdir[0] = 0;
+    assert(pp0->pp_ref == 1);
+    pp0->pp_ref = 0;
+
+    // free the pages we took
+    page_free(pp0);
+
+    cprintf("check_page_installed_pgdir() succeeded!\n");
 }
diff --git a/kern/pmap.h b/kern/pmap.h
old mode 100644
new mode 100755
diff --git a/kern/printf.c b/kern/printf.c
old mode 100644
new mode 100755
diff --git a/kern/sched.c b/kern/sched.c
old mode 100644
new mode 100755
index fbd2790..da94fb7
--- a/kern/sched.c
+++ b/kern/sched.c
@@ -8,76 +8,86 @@
 void sched_halt(void);
 
 // Choose a user environment to run and run it.
-void
+    void
 sched_yield(void)
 {
-	struct Env *idle;
+    struct Env *idle;
 
-	// Implement simple round-robin scheduling.
-	//
-	// Search through 'envs' for an ENV_RUNNABLE environment in
-	// circular fashion starting just after the env this CPU was
-	// last running.  Switch to the first such environment found.
-	//
-	// If no envs are runnable, but the environment previously
-	// running on this CPU is still ENV_RUNNING, it's okay to
-	// choose that environment.
-	//
-	// Never choose an environment that's currently running on
-	// another CPU (env_status == ENV_RUNNING). If there are
-	// no runnable environments, simply drop through to the code
-	// below to halt the cpu.
+    // Implement simple round-robin scheduling.
+    //
+    // Search through 'envs' for an ENV_RUNNABLE environment in
+    // circular fashion starting just after the env this CPU was
+    // last running.  Switch to the first such environment found.
+    //
+    // If no envs are runnable, but the environment previously
+    // running on this CPU is still ENV_RUNNING, it's okay to
+    // choose that environment.
+    //
+    // Never choose an environment that's currently running on
+    // another CPU (env_status == ENV_RUNNING). If there are
+    // no runnable environments, simply drop through to the code
+    // below to halt the cpu.
+    // LAB 4: Your code here.
+    int i;
+    if (curenv!=NULL) idle = curenv + 1;
+    else
+	idle =envs;
 
-	// LAB 4: Your code here.
-
-	// sched_halt never returns
-	sched_halt();
+    for(i=0;i<NENV; i++,idle++)
+    {
+	if(idle >= envs+NENV) idle = envs;
+	if(idle->env_status== ENV_RUNNABLE) env_run(idle);
+    }
+    if(thiscpu->cpu_env!=NULL&& thiscpu->cpu_env->env_status==ENV_RUNNING)
+	env_run(curenv);
+    // sched_halt never returns
+    sched_halt();
 }
 
 // Halt this CPU when there is nothing to do. Wait until the
 // timer interrupt wakes it up. This function never returns.
 //
-void
+    void
 sched_halt(void)
 {
-	int i;
+    int i;
 
-	// For debugging and testing purposes, if there are no runnable
-	// environments in the system, then drop into the kernel monitor.
-	for (i = 0; i < NENV; i++) {
-		if ((envs[i].env_status == ENV_RUNNABLE ||
-		     envs[i].env_status == ENV_RUNNING ||
-		     envs[i].env_status == ENV_DYING))
-			break;
-	}
-	if (i == NENV) {
-		cprintf("No runnable environments in the system!\n");
-		while (1)
-			monitor(NULL);
-	}
+    // For debugging and testing purposes, if there are no runnable
+    // environments in the system, then drop into the kernel monitor.
+    for (i = 0; i < NENV; i++) {
+	if ((envs[i].env_status == ENV_RUNNABLE ||
+		    envs[i].env_status == ENV_RUNNING ||
+		    envs[i].env_status == ENV_DYING))
+	    break;
+    }
+    if (i == NENV) {
+	cprintf("No runnable environments in the system!\n");
+	while (1)
+	    monitor(NULL);
+    }
 
-	// Mark that no environment is running on this CPU
-	curenv = NULL;
-	lcr3(PADDR(kern_pgdir));
+    // Mark that no environment is running on this CPU
+    curenv = NULL;
+    lcr3(PADDR(kern_pgdir));
 
-	// Mark that this CPU is in the HALT state, so that when
-	// timer interupts come in, we know we should re-acquire the
-	// big kernel lock
-	xchg(&thiscpu->cpu_status, CPU_HALTED);
+    // Mark that this CPU is in the HALT state, so that when
+    // timer interupts come in, we know we should re-acquire the
+    // big kernel lock
+    xchg(&thiscpu->cpu_status, CPU_HALTED);
 
-	// Release the big kernel lock as if we were "leaving" the kernel
-	unlock_kernel();
+    // Release the big kernel lock as if we were "leaving" the kernel
+    unlock_kernel();
 
-	// Reset stack pointer, enable interrupts and then halt.
-	asm volatile (
-		"movl $0, %%ebp\n"
-		"movl %0, %%esp\n"
-		"pushl $0\n"
-		"pushl $0\n"
-		"sti\n"
-		"1:\n"
-		"hlt\n"
-		"jmp 1b\n"
-	: : "a" (thiscpu->cpu_ts.ts_esp0));
+    // Reset stack pointer, enable interrupts and then halt.
+    asm volatile (
+	    "movl $0, %%ebp\n"
+	    "movl %0, %%esp\n"
+	    "pushl $0\n"
+	    "pushl $0\n"
+	    "sti\n"
+	    "1:\n"
+	    "hlt\n"
+	    "jmp 1b\n"
+	    : : "a" (thiscpu->cpu_ts.ts_esp0));
 }
 
diff --git a/kern/sched.h b/kern/sched.h
old mode 100644
new mode 100755
diff --git a/kern/spinlock.c b/kern/spinlock.c
old mode 100644
new mode 100755
diff --git a/kern/spinlock.h b/kern/spinlock.h
old mode 100644
new mode 100755
diff --git a/kern/syscall.c b/kern/syscall.c
old mode 100644
new mode 100755
index 85759fe..4aca407
--- a/kern/syscall.c
+++ b/kern/syscall.c
@@ -4,6 +4,7 @@
 #include <inc/error.h>
 #include <inc/string.h>
 #include <inc/assert.h>
+#include <inc/elf.h>
 
 #include <kern/env.h>
 #include <kern/pmap.h>
@@ -15,31 +16,33 @@
 // Print a string to the system console.
 // The string is exactly 'len' characters long.
 // Destroys the environment on memory errors.
-static void
+    static void
 sys_cputs(const char *s, size_t len)
 {
-	// Check that the user has permission to read memory [s, s+len).
-	// Destroy the environment if not.
+    // Check that the user has permission to read memory [s, s+len).
+    // Destroy the environment if not.
 
-	// LAB 3: Your code here.
+    // LAB 3: Your code here.
+    if (curenv->env_tf.tf_cs & 3)
+		user_mem_assert(curenv, s, len, 0);
 
-	// Print the string supplied by the user.
-	cprintf("%.*s", len, s);
+    // Print the string supplied by the user.
+    cprintf("%.*s", len, s);
 }
 
 // Read a character from the system console without blocking.
 // Returns the character, or 0 if there is no input waiting.
-static int
+    static int
 sys_cgetc(void)
 {
-	return cons_getc();
+    return cons_getc();
 }
 
 // Returns the current environment's envid.
-static envid_t
+    static envid_t
 sys_getenvid(void)
 {
-	return curenv->env_id;
+    return curenv->env_id;
 }
 
 // Destroy a given environment (possibly the currently running environment).
@@ -47,40 +50,49 @@ sys_getenvid(void)
 // Returns 0 on success, < 0 on error.  Errors are:
 //	-E_BAD_ENV if environment envid doesn't currently exist,
 //		or the caller doesn't have permission to change envid.
-static int
+    static int
 sys_env_destroy(envid_t envid)
 {
-	int r;
-	struct Env *e;
+    int r;
+    struct Env *e;
 
-	if ((r = envid2env(envid, &e, 1)) < 0)
-		return r;
-	env_destroy(e);
-	return 0;
+    if ((r = envid2env(envid, &e, 1)) < 0)
+	return r;
+    if (e == curenv)
+	cprintf("[%08x] exiting gracefully\n", curenv->env_id);
+    else
+	cprintf("[%08x] destroying %08x\n", curenv->env_id, e->env_id);
+    env_destroy(e);
+    return 0;
 }
 
 // Deschedule current environment and pick a different one to run.
-static void
+    static void
 sys_yield(void)
 {
-	sched_yield();
+    sched_yield();
 }
 
 // Allocate a new environment.
 // Returns envid of new environment, or < 0 on error.  Errors are:
 //	-E_NO_FREE_ENV if no free environment is available.
 //	-E_NO_MEM on memory exhaustion.
-static envid_t
+    envid_t
 sys_exofork(void)
 {
-	// Create the new environment with env_alloc(), from kern/env.c.
-	// It should be left as env_alloc created it, except that
-	// status is set to ENV_NOT_RUNNABLE, and the register set is copied
-	// from the current environment -- but tweaked so sys_exofork
-	// will appear to return 0.
+    // Create the new environment with env_alloc(), from kern/env.c.
+    // It should be left as env_alloc created it, except that
+    // status is set to ENV_NOT_RUNNABLE, and the register set is copied
+    // from the current environment -- but tweaked so sys_exofork
+    // will appear to return 0.
 
-	// LAB 4: Your code here.
-	panic("sys_exofork not implemented");
+    // LAB 4: Your code here.
+    struct Env *e = NULL;
+    if (env_alloc(&e, curenv->env_id) == -E_NO_FREE_ENV) return -E_NO_FREE_ENV;
+    memcpy(&e->env_tf, &curenv->env_tf, sizeof(e->env_tf));
+    e->env_tf.tf_regs.reg_eax = 0;
+    e->env_status = ENV_NOT_RUNNABLE;
+    return e->env_id;
 }
 
 // Set envid's env_status to status, which must be ENV_RUNNABLE
@@ -90,17 +102,22 @@ sys_exofork(void)
 //	-E_BAD_ENV if environment envid doesn't currently exist,
 //		or the caller doesn't have permission to change envid.
 //	-E_INVAL if status is not a valid status for an environment.
-static int
+    static int
 sys_env_set_status(envid_t envid, int status)
 {
-	// Hint: Use the 'envid2env' function from kern/env.c to translate an
-	// envid to a struct Env.
-	// You should set envid2env's third argument to 1, which will
-	// check whether the current environment has permission to set
-	// envid's status.
+    // Hint: Use the 'envid2env' function from kern/env.c to translate an
+    // envid to a struct Env.
+    // You should set envid2env's third argument to 1, which will
+    // check whether the current environment has permission to set
+    // envid's status.
+
+    // LAB 4: Your code here.
+    struct Env *e;
+    if (envid2env(envid, &e, 1) == -E_BAD_ENV) return -E_BAD_ENV;
+    if (status != ENV_RUNNABLE && status != ENV_NOT_RUNNABLE) return -E_INVAL;
+    e->env_status = status;
+    return 0;
 
-	// LAB 4: Your code here.
-	panic("sys_env_set_status not implemented");
 }
 
 // Set envid's trap frame to 'tf'.
@@ -110,13 +127,20 @@ sys_env_set_status(envid_t envid, int status)
 // Returns 0 on success, < 0 on error.  Errors are:
 //	-E_BAD_ENV if environment envid doesn't currently exist,
 //		or the caller doesn't have permission to change envid.
-static int
+    static int
 sys_env_set_trapframe(envid_t envid, struct Trapframe *tf)
 {
-	// LAB 5: Your code here.
-	// Remember to check whether the user has supplied us with a good
-	// address!
-	panic("sys_env_set_trapframe not implemented");
+    // LAB 5: Your code here.
+    // Remember to check whether the user has supplied us with a good
+    // address!
+    struct Env *e;
+    if (envid2env(envid, &e, 1) == -E_BAD_ENV) return -E_BAD_ENV;
+    if ((uintptr_t)tf >= UTOP || !page_lookup(curenv->env_pgdir, tf, 0)) return -E_INVAL;
+    e->env_tf = *tf;
+    e->env_tf.tf_cs = GD_UT |  3;
+    e->env_tf.tf_eflags |= FL_IF;
+    e->env_tf.tf_eflags &= ~FL_IOPL_MASK;
+    return 0;
 }
 
 // Set the page fault upcall for 'envid' by modifying the corresponding struct
@@ -127,11 +151,14 @@ sys_env_set_trapframe(envid_t envid, struct Trapframe *tf)
 // Returns 0 on success, < 0 on error.  Errors are:
 //	-E_BAD_ENV if environment envid doesn't currently exist,
 //		or the caller doesn't have permission to change envid.
-static int
+    static int
 sys_env_set_pgfault_upcall(envid_t envid, void *func)
 {
-	// LAB 4: Your code here.
-	panic("sys_env_set_pgfault_upcall not implemented");
+    // LAB 4: Your code here.
+    struct Env *e;
+    if (envid2env(envid, &e, 1) == -E_BAD_ENV) return -E_BAD_ENV;
+    e->env_pgfault_upcall = func;
+    return 0;
 }
 
 // Allocate a page of memory and map it at 'va' with permission
@@ -150,18 +177,29 @@ sys_env_set_pgfault_upcall(envid_t envid, void *func)
 //	-E_INVAL if perm is inappropriate (see above).
 //	-E_NO_MEM if there's no memory to allocate the new page,
 //		or to allocate any necessary page tables.
-static int
+    static int
 sys_page_alloc(envid_t envid, void *va, int perm)
 {
-	// Hint: This function is a wrapper around page_alloc() and
-	//   page_insert() from kern/pmap.c.
-	//   Most of the new code you write should be to check the
-	//   parameters for correctness.
-	//   If page_insert() fails, remember to free the page you
-	//   allocated!
+    // Hint: This function is a wrapper around page_alloc() and
+    //   page_insert() from kern/pmap.c.
+    //   Most of the new code you write should be to check the
+    //   parameters for correctness.
+    //   If page_insert() fails, remember to free the page you
+    //   allocated!
 
-	// LAB 4: Your code here.
-	panic("sys_page_alloc not implemented");
+    // LAB 4: Your code here.
+    struct Env *e;
+    struct PageInfo *p;
+    perm &= PTE_SYSCALL;
+    if (envid2env(envid, &e, 1) == -E_BAD_ENV) return -E_BAD_ENV;
+    if ((uintptr_t)va >= UTOP || (uintptr_t)va % PGSIZE != 0) return -E_INVAL;
+    if ((perm & (PTE_U | PTE_P)) != (PTE_U | PTE_P)) return -E_INVAL;
+    if (!(p = page_alloc(ALLOC_ZERO))) return -E_NO_MEM;
+    if (page_insert(e->env_pgdir, p, va, perm) == -E_NO_MEM) {
+	page_free(p);
+	return -E_NO_MEM;
+    }
+    return 0;
 }
 
 // Map the page of memory at 'srcva' in srcenvid's address space
@@ -180,19 +218,34 @@ sys_page_alloc(envid_t envid, void *va, int perm)
 //	-E_INVAL if (perm & PTE_W), but srcva is read-only in srcenvid's
 //		address space.
 //	-E_NO_MEM if there's no memory to allocate any necessary page tables.
-static int
+    static int
 sys_page_map(envid_t srcenvid, void *srcva,
-	     envid_t dstenvid, void *dstva, int perm)
+	envid_t dstenvid, void *dstva, int perm)
 {
-	// Hint: This function is a wrapper around page_lookup() and
-	//   page_insert() from kern/pmap.c.
-	//   Again, most of the new code you write should be to check the
-	//   parameters for correctness.
-	//   Use the third argument to page_lookup() to
-	//   check the current permissions on the page.
+    // Hint: This function is a wrapper around page_lookup() and
+    //   page_insert() from kern/pmap.c.
+    //   Again, most of the new code you write should be to check the
+    //   parameters for correctness.
+    //   Use the third argument to page_lookup() to
+    //   check the current permissions on the page.
 
-	// LAB 4: Your code here.
-	panic("sys_page_map not implemented");
+    // LAB 4: Your code here.
+    struct Env *esrc, *edst;
+    struct PageInfo *p;
+    pte_t *pte;
+    perm &= PTE_SYSCALL;
+    if (envid2env(srcenvid, &esrc, 1) == -E_BAD_ENV) return -E_BAD_ENV;
+    if (envid2env(dstenvid, &edst, 1) == -E_BAD_ENV) return -E_BAD_ENV;
+    if ((uintptr_t)srcva >= UTOP || (uintptr_t)srcva % PGSIZE != 0) return -E_INVAL;
+    if ((uintptr_t)dstva >= UTOP || (uintptr_t)dstva % PGSIZE != 0) return -E_INVAL;
+    if (!(p = page_lookup(esrc->env_pgdir, srcva, &pte))) return -E_INVAL;
+    if ((perm & (PTE_U | PTE_P)) != (PTE_U | PTE_P)) return -E_INVAL;
+    if (perm & PTE_W & ~*pte) return -E_INVAL;
+    if (page_insert(edst->env_pgdir, p, dstva, perm) == -E_NO_MEM){
+	page_free(p);
+	return -E_NO_MEM;
+    }
+    return 0;
 }
 
 // Unmap the page of memory at 'va' in the address space of 'envid'.
@@ -202,13 +255,17 @@ sys_page_map(envid_t srcenvid, void *srcva,
 //	-E_BAD_ENV if environment envid doesn't currently exist,
 //		or the caller doesn't have permission to change envid.
 //	-E_INVAL if va >= UTOP, or va is not page-aligned.
-static int
+    static int
 sys_page_unmap(envid_t envid, void *va)
 {
-	// Hint: This function is a wrapper around page_remove().
+    // Hint: This function is a wrapper around page_remove().
 
-	// LAB 4: Your code here.
-	panic("sys_page_unmap not implemented");
+    // LAB 4: Your code here.
+    struct Env *e;
+    if (envid2env(envid, &e, 1) == -E_BAD_ENV) return -E_BAD_ENV;
+    if ((uintptr_t)va >= UTOP || (uintptr_t)va % PGSIZE != 0) return -E_INVAL;
+    page_remove(e->env_pgdir, va);
+    return 0;
 }
 
 // Try to send 'value' to the target env 'envid'.
@@ -249,11 +306,34 @@ sys_page_unmap(envid_t envid, void *va)
 //		current environment's address space.
 //	-E_NO_MEM if there's not enough memory to map srcva in envid's
 //		address space.
-static int
+    static int
 sys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, unsigned perm)
 {
-	// LAB 4: Your code here.
-	panic("sys_ipc_try_send not implemented");
+    // LAB 4: Your code here.
+    struct Env *e;
+    struct PageInfo *p;
+    pte_t *pte;
+    perm &= PTE_SYSCALL;
+    if (envid2env(envid, &e, 0) == -E_BAD_ENV) return -E_BAD_ENV;
+    if (!e->env_ipc_recving) return -E_IPC_NOT_RECV;
+    if ((uintptr_t)srcva < UTOP) {
+	if ((uintptr_t)srcva % PGSIZE) return -E_INVAL;
+	if ((perm & (PTE_P | PTE_U)) != (PTE_P | PTE_U)) return -E_INVAL;
+	if (!(p = page_lookup(curenv->env_pgdir, srcva, &pte))) return -E_INVAL;
+	if (perm & PTE_W & ~*pte) return -E_INVAL;
+    }
+    e->env_ipc_recving = 0;
+    e->env_ipc_from = curenv->env_id;
+    e->env_ipc_value = value;
+    if ((uintptr_t)e->env_ipc_dstva < UTOP && (uintptr_t)srcva < UTOP) {
+	if (page_insert(e->env_pgdir, p, e->env_ipc_dstva, perm) == -E_NO_MEM) {
+	    return -E_NO_MEM;
+	}
+	e->env_ipc_perm = perm;
+    }
+    e->env_status = ENV_RUNNABLE;
+    e->env_tf.tf_regs.reg_eax = 0;
+    return 0;
 }
 
 // Block until a value is ready.  Record that you want to receive
@@ -267,27 +347,101 @@ sys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, unsigned perm)
 // return 0 on success.
 // Return < 0 on error.  Errors are:
 //	-E_INVAL if dstva < UTOP but dstva is not page-aligned.
-static int
+    static int
 sys_ipc_recv(void *dstva)
 {
-	// LAB 4: Your code here.
-	panic("sys_ipc_recv not implemented");
-	return 0;
+    // LAB 4: Your code here.
+    if ((uintptr_t)dstva < UTOP && (uintptr_t)dstva % PGSIZE) return -E_INVAL;
+    struct Env *e = curenv;
+    e->env_ipc_recving = 1;
+    e->env_ipc_dstva = dstva;
+    e->env_ipc_perm = 0;
+    e->env_status = ENV_NOT_RUNNABLE;
+    return 0;
 }
 
+	static int
+sys_exec(uint32_t eip, uint32_t esp, void *v_ph, uint32_t phnum)
+{
+	memset((void *) (&curenv->env_tf.tf_regs), 0, sizeof(struct PushRegs));
+	curenv->env_tf.tf_eip = eip;
+	cprintf("eip: %x\n", eip);
+	curenv->env_tf.tf_esp = esp;
+	int perm, i;
+	uint32_t now_addr = 0x80000000;
+	uint32_t now_stack = now_addr - PGSIZE;
+	uint32_t va, end_addr;
+	struct PageInfo *pg;
+
+	struct Proghdr *ph = (struct Proghdr *)v_ph;
+	for (i = 0; i < phnum; ++i, ph++)
+	{
+		if(ph->p_type != ELF_PROG_LOAD)
+			continue;
+		perm = PTE_P | PTE_U;
+		if(ph->p_flags & ELF_PROG_FLAG_WRITE)
+			perm |= PTE_W;
+		end_addr = ROUNDUP(ph->p_va + ph->p_memsz, PGSIZE);
+		for (va = ROUNDDOWN(ph->p_va, PGSIZE); va != end_addr; va += PGSIZE)
+		{
+			if((pg = page_lookup(curenv->env_pgdir, (void *)(now_addr + va), NULL)) == NULL)
+				return -E_NO_MEM;
+			if(page_insert(curenv->env_pgdir, pg, (void *)va, perm) < 0)
+				return -E_NO_MEM;
+			page_remove(curenv->env_pgdir, (void *)(now_addr + va));
+		}
+	}
+	
+	if((pg = page_lookup(curenv->env_pgdir, (void *)now_stack, NULL)) == NULL)
+		return -E_NO_MEM;
+	if(page_insert(curenv->env_pgdir, pg, (void *)(USTACKTOP - PGSIZE), PTE_P | PTE_U | PTE_W) < 0)
+		return -E_NO_MEM;
+	page_remove(curenv->env_pgdir, (void *)now_stack);
+	
+	env_run(curenv);
+	return 0;
+}
 // Dispatches to the correct kernel function, passing the arguments.
-int32_t
+    int32_t
 syscall(uint32_t syscallno, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5)
 {
-	// Call the function corresponding to the 'syscallno' parameter.
-	// Return any appropriate return value.
-	// LAB 3: Your code here.
-
-	panic("syscall not implemented");
-
-	switch (syscallno) {
+    // Call the function corresponding to the 'syscallno' parameter.
+    // Return any appropriate return value.
+    // LAB 3: Your code here.
+    switch (syscallno) {
+	case SYS_cputs:
+	    sys_cputs((const char*)a1, (size_t)a2);
+	    return 0;
+	case SYS_cgetc:
+	    return sys_cgetc();
+	case SYS_getenvid:
+	    return sys_getenvid();
+	case SYS_env_destroy:
+	    return sys_env_destroy((envid_t)a1);
+	case SYS_yield:
+	    sys_yield();
+	case SYS_exofork:
+	    return sys_exofork();
+	case SYS_env_set_status:
+	    return sys_env_set_status((envid_t)a1, (int)a2);
+	case SYS_page_alloc:
+	    return sys_page_alloc((envid_t)a1, (void*)a2, (int)a3);
+	case SYS_page_map:
+	    return sys_page_map((envid_t)a1, (void*)a2, (envid_t)a3, (void*)a4, (int)a5);
+	case SYS_page_unmap:
+	    return sys_page_unmap((envid_t)a1, (void*)a2);
+	case SYS_env_set_pgfault_upcall:
+	    return sys_env_set_pgfault_upcall((envid_t)a1, (void*)a2);
+	case SYS_ipc_try_send:
+	    return sys_ipc_try_send((envid_t)a1, (uint32_t)a2, (void*)a3, (unsigned)a4);
+	case SYS_ipc_recv:
+	    return sys_ipc_recv((void*)a1);
+	case SYS_env_set_trapframe:
+	    return sys_env_set_trapframe((envid_t) a1, (struct Trapframe *)a2);
+	case SYS_exec:
+		return sys_exec((uint32_t) a1, (uint32_t) a2, (void *) a3, (uint32_t) a4);
 	default:
-		return -E_INVAL;
-	}
+	    return -E_INVAL;
+    }
 }
 
diff --git a/kern/syscall.h b/kern/syscall.h
old mode 100644
new mode 100755
diff --git a/kern/trap.c b/kern/trap.c
old mode 100644
new mode 100755
index 25694ef..008547c
--- a/kern/trap.c
+++ b/kern/trap.c
@@ -14,6 +14,7 @@
 #include <kern/cpu.h>
 #include <kern/spinlock.h>
 
+
 static struct Taskstate ts;
 
 /* For debugging, so print_trapframe can distinguish between printing
@@ -27,290 +28,429 @@ static struct Trapframe *last_tf;
  */
 struct Gatedesc idt[256] = { { 0 } };
 struct Pseudodesc idt_pd = {
-	sizeof(idt) - 1, (uint32_t) idt
+    sizeof(idt) - 1, (uint32_t) idt
 };
 
+struct IDT_ENTRY
+{
+	uint32_t name;
+	uint32_t num;
+	uint32_t dpl;
+	uint32_t istrap;
+};
 
 static const char *trapname(int trapno)
 {
-	static const char * const excnames[] = {
-		"Divide error",
-		"Debug",
-		"Non-Maskable Interrupt",
-		"Breakpoint",
-		"Overflow",
-		"BOUND Range Exceeded",
-		"Invalid Opcode",
-		"Device Not Available",
-		"Double Fault",
-		"Coprocessor Segment Overrun",
-		"Invalid TSS",
-		"Segment Not Present",
-		"Stack Fault",
-		"General Protection",
-		"Page Fault",
-		"(unknown trap)",
-		"x87 FPU Floating-Point Error",
-		"Alignment Check",
-		"Machine-Check",
-		"SIMD Floating-Point Exception"
-	};
-
-	if (trapno < ARRAY_SIZE(excnames))
-		return excnames[trapno];
-	if (trapno == T_SYSCALL)
-		return "System call";
-	if (trapno >= IRQ_OFFSET && trapno < IRQ_OFFSET + 16)
-		return "Hardware Interrupt";
-	return "(unknown trap)";
+    static const char * const excnames[] = {
+	"Divide error",
+	"Debug",
+	"Non-Maskable Interrupt",
+	"Breakpoint",
+	"Overflow",
+	"BOUND Range Exceeded",
+	"Invalid Opcode",
+	"Device Not Available",
+	"Double Fault",
+	"Coprocessor Segment Overrun",
+	"Invalid TSS",
+	"Segment Not Present",
+	"Stack Fault",
+	"General Protection",
+	"Page Fault",
+	"(unknown trap)",
+	"x87 FPU Floating-Point Error",
+	"Alignment Check",
+	"Machine-Check",
+	"SIMD Floating-Point Exception"
+    };
+
+    if (trapno < ARRAY_SIZE(excnames))
+	return excnames[trapno];
+    if (trapno == T_SYSCALL)
+	return "System call";
+    if (trapno >= IRQ_OFFSET && trapno < IRQ_OFFSET + 16)
+	return "Hardware Interrupt";
+    return "(unknown trap)";
 }
 
 
-void
+    void
 trap_init(void)
 {
-	extern struct Segdesc gdt[];
-
-	// LAB 3: Your code here.
+    extern struct Segdesc gdt[];
+    
+    extern void r_divide();
+	extern void r_debug();
+	extern void r_nmi();
+	extern void r_brkpt();
+	extern void r_oflow();
+	extern void r_bound();
+	extern void r_illop();
+	extern void r_device();
+	extern void r_dblflt();
+	extern void r_tss();
+	extern void r_segnp();
+	extern void r_stack();
+	extern void r_gpflt();
+	extern void r_pgflt();
+	extern void r_fperr();
+	extern void r_align();
+	extern void r_mchk();
+	extern void r_simderr();
+	extern void r_syscall();
+	extern void r_irq0();
+	extern void r_irq1();
+	extern void r_irq2();
+	extern void r_irq3();
+	extern void r_irq4();
+	extern void r_irq5();
+	extern void r_irq6();
+	extern void r_irq7();
+	extern void r_irq8();
+	extern void r_irq9();
+	extern void r_irq10();
+	extern void r_irq11();
+	extern void r_irq12();
+	extern void r_irq13();
+	extern void r_irq14();
+	extern void r_irq15();
+	/*
+	SETGATE(idt[T_DIVIDE], 0, GD_KT, r_divide, 0);
+	SETGATE(idt[T_DEBUG], 0, GD_KT, r_debug, 0);
+	SETGATE(idt[T_NMI], 0, GD_KT, r_nmi, 0);
+	SETGATE(idt[T_BRKPT], 0, GD_KT, r_brkpt, 3);
+	SETGATE(idt[T_OFLOW], 0, GD_KT, r_oflow, 0);
+	SETGATE(idt[T_BOUND], 0, GD_KT, r_bound, 0);
+	SETGATE(idt[T_ILLOP], 0, GD_KT, r_illop, 0);
+	SETGATE(idt[T_DEVICE], 0, GD_KT, r_device, 0);
+	SETGATE(idt[T_DBLFLT], 0, GD_KT, r_dblflt, 0);
+	SETGATE(idt[T_TSS], 0, GD_KT, r_tss, 0);
+	SETGATE(idt[T_SEGNP], 0, GD_KT, r_segnp, 0);
+	SETGATE(idt[T_STACK], 0, GD_KT, r_stack, 0);
+	SETGATE(idt[T_GPFLT], 0, GD_KT, r_gpflt, 0);
+	SETGATE(idt[T_PGFLT], 0, GD_KT, r_pgflt, 0);
+	SETGATE(idt[T_FPERR], 0, GD_KT, r_fperr, 0);
+	SETGATE(idt[T_ALIGN], 0, GD_KT, r_align, 0);
+	SETGATE(idt[T_MCHK], 0, GD_KT, r_mchk, 0);
+	SETGATE(idt[T_SIMDERR], 0, GD_KT, r_simderr, 0);
+	SETGATE(idt[T_SYSCALL], 0, GD_KT, r_syscall, 3);
+
+	SETGATE(idt[IRQ_OFFSET + 0], 0, GD_KT, r_irq0, 0);
+	SETGATE(idt[IRQ_OFFSET + 1], 0, GD_KT, r_irq1, 0);
+	SETGATE(idt[IRQ_OFFSET + 2], 0, GD_KT, r_irq2, 0);
+	SETGATE(idt[IRQ_OFFSET + 3], 0, GD_KT, r_irq3, 0);
+	SETGATE(idt[IRQ_OFFSET + 4], 0, GD_KT, r_irq4, 0);
+	SETGATE(idt[IRQ_OFFSET + 5], 0, GD_KT, r_irq5, 0);
+	SETGATE(idt[IRQ_OFFSET + 6], 0, GD_KT, r_irq6, 0);
+	SETGATE(idt[IRQ_OFFSET + 7], 0, GD_KT, r_irq7, 0);
+	SETGATE(idt[IRQ_OFFSET + 8], 0, GD_KT, r_irq8, 0);
+	SETGATE(idt[IRQ_OFFSET + 9], 0, GD_KT, r_irq9, 0);
+	SETGATE(idt[IRQ_OFFSET + 10], 0, GD_KT, r_irq10, 0);
+	SETGATE(idt[IRQ_OFFSET + 11], 0, GD_KT, r_irq11, 0);
+	SETGATE(idt[IRQ_OFFSET + 12], 0, GD_KT, r_irq12, 0);
+	SETGATE(idt[IRQ_OFFSET + 13], 0, GD_KT, r_irq13, 0);
+	SETGATE(idt[IRQ_OFFSET + 14], 0, GD_KT, r_irq14, 0);
+	SETGATE(idt[IRQ_OFFSET + 15], 0, GD_KT, r_irq15, 0);
+	*/
+	extern uint32_t * idt_entry;
+	struct IDT_ENTRY *idt_entrys = (struct IDT_ENTRY *)(&idt_entry);
+	int i = 0;
+	for(i = 0; i <= 0x30; i++)
+	{
+		SETGATE(idt[i],0,GD_KT,idt_entrys[i].name,idt_entrys[i].dpl);
+	}
 
-	// Per-CPU setup 
-	trap_init_percpu();
+    // Per-CPU setup 
+    trap_init_percpu();
 }
 
 // Initialize and load the per-CPU TSS and IDT
-void
+    void
 trap_init_percpu(void)
 {
-	// The example code here sets up the Task State Segment (TSS) and
-	// the TSS descriptor for CPU 0. But it is incorrect if we are
-	// running on other CPUs because each CPU has its own kernel stack.
-	// Fix the code so that it works for all CPUs.
-	//
-	// Hints:
-	//   - The macro "thiscpu" always refers to the current CPU's
-	//     struct CpuInfo;
-	//   - The ID of the current CPU is given by cpunum() or
-	//     thiscpu->cpu_id;
-	//   - Use "thiscpu->cpu_ts" as the TSS for the current CPU,
-	//     rather than the global "ts" variable;
-	//   - Use gdt[(GD_TSS0 >> 3) + i] for CPU i's TSS descriptor;
-	//   - You mapped the per-CPU kernel stacks in mem_init_mp()
-	//
-	// ltr sets a 'busy' flag in the TSS selector, so if you
-	// accidentally load the same TSS on more than one CPU, you'll
-	// get a triple fault.  If you set up an individual CPU's TSS
-	// wrong, you may not get a fault until you try to return from
-	// user space on that CPU.
-	//
-	// LAB 4: Your code here:
-
-	// Setup a TSS so that we get the right stack
-	// when we trap to the kernel.
-	ts.ts_esp0 = KSTACKTOP;
-	ts.ts_ss0 = GD_KD;
-	ts.ts_iomb = sizeof(struct Taskstate);
-
-	// Initialize the TSS slot of the gdt.
-	gdt[GD_TSS0 >> 3] = SEG16(STS_T32A, (uint32_t) (&ts),
-					sizeof(struct Taskstate) - 1, 0);
-	gdt[GD_TSS0 >> 3].sd_s = 0;
-
-	// Load the TSS selector (like other segment selectors, the
-	// bottom three bits are special; we leave them 0)
-	ltr(GD_TSS0);
-
-	// Load the IDT
-	lidt(&idt_pd);
+    // The example code here sets up the Task State Segment (TSS) and
+    // the TSS descriptor for CPU 0. But it is incorrect if we are
+    // running on other CPUs because each CPU has its own kernel stack.
+    // Fix the code so that it works for all CPUs.
+    //
+    // Hints:
+    //   - The macro "thiscpu" always refers to the current CPU's
+    //     struct CpuInfo;
+    //   - The ID of the current CPU is given by cpunum() or
+    //     thiscpu->cpu_id;
+    //   - Use "thiscpu->cpu_ts" as the TSS for the current CPU,
+    //     rather than the global "ts" variable;
+    //   - Use gdt[(GD_TSS0 >> 3) + i] for CPU i's TSS descriptor;
+    //   - You mapped the per-CPU kernel stacks in mem_init_mp()
+    //
+    // ltr sets a 'busy' flag in the TSS selector, so if you
+    // accidentally load the same TSS on more than one CPU, you'll
+    // get a triple fault.  If you set up an individual CPU's TSS
+    // wrong, you may not get a fault until you try to return from
+    // user space on that CPU.
+    //
+    // LAB 4: Your code here:
+    int i = thiscpu->cpu_id;
+
+    thiscpu->cpu_ts.ts_esp0 = KSTACKTOP - i * (KSTKSIZE + KSTKGAP);
+    thiscpu->cpu_ts.ts_ss0 = GD_KD;
+    thiscpu->cpu_ts.ts_iomb = sizeof(struct Taskstate);
+
+    // Initialize the TSS slot of the gdt.
+    gdt[(GD_TSS0 >> 3) + i] = SEG16(STS_T32A, (uint32_t) (&thiscpu->cpu_ts), sizeof(struct Taskstate), 0); 
+
+    gdt[(GD_TSS0 >> 3) + i].sd_s = 0;
+
+    // Load the TSS selector (like other segment selectors, the
+    // bottom three bits are special; we leave them 0)
+    ltr(GD_TSS0+ (i<<3));
+
+    // Load the IDT
+    lidt(&idt_pd);
 }
 
-void
+    void
 print_trapframe(struct Trapframe *tf)
 {
-	cprintf("TRAP frame at %p from CPU %d\n", tf, cpunum());
-	print_regs(&tf->tf_regs);
-	cprintf("  es   0x----%04x\n", tf->tf_es);
-	cprintf("  ds   0x----%04x\n", tf->tf_ds);
-	cprintf("  trap 0x%08x %s\n", tf->tf_trapno, trapname(tf->tf_trapno));
-	// If this trap was a page fault that just happened
-	// (so %cr2 is meaningful), print the faulting linear address.
-	if (tf == last_tf && tf->tf_trapno == T_PGFLT)
-		cprintf("  cr2  0x%08x\n", rcr2());
-	cprintf("  err  0x%08x", tf->tf_err);
-	// For page faults, print decoded fault error code:
-	// U/K=fault occurred in user/kernel mode
-	// W/R=a write/read caused the fault
-	// PR=a protection violation caused the fault (NP=page not present).
-	if (tf->tf_trapno == T_PGFLT)
-		cprintf(" [%s, %s, %s]\n",
-			tf->tf_err & 4 ? "user" : "kernel",
-			tf->tf_err & 2 ? "write" : "read",
-			tf->tf_err & 1 ? "protection" : "not-present");
-	else
-		cprintf("\n");
-	cprintf("  eip  0x%08x\n", tf->tf_eip);
-	cprintf("  cs   0x----%04x\n", tf->tf_cs);
-	cprintf("  flag 0x%08x\n", tf->tf_eflags);
-	if ((tf->tf_cs & 3) != 0) {
-		cprintf("  esp  0x%08x\n", tf->tf_esp);
-		cprintf("  ss   0x----%04x\n", tf->tf_ss);
-	}
+    cprintf("TRAP frame at %p from CPU %d\n", tf, cpunum());
+    print_regs(&tf->tf_regs);
+    cprintf("  es   0x----%04x\n", tf->tf_es);
+    cprintf("  ds   0x----%04x\n", tf->tf_ds);
+    cprintf("  trap 0x%08x %s\n", tf->tf_trapno, trapname(tf->tf_trapno));
+    // If this trap was a page fault that just happened
+    // (so %cr2 is meaningful), print the faulting linear address.
+    if (tf == last_tf && tf->tf_trapno == T_PGFLT)
+	cprintf("  cr2  0x%08x\n", rcr2());
+    cprintf("  err  0x%08x", tf->tf_err);
+    // For page faults, print decoded fault error code:
+    // U/K=fault occurred in user/kernel mode
+    // W/R=a write/read caused the fault
+    // PR=a protection violation caused the fault (NP=page not present).
+    if (tf->tf_trapno == T_PGFLT)
+	cprintf(" [%s, %s, %s]\n",
+		tf->tf_err & 4 ? "user" : "kernel",
+		tf->tf_err & 2 ? "write" : "read",
+		tf->tf_err & 1 ? "protection" : "not-present");
+    else
+	cprintf("\n");
+    cprintf("  eip  0x%08x\n", tf->tf_eip);
+    cprintf("  cs   0x----%04x\n", tf->tf_cs);
+    cprintf("  flag 0x%08x\n", tf->tf_eflags);
+    if ((tf->tf_cs & 3) != 0) {
+	cprintf("  esp  0x%08x\n", tf->tf_esp);
+	cprintf("  ss   0x----%04x\n", tf->tf_ss);
+    }
 }
 
-void
+    void
 print_regs(struct PushRegs *regs)
 {
-	cprintf("  edi  0x%08x\n", regs->reg_edi);
-	cprintf("  esi  0x%08x\n", regs->reg_esi);
-	cprintf("  ebp  0x%08x\n", regs->reg_ebp);
-	cprintf("  oesp 0x%08x\n", regs->reg_oesp);
-	cprintf("  ebx  0x%08x\n", regs->reg_ebx);
-	cprintf("  edx  0x%08x\n", regs->reg_edx);
-	cprintf("  ecx  0x%08x\n", regs->reg_ecx);
-	cprintf("  eax  0x%08x\n", regs->reg_eax);
+
+    cprintf("  esi  0x%08x\n", regs->reg_esi);
+    cprintf("  ebp  0x%08x\n", regs->reg_ebp);
+    cprintf("  oesp 0x%08x\n", regs->reg_oesp);
+    cprintf("  ebx  0x%08x\n", regs->reg_ebx);
+    cprintf("  edx  0x%08x\n", regs->reg_edx);
+    cprintf("  ecx  0x%08x\n", regs->reg_ecx);
+    cprintf("  eax  0x%08x\n", regs->reg_eax);
 }
 
-static void
+    static void
 trap_dispatch(struct Trapframe *tf)
 {
-	// Handle processor exceptions.
-	// LAB 3: Your code here.
-
-	// Handle spurious interrupts
-	// The hardware sometimes raises these because of noise on the
-	// IRQ line or other reasons. We don't care.
-	if (tf->tf_trapno == IRQ_OFFSET + IRQ_SPURIOUS) {
+    // Handle processor exceptions.
+    // LAB 3: Your code here.
+    switch (tf->tf_trapno) 
+    {
+	case T_DEBUG:
+	case T_BRKPT:
+	    monitor(tf);
+	    return;
+	case T_PGFLT:
+	    page_fault_handler(tf);
+	    return;
+	case T_SYSCALL:
+	    tf->tf_regs.reg_eax = syscall(tf->tf_regs.reg_eax, tf->tf_regs.reg_edx, tf->tf_regs.reg_ecx, 
+	    	tf->tf_regs.reg_ebx, tf->tf_regs.reg_edi, tf->tf_regs.reg_esi);
+	    return;
+    }
+
+    // Handle spurious interrupts
+    // The hardware sometimes raises these because of noise on the
+    // IRQ line or other reasons. We don't care.
+    if (tf->tf_trapno == IRQ_OFFSET + IRQ_SPURIOUS) 
+    {
 		cprintf("Spurious interrupt on irq 7\n");
 		print_trapframe(tf);
 		return;
-	}
-
-	// Handle clock interrupts. Don't forget to acknowledge the
-	// interrupt using lapic_eoi() before calling the scheduler!
-	// LAB 4: Your code here.
+    }
+
+    // Handle clock interrupts. Don't forget to acknowledge the
+    // interrupt using lapic_eoi() before calling the scheduler!
+    // LAB 4: Your code here.
+    if (tf->tf_trapno == IRQ_OFFSET + IRQ_TIMER) 
+    {
+		lapic_eoi();
+		sched_yield();
+		return;
+    }
 
-	// Handle keyboard and serial interrupts.
-	// LAB 5: Your code here.
+    // Handle keyboard and serial interrupts.
+    // LAB 5: Your code here.
+    if (tf->tf_trapno == IRQ_OFFSET+IRQ_KBD) 
+    {
+		kbd_intr();
+		return;
+    }
 
-	// Unexpected trap: The user process or the kernel has a bug.
-	print_trapframe(tf);
-	if (tf->tf_cs == GD_KT)
+    if (tf->tf_trapno == IRQ_OFFSET+IRQ_SERIAL) 
+    {
+		serial_intr();
+		return;
+    }
+    // Unexpected trap: The user process or the kernel has a bug.
+    print_trapframe(tf);
+    if (tf->tf_cs == GD_KT)
 		panic("unhandled trap in kernel");
-	else {
+    else 
+    {
 		env_destroy(curenv);
 		return;
-	}
+    }
 }
-
-void
+    void
 trap(struct Trapframe *tf)
 {
-	// The environment may have set DF and some versions
-	// of GCC rely on DF being clear
-	asm volatile("cld" ::: "cc");
+    // The environment may have set DF and some versions
+    // of GCC rely on DF being clear
+    asm volatile("cld" ::: "cc");
 
-	// Halt the CPU if some other CPU has called panic()
-	extern char *panicstr;
-	if (panicstr)
+    // Halt the CPU if some other CPU has called panic()
+    extern char *panicstr;
+    if (panicstr)
 		asm volatile("hlt");
 
-	// Re-acqurie the big kernel lock if we were halted in
-	// sched_yield()
-	if (xchg(&thiscpu->cpu_status, CPU_STARTED) == CPU_HALTED)
+    // Re-acqurie the big kernel lock if we were halted in
+    // sched_yield()
+    if (xchg(&thiscpu->cpu_status, CPU_STARTED) == CPU_HALTED)
 		lock_kernel();
-	// Check that interrupts are disabled.  If this assertion
-	// fails, DO NOT be tempted to fix it by inserting a "cli" in
-	// the interrupt path.
-	assert(!(read_eflags() & FL_IF));
-
-	if ((tf->tf_cs & 3) == 3) {
-		// Trapped from user mode.
-		// Acquire the big kernel lock before doing any
-		// serious kernel work.
-		// LAB 4: Your code here.
+    // Check that interrupts are disabled.  If this assertion
+    // fails, DO NOT be tempted to fix it by inserting a "cli" in
+    // the interrupt path.
+    assert(!(read_eflags() & FL_IF));
+
+    if ((tf->tf_cs & 3) == 3) {
+	// Trapped from user mode.
+	// Acquire the big kernel lock before doing any
+	// serious kernel work.
+	// LAB 4: Your code here.
 		assert(curenv);
+		lock_kernel();
+
 
-		// Garbage collect if current enviroment is a zombie
+	// Garbage collect if current enviroment is a zombie
 		if (curenv->env_status == ENV_DYING) {
-			env_free(curenv);
-			curenv = NULL;
-			sched_yield();
+	    	env_free(curenv);
+	    	curenv = NULL;
+	    	sched_yield();
 		}
 
-		// Copy trap frame (which is currently on the stack)
-		// into 'curenv->env_tf', so that running the environment
-		// will restart at the trap point.
+	// Copy trap frame (which is currently on the stack)
+	// into 'curenv->env_tf', so that running the environment
+	// will restart at the trap point.
 		curenv->env_tf = *tf;
-		// The trapframe on the stack should be ignored from here on.
+	// The trapframe on the stack should be ignored from here on.
 		tf = &curenv->env_tf;
-	}
+    }
 
-	// Record that tf is the last real trapframe so
-	// print_trapframe can print some additional information.
-	last_tf = tf;
+    // Record that tf is the last real trapframe so
+    // print_trapframe can print some additional information.
+    last_tf = tf;
 
-	// Dispatch based on what type of trap occurred
-	trap_dispatch(tf);
+    // Dispatch based on what type of trap occurred
+    trap_dispatch(tf);
 
-	// If we made it to this point, then no other environment was
-	// scheduled, so we should return to the current environment
-	// if doing so makes sense.
-	if (curenv && curenv->env_status == ENV_RUNNING)
+    // If we made it to this point, then no other environment was
+    // scheduled, so we should return to the current environment
+    // if doing so makes sense.
+    if (curenv && curenv->env_status == ENV_RUNNING)
 		env_run(curenv);
-	else
+    else
 		sched_yield();
 }
 
 
-void
+    void
 page_fault_handler(struct Trapframe *tf)
 {
-	uint32_t fault_va;
-
-	// Read processor's CR2 register to find the faulting address
-	fault_va = rcr2();
-
-	// Handle kernel-mode page faults.
-
-	// LAB 3: Your code here.
-
-	// We've already handled kernel-mode exceptions, so if we get here,
-	// the page fault happened in user mode.
-
-	// Call the environment's page fault upcall, if one exists.  Set up a
-	// page fault stack frame on the user exception stack (below
-	// UXSTACKTOP), then branch to curenv->env_pgfault_upcall.
-	//
-	// The page fault upcall might cause another page fault, in which case
-	// we branch to the page fault upcall recursively, pushing another
-	// page fault stack frame on top of the user exception stack.
-	//
-	// It is convenient for our code which returns from a page fault
-	// (lib/pfentry.S) to have one word of scratch space at the top of the
-	// trap-time stack; it allows us to more easily restore the eip/esp. In
-	// the non-recursive case, we don't have to worry about this because
-	// the top of the regular user stack is free.  In the recursive case,
-	// this means we have to leave an extra word between the current top of
-	// the exception stack and the new stack frame because the exception
-	// stack _is_ the trap-time stack.
-	//
-	// If there's no page fault upcall, the environment didn't allocate a
-	// page for its exception stack or can't write to it, or the exception
-	// stack overflows, then destroy the environment that caused the fault.
-	// Note that the grade script assumes you will first check for the page
-	// fault upcall and print the "user fault va" message below if there is
-	// none.  The remaining three checks can be combined into a single test.
-	//
-	// Hints:
-	//   user_mem_assert() and env_run() are useful here.
-	//   To change what the user environment runs, modify 'curenv->env_tf'
-	//   (the 'tf' variable points at 'curenv->env_tf').
-
-	// LAB 4: Your code here.
+    uint32_t fault_va;
+
+    // Read processor's CR2 register to find the faulting address
+    fault_va = rcr2();
+
+    // Handle kernel-mode page faults.
+
+    // LAB 3: Your code here.
+    if (!(tf->tf_cs & 3))
+		panic("a page fault happens in kernel mode\n");
+
+    // We've already handled kernel-mode exceptions, so if we get here,
+    // the page fault happened in user mode.
+
+    // Call the environment's page fault upcall, if one exists.  Set up a
+    // page fault stack frame on the user exception stack (below
+    // UXSTACKTOP), then branch to curenv->env_pgfault_upcall.
+    //
+    // The page fault upcall might cause another page fault, in which case
+    // we branch to the page fault upcall recursively, pushing another
+    // page fault stack frame on top of the user exception stack.
+    //
+    // The trap handler needs one word of scratch space at the top of the
+    // trap-time stack in order to return.  In the non-recursive case, we
+    // don't have to worry about this because the top of the regular user
+    // stack is free.  In the recursive case, this means we have to leave
+    // an extra word between the current top of the exception stack and
+    // the new stack frame because the exception stack _is_ the trap-time
+    // stack.
+    //
+    // If there's no page fault upcall, the environment didn't allocate a
+    // page for its exception stack or can't write to it, or the exception
+    // stack overflows, then destroy the environment that caused the fault.
+    // Note that the grade script assumes you will first check for the page
+    // fault upcall and print the "user fault va" message below if there is
+    // none.  The remaining three checks can be combined into a single test.
+    //
+    // Hints:
+    //   user_mem_assert() and env_run() are useful here.
+    //   To change what the user environment runs, modify 'curenv->env_tf'
+    //   (the 'tf' variable points at 'curenv->env_tf').
+
+    // LAB 4: Your code here.
+    struct UTrapframe *utf;
+    uint32_t esp = tf->tf_esp;
+
+    if (curenv->env_pgfault_upcall) 
+    {
+		if (esp < UXSTACKTOP - PGSIZE || esp >= UXSTACKTOP) 
+			tf->tf_esp = UXSTACKTOP+4; 
+		utf = (struct UTrapframe*)(tf->tf_esp - 4 - sizeof(struct UTrapframe));
+		user_mem_assert(curenv, (const void*)utf, 1, PTE_W|PTE_U);
+		lcr3(PADDR(curenv->env_pgdir));
+		utf->utf_fault_va = fault_va;
+		utf->utf_err = tf->tf_err;
+		utf->utf_regs = tf->tf_regs;
+		utf->utf_eip = tf->tf_eip;
+		utf->utf_eflags = tf->tf_eflags;
+		utf->utf_esp = esp;
+		tf->tf_esp = (uint32_t)utf;
+		tf->tf_eip = (uint32_t)curenv->env_pgfault_upcall;
+		env_run(curenv);
+    }
 
-	// Destroy the environment that caused the fault.
-	cprintf("[%08x] user fault va %08x ip %08x\n",
-		curenv->env_id, fault_va, tf->tf_eip);
-	print_trapframe(tf);
-	env_destroy(curenv);
+    // Destroy the environment that caused the fault.
+    cprintf("[%08x] user fault va %08x ip %08x\n",
+	    curenv->env_id, fault_va, tf->tf_eip);
+    print_trapframe(tf);
+    env_destroy(curenv);
 }
 
diff --git a/kern/trap.h b/kern/trap.h
old mode 100644
new mode 100755
diff --git a/kern/trapentry.S b/kern/trapentry.S
old mode 100644
new mode 100755
index 2dbeeca..993381f
--- a/kern/trapentry.S
+++ b/kern/trapentry.S
@@ -4,9 +4,15 @@
 #include <inc/memlayout.h>
 #include <inc/trap.h>
 
-#include <kern/picirq.h>
-
 
+#define IDTENTRY(name,num,dpl,istrap)           \
+    .data;                      \
+    .align 2;                   \
+    .long name;                 \
+    .long num;                  \
+    .long dpl;                  \
+    .long istrap;                   
+    
 ###################################################################
 # exceptions/interrupts
 ###################################################################
@@ -21,36 +27,92 @@
  *   void NAME();
  * where NAME is the argument passed to TRAPHANDLER.
  */
-#define TRAPHANDLER(name, num)						\
-	.globl name;		/* define global symbol for 'name' */	\
-	.type name, @function;	/* symbol type is function */		\
-	.align 2;		/* align function definition */		\
-	name:			/* function starts here */		\
-	pushl $(num);							\
-	jmp _alltraps
+#define TRAPHANDLER(name, num, dpl, istrap)                     \
+    .text;                              \
+    .globl name;        /* define global symbol for 'name' */   \
+    .type name, @function;  /* symbol type is function */       \
+    .align 2;       /* align function definition */     \
+    name:           /* function starts here */      \
+    pushl $(num);                           \
+    jmp _alltraps;                          \
+    IDTENTRY(name,num,dpl,istrap)
 
 /* Use TRAPHANDLER_NOEC for traps where the CPU doesn't push an error code.
  * It pushes a 0 in place of the error code, so the trap frame has the same
  * format in either case.
  */
-#define TRAPHANDLER_NOEC(name, num)					\
-	.globl name;							\
-	.type name, @function;						\
-	.align 2;							\
-	name:								\
-	pushl $0;							\
-	pushl $(num);							\
-	jmp _alltraps
-
+#define TRAPHANDLER_NOEC(name, num, dpl, istrap)                \
+    .text;                              \
+    .globl name;                            \
+    .type name, @function;                      \
+    .align 2;                           \
+    name:                               \
+    pushl $0;                           \
+    pushl $(num);                           \
+    jmp _alltraps;                          \
+    IDTENTRY(name,num,dpl,istrap)
 .text
 
 /*
  * Lab 3: Your code here for generating entry points for the different traps.
  */
-
+.data
+.align 2
+.globl idt_entry
+idt_entry:
+    TRAPHANDLER_NOEC(r_divide, T_DIVIDE, 0, 0 )
+    TRAPHANDLER_NOEC(r_debug, T_DEBUG, 0, 0 ) 
+    TRAPHANDLER_NOEC(r_nmi, T_NMI, 0, 0 )
+    TRAPHANDLER_NOEC(r_brkpt, T_BRKPT, 3, 0 )
+    TRAPHANDLER_NOEC(r_oflow, T_OFLOW, 0, 0 )
+    TRAPHANDLER_NOEC(r_bound, T_BOUND, 0, 0 )
+    TRAPHANDLER_NOEC(r_illop, T_ILLOP, 0, 0 )
+    TRAPHANDLER_NOEC(r_device, T_DEVICE, 0, 0 )
+    TRAPHANDLER(r_dblflt, T_DBLFLT, 0, 0 )
+.fill 2,8,0
+    TRAPHANDLER(r_tss, T_TSS, 0, 0 )
+    TRAPHANDLER(r_segnp, T_SEGNP, 0, 0 )
+    TRAPHANDLER(r_stack, T_STACK, 0, 0 )
+    TRAPHANDLER(r_gpflt, T_GPFLT, 0, 0 )
+    TRAPHANDLER(r_pgflt, T_PGFLT, 0, 0 )
+.fill 2,8,0
+    TRAPHANDLER_NOEC(r_fperr, T_FPERR, 0, 0 )
+    TRAPHANDLER(r_align, T_ALIGN, 0, 0 )
+    TRAPHANDLER_NOEC(r_mchk, T_MCHK, 0, 0 )
+    TRAPHANDLER_NOEC(r_simderr, T_SIMDERR, 0, 0 )
+.fill 24,8,0
+    TRAPHANDLER_NOEC(r_irq0, IRQ_OFFSET + 0, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq1, IRQ_OFFSET + 1, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq2, IRQ_OFFSET + 2, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq3, IRQ_OFFSET + 3, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq4, IRQ_OFFSET + 4, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq5, IRQ_OFFSET + 5, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq6, IRQ_OFFSET + 6, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq7, IRQ_OFFSET + 7, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq8, IRQ_OFFSET + 8, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq9, IRQ_OFFSET + 9, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq10, IRQ_OFFSET + 10, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq11, IRQ_OFFSET + 11, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq12, IRQ_OFFSET + 12, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq13, IRQ_OFFSET + 13, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq14, IRQ_OFFSET + 14, 0, 0 )
+    TRAPHANDLER_NOEC(r_irq15, IRQ_OFFSET + 15, 0, 0 )
+    TRAPHANDLER_NOEC(r_syscall, T_SYSCALL, 3, 0 )
 
 
 /*
  * Lab 3: Your code here for _alltraps
  */
+_alltraps:
+    pushw $0x0
+    pushw %ds
+    pushw $0x0
+    pushw %es
+    pushal
+    
+    movw $GD_KD, %ax
+    movw %ax, %ds
+    movw %ax, %es
+    pushl %esp  
+    call trap
 
diff --git a/lib.old/Makefrag b/lib.old/Makefrag
new file mode 100755
index 0000000..514e4a7
--- /dev/null
+++ b/lib.old/Makefrag
@@ -0,0 +1,46 @@
+OBJDIRS += lib
+
+LIB_SRCFILES :=		lib/console.c \
+			lib/libmain.c \
+			lib/exit.c \
+			lib/panic.c \
+			lib/printf.c \
+			lib/printfmt.c \
+			lib/readline.c \
+			lib/string.c \
+			lib/syscall.c
+
+LIB_SRCFILES :=		$(LIB_SRCFILES) \
+			lib/pgfault.c \
+			lib/pfentry.S \
+			lib/fork.c \
+			lib/ipc.c
+
+LIB_SRCFILES :=		$(LIB_SRCFILES) \
+			lib/args.c \
+			lib/fd.c \
+			lib/file.c \
+			lib/fprintf.c \
+			lib/pageref.c \
+			lib/spawn.c
+
+LIB_SRCFILES :=		$(LIB_SRCFILES) \
+			lib/pipe.c \
+			lib/wait.c
+
+LIB_OBJFILES := $(patsubst lib/%.c, $(OBJDIR)/lib/%.o, $(LIB_SRCFILES))
+LIB_OBJFILES := $(patsubst lib/%.S, $(OBJDIR)/lib/%.o, $(LIB_OBJFILES))
+
+$(OBJDIR)/lib/%.o: lib/%.c $(OBJDIR)/.vars.USER_CFLAGS
+	@echo + cc[USER] $<
+	@mkdir -p $(@D)
+	$(V)$(CC) -nostdinc $(USER_CFLAGS) -c -o $@ $<
+
+$(OBJDIR)/lib/%.o: lib/%.S $(OBJDIR)/.vars.USER_CFLAGS
+	@echo + as[USER] $<
+	@mkdir -p $(@D)
+	$(V)$(CC) -nostdinc $(USER_CFLAGS) -c -o $@ $<
+
+$(OBJDIR)/lib/libjos.a: $(LIB_OBJFILES)
+	@echo + ar $@
+	$(V)$(AR) r $@ $(LIB_OBJFILES)
diff --git a/lib.old/args.c b/lib.old/args.c
new file mode 100644
index 0000000..9269aca
--- /dev/null
+++ b/lib.old/args.c
@@ -0,0 +1,73 @@
+#include <inc/args.h>
+#include <inc/string.h>
+
+void
+argstart(int *argc, char **argv, struct Argstate *args)
+{
+	args->argc = argc;
+	args->argv = (const char **) argv;
+	args->curarg = (*argc > 1 && argv ? "" : 0);
+	args->argvalue = 0;
+}
+
+int
+argnext(struct Argstate *args)
+{
+	int arg;
+
+	args->argvalue = 0;
+
+	// Done processing arguments if args->curarg == 0
+	if (args->curarg == 0)
+		return -1;
+
+	if (!*args->curarg) {
+		// Need to process the next argument
+		// Check for end of argument list
+		if (*args->argc == 1
+		    || args->argv[1][0] != '-'
+		    || args->argv[1][1] == '\0')
+			goto endofargs;
+		// Shift arguments down one
+		args->curarg = args->argv[1] + 1;
+		memmove(args->argv + 1, args->argv + 2, sizeof(const char *) * (*args->argc - 1));
+		(*args->argc)--;
+		// Check for "--": end of argument list
+		if (args->curarg[0] == '-' && args->curarg[1] == '\0')
+			goto endofargs;
+	}
+
+	arg = (unsigned char) *args->curarg;
+	args->curarg++;
+	return arg;
+
+    endofargs:
+	args->curarg = 0;
+	return -1;
+}
+
+char *
+argvalue(struct Argstate *args)
+{
+	return (char*) (args->argvalue ? args->argvalue : argnextvalue(args));
+}
+
+char *
+argnextvalue(struct Argstate *args)
+{
+	if (!args->curarg)
+		return 0;
+	if (*args->curarg) {
+		args->argvalue = args->curarg;
+		args->curarg = "";
+	} else if (*args->argc > 1) {
+		args->argvalue = args->argv[1];
+		memmove(args->argv + 1, args->argv + 2, sizeof(const char *) * (*args->argc - 1));
+		(*args->argc)--;
+	} else {
+		args->argvalue = 0;
+		args->curarg = 0;
+	}
+	return (char*) args->argvalue;
+}
+
diff --git a/lib.old/console.c b/lib.old/console.c
new file mode 100755
index 0000000..fe35ff7
--- /dev/null
+++ b/lib.old/console.c
@@ -0,0 +1,128 @@
+
+#include <inc/string.h>
+#include <inc/lib.h>
+
+void
+cputchar(int ch)
+{
+	char c = ch;
+
+	// Unlike standard Unix's putchar,
+	// the cputchar function _always_ outputs to the system console.
+	sys_cputs(&c, 1);
+}
+
+int
+getchar(void)
+{
+	unsigned char c;
+	int r;
+
+	// JOS does, however, support standard _input_ redirection,
+	// allowing the user to redirect script files to the shell and such.
+	// getchar() reads a character from file descriptor 0.
+	r = read(0, &c, 1);
+	if (r < 0)
+		return r;
+	if (r < 1)
+		return -E_EOF;
+	return c;
+}
+
+
+// "Real" console file descriptor implementation.
+// The putchar/getchar functions above will still come here by default,
+// but now can be redirected to files, pipes, etc., via the fd layer.
+
+static ssize_t devcons_read(struct Fd*, void*, size_t);
+static ssize_t devcons_write(struct Fd*, const void*, size_t);
+static int devcons_close(struct Fd*);
+static int devcons_stat(struct Fd*, struct Stat*);
+
+struct Dev devcons =
+{
+	.dev_id =	'c',
+	.dev_name =	"cons",
+	.dev_read =	devcons_read,
+	.dev_write =	devcons_write,
+	.dev_close =	devcons_close,
+	.dev_stat =	devcons_stat
+};
+
+int
+iscons(int fdnum)
+{
+	int r;
+	struct Fd *fd;
+
+	if ((r = fd_lookup(fdnum, &fd)) < 0)
+		return r;
+	return fd->fd_dev_id == devcons.dev_id;
+}
+
+int
+opencons(void)
+{
+	int r;
+	struct Fd* fd;
+
+	if ((r = fd_alloc(&fd)) < 0)
+		return r;
+	if ((r = sys_page_alloc(0, fd, PTE_P|PTE_U|PTE_W|PTE_SHARE)) < 0)
+		return r;
+	fd->fd_dev_id = devcons.dev_id;
+	fd->fd_omode = O_RDWR;
+	return fd2num(fd);
+}
+
+static ssize_t
+devcons_read(struct Fd *fd, void *vbuf, size_t n)
+{
+	int c;
+
+	if (n == 0)
+		return 0;
+
+	while ((c = sys_cgetc()) == 0)
+		sys_yield();
+	if (c < 0)
+		return c;
+	if (c == 0x04)	// ctl-d is eof
+		return 0;
+	*(char*)vbuf = c;
+	return 1;
+}
+
+static ssize_t
+devcons_write(struct Fd *fd, const void *vbuf, size_t n)
+{
+	int tot, m;
+	char buf[128];
+
+	// mistake: have to nul-terminate arg to sys_cputs,
+	// so we have to copy vbuf into buf in chunks and nul-terminate.
+	for (tot = 0; tot < n; tot += m) {
+		m = n - tot;
+		if (m > sizeof(buf) - 1)
+			m = sizeof(buf) - 1;
+		memmove(buf, (char*)vbuf + tot, m);
+		sys_cputs(buf, m);
+	}
+	return tot;
+}
+
+static int
+devcons_close(struct Fd *fd)
+{
+	USED(fd);
+
+	return 0;
+}
+
+static int
+devcons_stat(struct Fd *fd, struct Stat *stat)
+{
+	strcpy(stat->st_name, "<cons>");
+	return 0;
+}
+
diff --git a/lib.old/entry.S b/lib.old/entry.S
new file mode 100755
index 0000000..222d16c
--- /dev/null
+++ b/lib.old/entry.S
@@ -0,0 +1,35 @@
+#include <inc/mmu.h>
+#include <inc/memlayout.h>
+
+.data
+// Define the global symbols 'envs', 'pages', 'uvpt', and 'uvpd'
+// so that they can be used in C as if they were ordinary global arrays.
+	.globl envs
+	.set envs, UENVS
+	.globl pages
+	.set pages, UPAGES
+	.globl uvpt
+	.set uvpt, UVPT
+	.globl uvpd
+	.set uvpd, (UVPT+(UVPT>>12)*4)
+
+
+// Entrypoint - this is where the kernel (or our parent environment)
+// starts us running when we are initially loaded into a new environment.
+.text
+.globl _start
+_start:
+	// See if we were started with arguments on the stack
+	cmpl $USTACKTOP, %esp
+	jne args_exist
+
+	// If not, push dummy argc/argv arguments.
+	// This happens when we are loaded by the kernel,
+	// because the kernel does not know about passing arguments.
+	pushl $0
+	pushl $0
+
+args_exist:
+	call libmain
+1:	jmp 1b
+
diff --git a/lib.old/exit.c b/lib.old/exit.c
new file mode 100755
index 0000000..cee3336
--- /dev/null
+++ b/lib.old/exit.c
@@ -0,0 +1,10 @@
+
+#include <inc/lib.h>
+
+void
+exit(void)
+{
+	close_all();
+	sys_env_destroy(0);
+}
+
diff --git a/lib.old/fd.c b/lib.old/fd.c
new file mode 100644
index 0000000..52a15ed
--- /dev/null
+++ b/lib.old/fd.c
@@ -0,0 +1,320 @@
+#include <inc/lib.h>
+
+#define debug		0
+
+// Maximum number of file descriptors a program may hold open concurrently
+#define MAXFD		32
+// Bottom of file descriptor area
+#define FDTABLE		0xD0000000
+// Bottom of file data area.  We reserve one data page for each FD,
+// which devices can use if they choose.
+#define FILEDATA	(FDTABLE + MAXFD*PGSIZE)
+
+// Return the 'struct Fd*' for file descriptor index i
+#define INDEX2FD(i)	((struct Fd*) (FDTABLE + (i)*PGSIZE))
+// Return the file data page for file descriptor index i
+#define INDEX2DATA(i)	((char*) (FILEDATA + (i)*PGSIZE))
+
+
+// --------------------------------------------------------------
+// File descriptor manipulators
+// --------------------------------------------------------------
+
+int
+fd2num(struct Fd *fd)
+{
+	return ((uintptr_t) fd - FDTABLE) / PGSIZE;
+}
+
+char*
+fd2data(struct Fd *fd)
+{
+	return INDEX2DATA(fd2num(fd));
+}
+
+// Finds the smallest i from 0 to MAXFD-1 that doesn't have
+// its fd page mapped.
+// Sets *fd_store to the corresponding fd page virtual address.
+//
+// fd_alloc does NOT actually allocate an fd page.
+// It is up to the caller to allocate the page somehow.
+// This means that if someone calls fd_alloc twice in a row
+// without allocating the first page we return, we'll return the same
+// page the second time.
+//
+// Hint: Use INDEX2FD.
+//
+// Returns 0 on success, < 0 on error.  Errors are:
+//	-E_MAX_FD: no more file descriptors
+// On error, *fd_store is set to 0.
+int
+fd_alloc(struct Fd **fd_store)
+{
+	int i;
+	struct Fd *fd;
+
+	for (i = 0; i < MAXFD; i++) {
+		fd = INDEX2FD(i);
+		if ((uvpd[PDX(fd)] & PTE_P) == 0 || (uvpt[PGNUM(fd)] & PTE_P) == 0) {
+			*fd_store = fd;
+			return 0;
+		}
+	}
+	*fd_store = 0;
+	return -E_MAX_OPEN;
+}
+
+// Check that fdnum is in range and mapped.
+// If it is, set *fd_store to the fd page virtual address.
+//
+// Returns 0 on success (the page is in range and mapped), < 0 on error.
+// Errors are:
+//	-E_INVAL: fdnum was either not in range or not mapped.
+int
+fd_lookup(int fdnum, struct Fd **fd_store)
+{
+	struct Fd *fd;
+
+	if (fdnum < 0 || fdnum >= MAXFD) {
+		if (debug)
+			cprintf("[%08x] bad fd %d\n", thisenv->env_id, fdnum);
+		return -E_INVAL;
+	}
+	fd = INDEX2FD(fdnum);
+	if (!(uvpd[PDX(fd)] & PTE_P) || !(uvpt[PGNUM(fd)] & PTE_P)) {
+		if (debug)
+			cprintf("[%08x] closed fd %d\n", thisenv->env_id, fdnum);
+		return -E_INVAL;
+	}
+	*fd_store = fd;
+	return 0;
+}
+
+// Frees file descriptor 'fd' by closing the corresponding file
+// and unmapping the file descriptor page.
+// If 'must_exist' is 0, then fd can be a closed or nonexistent file
+// descriptor; the function will return 0 and have no other effect.
+// If 'must_exist' is 1, then fd_close returns -E_INVAL when passed a
+// closed or nonexistent file descriptor.
+// Returns 0 on success, < 0 on error.
+int
+fd_close(struct Fd *fd, bool must_exist)
+{
+	struct Fd *fd2;
+	struct Dev *dev;
+	int r;
+	if ((r = fd_lookup(fd2num(fd), &fd2)) < 0
+	    || fd != fd2)
+		return (must_exist ? r : 0);
+	if ((r = dev_lookup(fd->fd_dev_id, &dev)) >= 0) {
+		if (dev->dev_close)
+			r = (*dev->dev_close)(fd);
+		else
+			r = 0;
+	}
+	// Make sure fd is unmapped.  Might be a no-op if
+	// (*dev->dev_close)(fd) already unmapped it.
+	(void) sys_page_unmap(0, fd);
+	return r;
+}
+
+
+// --------------------------------------------------------------
+// File functions
+// --------------------------------------------------------------
+
+static struct Dev *devtab[] =
+{
+	&devfile,
+	&devpipe,
+	&devcons,
+	0
+};
+
+int
+dev_lookup(int dev_id, struct Dev **dev)
+{
+	int i;
+	for (i = 0; devtab[i]; i++)
+		if (devtab[i]->dev_id == dev_id) {
+			*dev = devtab[i];
+			return 0;
+		}
+	cprintf("[%08x] unknown device type %d\n", thisenv->env_id, dev_id);
+	*dev = 0;
+	return -E_INVAL;
+}
+
+int
+close(int fdnum)
+{
+	struct Fd *fd;
+	int r;
+
+	if ((r = fd_lookup(fdnum, &fd)) < 0)
+		return r;
+	else
+		return fd_close(fd, 1);
+}
+
+void
+close_all(void)
+{
+	int i;
+	for (i = 0; i < MAXFD; i++)
+		close(i);
+}
+
+// Make file descriptor 'newfdnum' a duplicate of file descriptor 'oldfdnum'.
+// For instance, writing onto either file descriptor will affect the
+// file and the file offset of the other.
+// Closes any previously open file descriptor at 'newfdnum'.
+// This is implemented using virtual memory tricks (of course!).
+int
+dup(int oldfdnum, int newfdnum)
+{
+	int r;
+	char *ova, *nva;
+	pte_t pte;
+	struct Fd *oldfd, *newfd;
+
+	if ((r = fd_lookup(oldfdnum, &oldfd)) < 0)
+		return r;
+	close(newfdnum);
+
+	newfd = INDEX2FD(newfdnum);
+	ova = fd2data(oldfd);
+	nva = fd2data(newfd);
+
+	if ((uvpd[PDX(ova)] & PTE_P) && (uvpt[PGNUM(ova)] & PTE_P))
+		if ((r = sys_page_map(0, ova, 0, nva, uvpt[PGNUM(ova)] & PTE_SYSCALL)) < 0)
+			goto err;
+	if ((r = sys_page_map(0, oldfd, 0, newfd, uvpt[PGNUM(oldfd)] & PTE_SYSCALL)) < 0)
+		goto err;
+
+	return newfdnum;
+
+err:
+	sys_page_unmap(0, newfd);
+	sys_page_unmap(0, nva);
+	return r;
+}
+
+ssize_t
+read(int fdnum, void *buf, size_t n)
+{
+	int r;
+	struct Dev *dev;
+	struct Fd *fd;
+
+	if ((r = fd_lookup(fdnum, &fd)) < 0
+	    || (r = dev_lookup(fd->fd_dev_id, &dev)) < 0)
+		return r;
+	if ((fd->fd_omode & O_ACCMODE) == O_WRONLY) {
+		cprintf("[%08x] read %d -- bad mode\n", thisenv->env_id, fdnum);
+		return -E_INVAL;
+	}
+	if (!dev->dev_read)
+		return -E_NOT_SUPP;
+	return (*dev->dev_read)(fd, buf, n);
+}
+
+ssize_t
+readn(int fdnum, void *buf, size_t n)
+{
+	int m, tot;
+
+	for (tot = 0; tot < n; tot += m) {
+		m = read(fdnum, (char*)buf + tot, n - tot);
+		if (m < 0)
+			return m;
+		if (m == 0)
+			break;
+	}
+	return tot;
+}
+
+ssize_t
+write(int fdnum, const void *buf, size_t n)
+{
+	int r;
+	struct Dev *dev;
+	struct Fd *fd;
+
+	if ((r = fd_lookup(fdnum, &fd)) < 0
+	    || (r = dev_lookup(fd->fd_dev_id, &dev)) < 0)
+		return r;
+	if ((fd->fd_omode & O_ACCMODE) == O_RDONLY) {
+		cprintf("[%08x] write %d -- bad mode\n", thisenv->env_id, fdnum);
+		return -E_INVAL;
+	}
+	if (debug)
+		cprintf("write %d %p %d via dev %s\n",
+			fdnum, buf, n, dev->dev_name);
+	if (!dev->dev_write)
+		return -E_NOT_SUPP;
+	return (*dev->dev_write)(fd, buf, n);
+}
+
+int
+seek(int fdnum, off_t offset)
+{
+	int r;
+	struct Fd *fd;
+
+	if ((r = fd_lookup(fdnum, &fd)) < 0)
+		return r;
+	fd->fd_offset = offset;
+	return 0;
+}
+
+int
+ftruncate(int fdnum, off_t newsize)
+{
+	int r;
+	struct Dev *dev;
+	struct Fd *fd;
+	if ((r = fd_lookup(fdnum, &fd)) < 0
+	    || (r = dev_lookup(fd->fd_dev_id, &dev)) < 0)
+		return r;
+	if ((fd->fd_omode & O_ACCMODE) == O_RDONLY) {
+		cprintf("[%08x] ftruncate %d -- bad mode\n",
+			thisenv->env_id, fdnum);
+		return -E_INVAL;
+	}
+	if (!dev->dev_trunc)
+		return -E_NOT_SUPP;
+	return (*dev->dev_trunc)(fd, newsize);
+}
+
+int
+fstat(int fdnum, struct Stat *stat)
+{
+	int r;
+	struct Dev *dev;
+	struct Fd *fd;
+
+	if ((r = fd_lookup(fdnum, &fd)) < 0
+	    || (r = dev_lookup(fd->fd_dev_id, &dev)) < 0)
+		return r;
+	if (!dev->dev_stat)
+		return -E_NOT_SUPP;
+	stat->st_name[0] = 0;
+	stat->st_size = 0;
+	stat->st_isdir = 0;
+	stat->st_dev = dev;
+	return (*dev->dev_stat)(fd, stat);
+}
+
+int
+stat(const char *path, struct Stat *stat)
+{
+	int fd, r;
+
+	if ((fd = open(path, O_RDONLY)) < 0)
+		return fd;
+	r = fstat(fd, stat);
+	close(fd);
+	return r;
+}
+
diff --git a/lib.old/file.c b/lib.old/file.c
new file mode 100644
index 0000000..39025b2
--- /dev/null
+++ b/lib.old/file.c
@@ -0,0 +1,180 @@
+#include <inc/fs.h>
+#include <inc/string.h>
+#include <inc/lib.h>
+
+#define debug 0
+
+union Fsipc fsipcbuf __attribute__((aligned(PGSIZE)));
+
+// Send an inter-environment request to the file server, and wait for
+// a reply.  The request body should be in fsipcbuf, and parts of the
+// response may be written back to fsipcbuf.
+// type: request code, passed as the simple integer IPC value.
+// dstva: virtual address at which to receive reply page, 0 if none.
+// Returns result from the file server.
+static int
+fsipc(unsigned type, void *dstva)
+{
+	static envid_t fsenv;
+	if (fsenv == 0)
+		fsenv = ipc_find_env(ENV_TYPE_FS);
+
+	static_assert(sizeof(fsipcbuf) == PGSIZE);
+
+	if (debug)
+		cprintf("[%08x] fsipc %d %08x\n", thisenv->env_id, type, *(uint32_t *)&fsipcbuf);
+
+	ipc_send(fsenv, type, &fsipcbuf, PTE_P | PTE_W | PTE_U);
+	return ipc_recv(NULL, dstva, NULL);
+}
+
+static int devfile_flush(struct Fd *fd);
+static ssize_t devfile_read(struct Fd *fd, void *buf, size_t n);
+static ssize_t devfile_write(struct Fd *fd, const void *buf, size_t n);
+static int devfile_stat(struct Fd *fd, struct Stat *stat);
+static int devfile_trunc(struct Fd *fd, off_t newsize);
+
+struct Dev devfile =
+{
+	.dev_id =	'f',
+	.dev_name =	"file",
+	.dev_read =	devfile_read,
+	.dev_close =	devfile_flush,
+	.dev_stat =	devfile_stat,
+	.dev_write =	devfile_write,
+	.dev_trunc =	devfile_trunc
+};
+
+// Open a file (or directory).
+//
+// Returns:
+// 	The file descriptor index on success
+// 	-E_BAD_PATH if the path is too long (>= MAXPATHLEN)
+// 	< 0 for other errors.
+int
+open(const char *path, int mode)
+{
+	// Find an unused file descriptor page using fd_alloc.
+	// Then send a file-open request to the file server.
+	// Include 'path' and 'omode' in request,
+	// and map the returned file descriptor page
+	// at the appropriate fd address.
+	// FSREQ_OPEN returns 0 on success, < 0 on failure.
+	//
+	// (fd_alloc does not allocate a page, it just returns an
+	// unused fd address.  Do you need to allocate a page?)
+	//
+	// Return the file descriptor index.
+	// If any step after fd_alloc fails, use fd_close to free the
+	// file descriptor.
+
+	int r;
+	struct Fd *fd;
+
+	if (strlen(path) >= MAXPATHLEN)
+		return -E_BAD_PATH;
+
+	if ((r = fd_alloc(&fd)) < 0)
+		return r;
+
+	strcpy(fsipcbuf.open.req_path, path);
+	fsipcbuf.open.req_omode = mode;
+
+	if ((r = fsipc(FSREQ_OPEN, fd)) < 0) {
+		fd_close(fd, 0);
+		return r;
+	}
+
+	return fd2num(fd);
+}
+
+// Flush the file descriptor.  After this the fileid is invalid.
+//
+// This function is called by fd_close.  fd_close will take care of
+// unmapping the FD page from this environment.  Since the server uses
+// the reference counts on the FD pages to detect which files are
+// open, unmapping it is enough to free up server-side resources.
+// Other than that, we just have to make sure our changes are flushed
+// to disk.
+static int
+devfile_flush(struct Fd *fd)
+{
+	fsipcbuf.flush.req_fileid = fd->fd_file.id;
+	return fsipc(FSREQ_FLUSH, NULL);
+}
+
+// Read at most 'n' bytes from 'fd' at the current position into 'buf'.
+//
+// Returns:
+// 	The number of bytes successfully read.
+// 	< 0 on error.
+static ssize_t
+devfile_read(struct Fd *fd, void *buf, size_t n)
+{
+	// Make an FSREQ_READ request to the file system server after
+	// filling fsipcbuf.read with the request arguments.  The
+	// bytes read will be written back to fsipcbuf by the file
+	// system server.
+	int r;
+
+	fsipcbuf.read.req_fileid = fd->fd_file.id;
+	fsipcbuf.read.req_n = n;
+	if ((r = fsipc(FSREQ_READ, NULL)) < 0)
+		return r;
+	assert(r <= n);
+	assert(r <= PGSIZE);
+	memmove(buf, fsipcbuf.readRet.ret_buf, r);
+	return r;
+}
+
+
+// Write at most 'n' bytes from 'buf' to 'fd' at the current seek position.
+//
+// Returns:
+//	 The number of bytes successfully written.
+//	 < 0 on error.
+static ssize_t
+devfile_write(struct Fd *fd, const void *buf, size_t n)
+{
+	// Make an FSREQ_WRITE request to the file system server.  Be
+	// careful: fsipcbuf.write.req_buf is only so large, but
+	// remember that write is always allowed to write *fewer*
+	// bytes than requested.
+	// LAB 5: Your code here
+	panic("devfile_write not implemented");
+}
+
+static int
+devfile_stat(struct Fd *fd, struct Stat *st)
+{
+	int r;
+
+	fsipcbuf.stat.req_fileid = fd->fd_file.id;
+	if ((r = fsipc(FSREQ_STAT, NULL)) < 0)
+		return r;
+	strcpy(st->st_name, fsipcbuf.statRet.ret_name);
+	st->st_size = fsipcbuf.statRet.ret_size;
+	st->st_isdir = fsipcbuf.statRet.ret_isdir;
+	return 0;
+}
+
+// Truncate or extend an open file to 'size' bytes
+static int
+devfile_trunc(struct Fd *fd, off_t newsize)
+{
+	fsipcbuf.set_size.req_fileid = fd->fd_file.id;
+	fsipcbuf.set_size.req_size = newsize;
+	return fsipc(FSREQ_SET_SIZE, NULL);
+}
+
+
+// Synchronize disk with buffer cache
+int
+sync(void)
+{
+	// Ask the file server to update the disk
+	// by writing any dirty blocks in the buffer cache.
+
+	return fsipc(FSREQ_SYNC, NULL);
+}
+
diff --git a/lib.old/fork.c b/lib.old/fork.c
new file mode 100755
index 0000000..29cdf66
--- /dev/null
+++ b/lib.old/fork.c
@@ -0,0 +1,127 @@
+// implement fork from user space
+
+#include <inc/string.h>
+#include <inc/lib.h>
+
+// PTE_COW marks copy-on-write page table entries.
+// It is one of the bits explicitly allocated to user processes (PTE_AVAIL).
+#define PTE_COW		0x800
+
+//
+// Custom page fault handler - if faulting page is copy-on-write,
+// map in our own private writable copy.
+//
+    static void
+pgfault(struct UTrapframe *utf)
+{
+    void *addr = (void *) utf->utf_fault_va;
+    uint32_t err = utf->utf_err;
+    int r;
+    pte_t pte;
+    // Check that the faulting access was (1) a write, and (2) to a
+    // copy-on-write page.  If not, panic.
+    // Hint:
+    //   Use the read-only page table mappings at uvpt
+    //   (see <inc/memlayout.h>).
+    // LAB 4: Your code here.
+    if (!(utf->utf_err & FEC_WR)) panic("pgfault(): FEC_WR %x\n", addr);
+    if (!uvpd[((uintptr_t)addr >> 22)]) panic("pgfault(): page not mapped");
+    if (!(pte = uvpt[(uintptr_t)addr >> 12])) panic("pgfault(): page not mapped");
+    if (!(pte & PTE_COW)) panic("pgfault: PTE_COW\n");
+    // Allocate a new page, map it at a temporary location (PFTEMP),
+    // copy the data from the old page to the new page, then move the new
+    // page to the old page's address.
+    // Hint:
+    //   You should make three system calls.
+    // LAB 4: Your code here.
+    sys_page_alloc(0, (void*)PFTEMP, PTE_P | PTE_U | PTE_W);
+    memcpy((void*)PFTEMP, (void*)ROUNDDOWN((uintptr_t)addr, PGSIZE), PGSIZE);
+    sys_page_map(0, (void*)PFTEMP, 0, (void*)ROUNDDOWN((uintptr_t)addr, PGSIZE), PTE_P | PTE_U | PTE_W);
+    sys_page_unmap(0, (void*)PFTEMP);
+}
+
+//
+// Map our virtual page pn (address pn*PGSIZE) into the target envid
+// at the same virtual address.  If the page is writable or copy-on-write,
+// the new mapping must be created copy-on-write, and then our mapping must be
+// marked copy-on-write as well.  (Exercise: Why do we need to mark ours
+// copy-on-write again if it was already copy-on-write at the beginning of
+// this function?)
+//
+// Returns: 0 on success, < 0 on error.
+// It is also OK to panic on error.
+//
+    static int
+duppage(envid_t envid, unsigned pn)
+{
+    int r;
+
+    // LAB 4: Your code here.
+    int perm = uvpt[pn] & 0xfff;
+
+    if (perm & (PTE_W | PTE_COW)) {
+	if ((r = sys_page_map(0, (void*)(pn * PGSIZE), envid, (void*)(pn * PGSIZE), (perm & ~PTE_W) | PTE_COW)))
+	    return r;
+	if ((r = sys_page_map(0, (void*)(pn * PGSIZE), 0, (void*)(pn * PGSIZE), (perm & ~PTE_W) | PTE_COW)))
+	    return r;
+    }
+    else {
+	if ((r = sys_page_map(0, (void*)(pn * PGSIZE), envid, (void*)(pn * PGSIZE), perm)))
+	    return r;
+    }
+    return 0;
+}
+
+//
+// User-level fork with copy-on-write.
+// Set up our page fault handler appropriately.
+// Create a child.
+// Copy our address space and page fault handler setup to the child.
+// Then mark the child as runnable and return.
+//
+// Returns: child's envid to the parent, 0 to the child, < 0 on error.
+// It is also OK to panic on error.
+//
+// Hint:
+//   Use uvpd, uvpt, and duppage.
+//   Remember to fix "thisenv" in the child process.
+//   Neither user exception stack should ever be marked copy-on-write,
+//   so you must allocate a new page for the child's user exception stack.
+//
+    envid_t
+fork(void)
+{
+    // LAB 4: Your code here.
+    extern void _pgfault_upcall(void);
+    uintptr_t p = 0;
+    envid_t envid;
+    set_pgfault_handler(pgfault);
+
+    envid = sys_exofork();
+    if (envid < 0) return envid;
+    if (envid == 0) {
+	thisenv = &envs[ENVX(sys_getenvid())];
+	return 0;
+    }
+
+    while (p < UTOP) {
+	if (!uvpd[p >> 22]) {
+	    p += PGSIZE << 10;
+	    continue;
+	}
+	if (p != UXSTACKTOP - PGSIZE && uvpt[p >> 12]) duppage(envid, p >> 12);
+	p += PGSIZE;
+    }
+    if (sys_page_alloc(envid, (void*)(UXSTACKTOP - PGSIZE), PTE_P | PTE_U | PTE_W) < 0) panic("fork(): 111111\n");
+    if (sys_env_set_pgfault_upcall(envid, _pgfault_upcall) < 0) panic("fork(): 22222222\n");
+    if (sys_env_set_status(envid, ENV_RUNNABLE) < 0) panic("fork(): 3333333\n");
+    return envid;
+}
+
+// Challenge!
+    int
+sfork(void)
+{
+    panic("sfork not implemented");
+    return -E_INVAL;
+}
diff --git a/lib.old/fprintf.c b/lib.old/fprintf.c
new file mode 100644
index 0000000..23f8924
--- /dev/null
+++ b/lib.old/fprintf.c
@@ -0,0 +1,81 @@
+#include <inc/lib.h>
+
+// Collect up to 256 characters into a buffer
+// and perform ONE system call to print all of them,
+// in order to make the lines output to the console atomic
+// and prevent interrupts from causing context switches
+// in the middle of a console output line and such.
+struct printbuf {
+	int fd;		// file descriptor
+	int idx;	// current buffer index
+	ssize_t result;	// accumulated results from write
+	int error;	// first error that occurred
+	char buf[256];
+};
+
+
+static void
+writebuf(struct printbuf *b)
+{
+	if (b->error > 0) {
+		ssize_t result = write(b->fd, b->buf, b->idx);
+		if (result > 0)
+			b->result += result;
+		if (result != b->idx) // error, or wrote less than supplied
+			b->error = (result < 0 ? result : 0);
+	}
+}
+
+static void
+putch(int ch, void *thunk)
+{
+	struct printbuf *b = (struct printbuf *) thunk;
+	b->buf[b->idx++] = ch;
+	if (b->idx == 256) {
+		writebuf(b);
+		b->idx = 0;
+	}
+}
+
+int
+vfprintf(int fd, const char *fmt, va_list ap)
+{
+	struct printbuf b;
+
+	b.fd = fd;
+	b.idx = 0;
+	b.result = 0;
+	b.error = 1;
+	vprintfmt(putch, &b, fmt, ap);
+	if (b.idx > 0)
+		writebuf(&b);
+
+	return (b.result ? b.result : b.error);
+}
+
+int
+fprintf(int fd, const char *fmt, ...)
+{
+	va_list ap;
+	int cnt;
+
+	va_start(ap, fmt);
+	cnt = vfprintf(fd, fmt, ap);
+	va_end(ap);
+
+	return cnt;
+}
+
+int
+printf(const char *fmt, ...)
+{
+	va_list ap;
+	int cnt;
+
+	va_start(ap, fmt);
+	cnt = vfprintf(1, fmt, ap);
+	va_end(ap);
+
+	return cnt;
+}
+
diff --git a/lib.old/ipc.c b/lib.old/ipc.c
new file mode 100755
index 0000000..ab83e4d
--- /dev/null
+++ b/lib.old/ipc.c
@@ -0,0 +1,72 @@
+// User-level IPC library routines
+
+#include <inc/lib.h>
+
+// Receive a value via IPC and return it.
+// If 'pg' is nonnull, then any page sent by the sender will be mapped at
+//	that address.
+// If 'from_env_store' is nonnull, then store the IPC sender's envid in
+//	*from_env_store.
+// If 'perm_store' is nonnull, then store the IPC sender's page permission
+//	in *perm_store (this is nonzero iff a page was successfully
+//	transferred to 'pg').
+// If the system call fails, then store 0 in *fromenv and *perm (if
+//	they're nonnull) and return the error.
+// Otherwise, return the value sent by the sender
+//
+// Hint:
+//   Use 'thisenv' to discover the value and who sent it.
+//   If 'pg' is null, pass sys_ipc_recv a value that it will understand
+//   as meaning "no page".  (Zero is not the right value, since that's
+//   a perfectly valid place to map a page.)
+    int32_t
+ipc_recv(envid_t *from_env_store, void *pg, int *perm_store)
+{
+    // LAB 4: Your code here.
+    int r;
+    if (!pg) pg = (void*)UTOP;
+    if ((r = sys_ipc_recv(pg)) < 0) 
+    {
+	   if (from_env_store) *from_env_store = 0;
+	   if (perm_store) *perm_store = 0;
+	   return r;
+    }
+    if (from_env_store) *from_env_store = thisenv->env_ipc_from;
+    if (perm_store) *perm_store = thisenv->env_ipc_perm;
+    return thisenv->env_ipc_value;
+}
+
+// Send 'val' (and 'pg' with 'perm', if 'pg' is nonnull) to 'toenv'.
+// This function keeps trying until it succeeds.
+// It should panic() on any error other than -E_IPC_NOT_RECV.
+//
+// Hint:
+//   Use sys_yield() to be CPU-friendly.
+//   If 'pg' is null, pass sys_ipc_try_send a value that it will understand
+//   as meaning "no page".  (Zero is not the right value.)
+    void
+ipc_send(envid_t to_env, uint32_t val, void *pg, int perm)
+{
+    // LAB 4: Your code here.
+    int r;
+    while ((r = sys_ipc_try_send(to_env, val, (pg ? pg : (void*)UTOP), perm))) 
+    {
+        if (r != -E_IPC_NOT_RECV)
+            panic("ipc_send() %e\n", r);
+        sys_yield();
+    }
+
+}
+
+// Find the first environment of the given type.  We'll use this to
+// find special environments.
+// Returns 0 if no such environment exists.
+    envid_t
+ipc_find_env(enum EnvType type)
+{
+    int i;
+    for (i = 0; i < NENV; i++)
+	if (envs[i].env_type == type)
+	    return envs[i].env_id;
+    return 0;
+}
diff --git a/lib.old/libmain.c b/lib.old/libmain.c
new file mode 100755
index 0000000..a5aa1e1
--- /dev/null
+++ b/lib.old/libmain.c
@@ -0,0 +1,28 @@
+// Called from entry.S to get us going.
+// entry.S already took care of defining envs, pages, uvpd, and uvpt.
+
+#include <inc/lib.h>
+
+extern void umain(int argc, char **argv);
+
+const volatile struct Env *thisenv;
+const char *binaryname = "<unknown>";
+
+void
+libmain(int argc, char **argv)
+{
+	// set thisenv to point at our Env structure in envs[].
+	// LAB 3: Your code here.
+        thisenv = envs + ENVX(sys_getenvid());
+    
+	// save the name of the program so that panic() can use it
+	if (argc > 0)
+		binaryname = argv[0];
+
+	// call user main routine
+	umain(argc, argv);
+
+	// exit gracefully
+	exit();
+}
+
diff --git a/lib.old/pageref.c b/lib.old/pageref.c
new file mode 100644
index 0000000..f6958a3
--- /dev/null
+++ b/lib.old/pageref.c
@@ -0,0 +1,14 @@
+#include <inc/lib.h>
+
+int
+pageref(void *v)
+{
+	pte_t pte;
+
+	if (!(uvpd[PDX(v)] & PTE_P))
+		return 0;
+	pte = uvpt[PGNUM(v)];
+	if (!(pte & PTE_P))
+		return 0;
+	return pages[PGNUM(pte)].pp_ref;
+}
diff --git a/lib.old/panic.c b/lib.old/panic.c
new file mode 100755
index 0000000..8d76788
--- /dev/null
+++ b/lib.old/panic.c
@@ -0,0 +1,26 @@
+
+#include <inc/lib.h>
+
+/*
+ * Panic is called on unresolvable fatal errors.
+ * It prints "panic: <message>", then causes a breakpoint exception,
+ * which causes JOS to enter the JOS kernel monitor.
+ */
+void
+_panic(const char *file, int line, const char *fmt, ...)
+{
+	va_list ap;
+
+	va_start(ap, fmt);
+
+	// Print the panic message
+	cprintf("[%08x] user panic in %s at %s:%d: ",
+		sys_getenvid(), binaryname, file, line);
+	vcprintf(fmt, ap);
+	cprintf("\n");
+
+	// Cause a breakpoint exception
+	while (1)
+		asm volatile("int3");
+}
+
diff --git a/lib.old/pfentry.S b/lib.old/pfentry.S
new file mode 100755
index 0000000..e29c0ec
--- /dev/null
+++ b/lib.old/pfentry.S
@@ -0,0 +1,94 @@
+#include <inc/mmu.h>
+#include <inc/memlayout.h>
+
+// Page fault upcall entrypoint.
+
+// This is where we ask the kernel to redirect us to whenever we cause
+// a page fault in user space (see the call to sys_set_pgfault_handler
+// in pgfault.c).
+//
+// When a page fault actually occurs, the kernel switches our ESP to
+// point to the user exception stack if we're not already on the user
+// exception stack, and then it pushes a UTrapframe onto our user
+// exception stack:
+//
+//	trap-time esp
+//	trap-time eflags
+//	trap-time eip
+//	utf_regs.reg_eax
+//	...
+//	utf_regs.reg_esi
+//	utf_regs.reg_edi
+//	utf_err (error code)
+//	utf_fault_va            <-- %esp
+//
+// If this is a recursive fault, the kernel will reserve for us a
+// blank word above the trap-time esp for scratch work when we unwind
+// the recursive call.
+//
+// We then have call up to the appropriate page fault handler in C
+// code, pointed to by the global variable '_pgfault_handler'.
+
+.text
+.globl _pgfault_upcall
+_pgfault_upcall:
+// Call the C page fault handler.
+pushl %esp			// function argument: pointer to UTF
+movl _pgfault_handler, %eax
+call *%eax
+addl $4, %esp			// pop function argument
+
+// Now the C page fault handler has returned and you must return
+// to the trap time state.
+// Push trap-time %eip onto the trap-time stack.
+//
+// Explanation:
+//   We must prepare the trap-time stack for our eventual return to
+//   re-execute the instruction that faulted.
+//   Unfortunately, we can't return directly from the exception stack:
+//   We can't call 'jmp', since that requires that we load the address
+//   into a register, and all registers must have their trap-time
+//   values after the return.
+//   We can't call 'ret' from the exception stack either, since if we
+//   did, %esp would have the wrong value.
+//   So instead, we push the trap-time %eip onto the *trap-time* stack!
+//   Below we'll switch to that stack and call 'ret', which will
+//   restore %eip to its pre-fault value.
+//
+//   In the case of a recursive fault on the exception stack,
+//   note that the word we're pushing now will fit in the
+//   blank word that the kernel reserved for us.
+//
+// Throughout the remaining code, think carefully about what
+// registers are available for intermediate calculations.  You
+// may find that you have to rearrange your code in non-obvious
+// ways as registers become unavailable as scratch space.
+//
+// LAB 4: Your code here.
+
+subl $4, 48(%esp)
+    movl 48(%esp), %eax
+    movl 40(%esp), %edx
+movl %edx, (%eax)
+
+    // Restore the trap-time registers.  After you do this, you
+    // can no longer modify any general-purpose registers.
+    // LAB 4: Your code here.
+    addl $8, %esp
+    popal
+
+    // Restore eflags from the stack.  After you do this, you can
+    // no longer use arithmetic operations or anything else that
+    // modifies eflags.
+    // LAB 4: Your code here.
+    addl $4, %esp
+    popfl
+
+    // Switch back to the adjusted trap-time stack.
+    // LAB 4: Your code here.
+    popl %esp
+
+    // Return to re-execute the instruction that faulted.
+    // LAB 4: Your code here.
+
+    ret
diff --git a/lib.old/pgfault.c b/lib.old/pgfault.c
new file mode 100755
index 0000000..c4bdd94
--- /dev/null
+++ b/lib.old/pgfault.c
@@ -0,0 +1,39 @@
+// User-level page fault handler support.
+// Rather than register the C page fault handler directly with the
+// kernel as the page fault handler, we register the assembly language
+// wrapper in pfentry.S, which in turns calls the registered C
+// function.
+
+#include <inc/lib.h>
+
+
+// Assembly language pgfault entrypoint defined in lib/pfentry.S.
+extern void _pgfault_upcall(void);
+
+// Pointer to currently installed C-language pgfault handler.
+void (*_pgfault_handler)(struct UTrapframe *utf);
+
+//
+// Set the page fault handler function.
+// If there isn't one yet, _pgfault_handler will be 0.
+// The first time we register a handler, we need to
+// allocate an exception stack (one page of memory with its top
+// at UXSTACKTOP), and tell the kernel to call the assembly-language
+// _pgfault_upcall routine when a page fault occurs.
+//
+    void
+set_pgfault_handler(void (*handler)(struct UTrapframe *utf))
+{
+    int r;
+
+    if (_pgfault_handler == 0) {
+	// First time through!
+	// LAB 4: Your code here.
+	sys_page_alloc(0, (void*)(UXSTACKTOP - PGSIZE), PTE_U | PTE_W | PTE_P);
+	sys_env_set_pgfault_upcall(0, (void*)_pgfault_upcall);
+
+    }
+
+    // Save handler pointer for assembly to call.
+    _pgfault_handler = handler;
+}
diff --git a/lib.old/pipe.c b/lib.old/pipe.c
new file mode 100644
index 0000000..92eb16b
--- /dev/null
+++ b/lib.old/pipe.c
@@ -0,0 +1,191 @@
+#include <inc/lib.h>
+
+#define debug 0
+
+static ssize_t devpipe_read(struct Fd *fd, void *buf, size_t n);
+static ssize_t devpipe_write(struct Fd *fd, const void *buf, size_t n);
+static int devpipe_stat(struct Fd *fd, struct Stat *stat);
+static int devpipe_close(struct Fd *fd);
+
+struct Dev devpipe =
+{
+	.dev_id =	'p',
+	.dev_name =	"pipe",
+	.dev_read =	devpipe_read,
+	.dev_write =	devpipe_write,
+	.dev_close =	devpipe_close,
+	.dev_stat =	devpipe_stat,
+};
+
+#define PIPEBUFSIZ 32		// small to provoke races
+
+struct Pipe {
+	off_t p_rpos;		// read position
+	off_t p_wpos;		// write position
+	uint8_t p_buf[PIPEBUFSIZ];	// data buffer
+};
+
+int
+pipe(int pfd[2])
+{
+	int r;
+	struct Fd *fd0, *fd1;
+	void *va;
+
+	// allocate the file descriptor table entries
+	if ((r = fd_alloc(&fd0)) < 0
+	    || (r = sys_page_alloc(0, fd0, PTE_P|PTE_W|PTE_U|PTE_SHARE)) < 0)
+		goto err;
+
+	if ((r = fd_alloc(&fd1)) < 0
+	    || (r = sys_page_alloc(0, fd1, PTE_P|PTE_W|PTE_U|PTE_SHARE)) < 0)
+		goto err1;
+
+	// allocate the pipe structure as first data page in both
+	va = fd2data(fd0);
+	if ((r = sys_page_alloc(0, va, PTE_P|PTE_W|PTE_U|PTE_SHARE)) < 0)
+		goto err2;
+	if ((r = sys_page_map(0, va, 0, fd2data(fd1), PTE_P|PTE_W|PTE_U|PTE_SHARE)) < 0)
+		goto err3;
+
+	// set up fd structures
+	fd0->fd_dev_id = devpipe.dev_id;
+	fd0->fd_omode = O_RDONLY;
+
+	fd1->fd_dev_id = devpipe.dev_id;
+	fd1->fd_omode = O_WRONLY;
+
+	if (debug)
+		cprintf("[%08x] pipecreate %08x\n", thisenv->env_id, uvpt[PGNUM(va)]);
+
+	pfd[0] = fd2num(fd0);
+	pfd[1] = fd2num(fd1);
+	return 0;
+
+    err3:
+	sys_page_unmap(0, va);
+    err2:
+	sys_page_unmap(0, fd1);
+    err1:
+	sys_page_unmap(0, fd0);
+    err:
+	return r;
+}
+
+static int
+_pipeisclosed(struct Fd *fd, struct Pipe *p)
+{
+	int n, nn, ret;
+
+	while (1) {
+		n = thisenv->env_runs;
+		ret = pageref(fd) == pageref(p);
+		nn = thisenv->env_runs;
+		if (n == nn)
+			return ret;
+		if (n != nn && ret == 1)
+			cprintf("pipe race avoided\n", n, thisenv->env_runs, ret);
+	}
+}
+
+int
+pipeisclosed(int fdnum)
+{
+	struct Fd *fd;
+	struct Pipe *p;
+	int r;
+
+	if ((r = fd_lookup(fdnum, &fd)) < 0)
+		return r;
+	p = (struct Pipe*) fd2data(fd);
+	return _pipeisclosed(fd, p);
+}
+
+static ssize_t
+devpipe_read(struct Fd *fd, void *vbuf, size_t n)
+{
+	uint8_t *buf;
+	size_t i;
+	struct Pipe *p;
+
+	p = (struct Pipe*)fd2data(fd);
+	if (debug)
+		cprintf("[%08x] devpipe_read %08x %d rpos %d wpos %d\n",
+			thisenv->env_id, uvpt[PGNUM(p)], n, p->p_rpos, p->p_wpos);
+
+	buf = vbuf;
+	for (i = 0; i < n; i++) {
+		while (p->p_rpos == p->p_wpos) {
+			// pipe is empty
+			// if we got any data, return it
+			if (i > 0)
+				return i;
+			// if all the writers are gone, note eof
+			if (_pipeisclosed(fd, p))
+				return 0;
+			// yield and see what happens
+			if (debug)
+				cprintf("devpipe_read yield\n");
+			sys_yield();
+		}
+		// there's a byte.  take it.
+		// wait to increment rpos until the byte is taken!
+		buf[i] = p->p_buf[p->p_rpos % PIPEBUFSIZ];
+		p->p_rpos++;
+	}
+	return i;
+}
+
+static ssize_t
+devpipe_write(struct Fd *fd, const void *vbuf, size_t n)
+{
+	const uint8_t *buf;
+	size_t i;
+	struct Pipe *p;
+
+	p = (struct Pipe*) fd2data(fd);
+	if (debug)
+		cprintf("[%08x] devpipe_write %08x %d rpos %d wpos %d\n",
+			thisenv->env_id, uvpt[PGNUM(p)], n, p->p_rpos, p->p_wpos);
+
+	buf = vbuf;
+	for (i = 0; i < n; i++) {
+		while (p->p_wpos >= p->p_rpos + sizeof(p->p_buf)) {
+			// pipe is full
+			// if all the readers are gone
+			// (it's only writers like us now),
+			// note eof
+			if (_pipeisclosed(fd, p))
+				return 0;
+			// yield and see what happens
+			if (debug)
+				cprintf("devpipe_write yield\n");
+			sys_yield();
+		}
+		// there's room for a byte.  store it.
+		// wait to increment wpos until the byte is stored!
+		p->p_buf[p->p_wpos % PIPEBUFSIZ] = buf[i];
+		p->p_wpos++;
+	}
+
+	return i;
+}
+
+static int
+devpipe_stat(struct Fd *fd, struct Stat *stat)
+{
+	struct Pipe *p = (struct Pipe*) fd2data(fd);
+	strcpy(stat->st_name, "<pipe>");
+	stat->st_size = p->p_wpos - p->p_rpos;
+	stat->st_isdir = 0;
+	stat->st_dev = &devpipe;
+	return 0;
+}
+
+static int
+devpipe_close(struct Fd *fd)
+{
+	(void) sys_page_unmap(0, fd);
+	return sys_page_unmap(0, fd2data(fd));
+}
+
diff --git a/lib.old/printf.c b/lib.old/printf.c
new file mode 100755
index 0000000..da4f788
--- /dev/null
+++ b/lib.old/printf.c
@@ -0,0 +1,61 @@
+// Implementation of cprintf console output for user environments,
+// based on printfmt() and the sys_cputs() system call.
+//
+// cprintf is a debugging statement, not a generic output statement.
+// It is very important that it always go to the console, especially when
+// debugging file descriptor code!
+
+#include <inc/types.h>
+#include <inc/stdio.h>
+#include <inc/stdarg.h>
+#include <inc/lib.h>
+
+// Collect up to 256 characters into a buffer
+// and perform ONE system call to print all of them,
+// in order to make the lines output to the console atomic
+// and prevent interrupts from causing context switches
+// in the middle of a console output line and such.
+struct printbuf {
+	int idx;	// current buffer index
+	int cnt;	// total bytes printed so far
+	char buf[256];
+};
+
+
+static void
+putch(int ch, struct printbuf *b)
+{
+	b->buf[b->idx++] = ch;
+	if (b->idx == 256-1) {
+		sys_cputs(b->buf, b->idx);
+		b->idx = 0;
+	}
+	b->cnt++;
+}
+
+int
+vcprintf(const char *fmt, va_list ap)
+{
+	struct printbuf b;
+
+	b.idx = 0;
+	b.cnt = 0;
+	vprintfmt((void*)putch, &b, fmt, ap);
+	sys_cputs(b.buf, b.idx);
+
+	return b.cnt;
+}
+
+int
+cprintf(const char *fmt, ...)
+{
+	va_list ap;
+	int cnt;
+
+	va_start(ap, fmt);
+	cnt = vcprintf(fmt, ap);
+	va_end(ap);
+
+	return cnt;
+}
+
diff --git a/lib.old/printfmt.c b/lib.old/printfmt.c
new file mode 100755
index 0000000..25a3280
--- /dev/null
+++ b/lib.old/printfmt.c
@@ -0,0 +1,335 @@
+// Stripped-down primitive printf-style formatting routines,
+// used in common by printf, sprintf, fprintf, etc.
+// This code is also used by both the kernel and user programs.
+
+#include <inc/types.h>
+#include <inc/stdio.h>
+#include <inc/string.h>
+#include <inc/stdarg.h>
+#include <inc/error.h>
+#include <inc/color.h>
+
+/*
+ * Space or zero padding and a field width are supported for the numeric
+ * formats only.
+ *
+ * The special format %e takes an integer error code
+ * and prints a string describing the error.
+ * The integer may be positive or negative,
+ * so that -E_NO_MEM and E_NO_MEM are equivalent.
+ */
+
+static const char * const error_string[MAXERROR] =
+{
+	[E_UNSPECIFIED]	= "unspecified error",
+	[E_BAD_ENV]	= "bad environment",
+	[E_INVAL]	= "invalid parameter",
+	[E_NO_MEM]	= "out of memory",
+	[E_NO_FREE_ENV]	= "out of environments",
+	[E_FAULT]	= "segmentation fault",
+	[E_IPC_NOT_RECV]= "env is not recving",
+	[E_EOF]		= "unexpected end of file",
+	[E_NO_DISK]	= "no free space on disk",
+	[E_MAX_OPEN]	= "too many files are open",
+	[E_NOT_FOUND]	= "file or block not found",
+	[E_BAD_PATH]	= "invalid path",
+	[E_FILE_EXISTS]	= "file already exists",
+	[E_NOT_EXEC]	= "file is not a valid executable",
+	[E_NOT_SUPP]	= "operation not supported",
+};
+
+/*
+ * Print a number (base <= 16) in reverse order,
+ * using specified putch function and associated pointer putdat.
+ */
+static void
+printnum(void (*putch)(int, void*), void *putdat,
+	 unsigned long long num, unsigned base, int width, int padc)
+{
+	// first recursively print all preceding (more significant) digits
+	if (num >= base) {
+		printnum(putch, putdat, num / base, base, width - 1, padc);
+	} else {
+		// print any needed pad characters before first digit
+		while (--width > 0)
+			putch(padc, putdat);
+	}
+
+	// then print this (the least significant) digit
+	putch("0123456789abcdef"[num % base], putdat);
+}
+
+// Get an unsigned int of various possible sizes from a varargs list,
+// depending on the lflag parameter.
+static unsigned long long
+getuint(va_list *ap, int lflag)
+{
+	if (lflag >= 2)
+		return va_arg(*ap, unsigned long long);
+	else if (lflag)
+		return va_arg(*ap, unsigned long);
+	else
+		return va_arg(*ap, unsigned int);
+}
+
+// Same as getuint but signed - can't use getuint
+// because of sign extension
+static long long
+getint(va_list *ap, int lflag)
+{
+	if (lflag >= 2)
+		return va_arg(*ap, long long);
+	else if (lflag)
+		return va_arg(*ap, long);
+	else
+		return va_arg(*ap, int);
+}
+
+
+// Main function to format and print a string.
+void printfmt(void (*putch)(int, void*), void *putdat, const char *fmt, ...);
+
+void
+vprintfmt(void (*putch)(int, void*), void *putdat, const char *fmt, va_list ap)
+{
+	register const char *p;
+	register int ch, err;
+	unsigned long long num;
+	int base, lflag, width, precision, altflag;
+	char padc;
+
+	while (1) {
+		while ((ch = *(unsigned char *) fmt++) != '%') {
+			if (ch == '\0')
+				return;
+			else if(ch == '\033'){
+				if((ch = *(unsigned char *) fmt++) != '[') {
+				    putch(ch, putdat);
+				    continue;
+				}
+				BG_COLOR = *(unsigned char *) fmt++;
+				FG_COLOR = *(unsigned char *) fmt++;
+
+				if(BG_COLOR >= '0' && BG_COLOR <= '9')
+				    BG_COLOR -= '0';
+				else if(BG_COLOR >= 'a' && BG_COLOR <= 'f')
+				    BG_COLOR = BG_COLOR - 'a' + 10;
+				else if(BG_COLOR >= 'A' && BG_COLOR <= 'F')
+				    BG_COLOR = BG_COLOR - 'A' + 10;
+				else BG_COLOR = 0;
+
+				if(FG_COLOR >= '0' && FG_COLOR <= '9')
+				    FG_COLOR -= '0';
+				else if(FG_COLOR >= 'a' && FG_COLOR <= 'f')
+				    FG_COLOR = FG_COLOR - 'a' + 10;
+				else if(FG_COLOR >= 'A' && FG_COLOR <= 'F')
+				    FG_COLOR = FG_COLOR - 'A' + 10;
+				else BG_COLOR = 7;
+
+				COLOR = (BG_COLOR << 12) | (FG_COLOR << 8);
+				continue;
+			}	
+			putch(ch, putdat);
+		}
+
+		// Process a %-escape sequence
+		padc = ' ';
+		width = -1;
+		precision = -1;
+		lflag = 0;
+		altflag = 0;
+	reswitch:
+		switch (ch = *(unsigned char *) fmt++) {
+
+		// flag to pad on the right
+		case '-':
+			padc = '-';
+			goto reswitch;
+
+		// flag to pad with 0's instead of spaces
+		case '0':
+			padc = '0';
+			goto reswitch;
+
+		// width field
+		case '1':
+		case '2':
+		case '3':
+		case '4':
+		case '5':
+		case '6':
+		case '7':
+		case '8':
+		case '9':
+			for (precision = 0; ; ++fmt) {
+				precision = precision * 10 + ch - '0';
+				ch = *fmt;
+				if (ch < '0' || ch > '9')
+					break;
+			}
+			goto process_precision;
+
+		case '*':
+			precision = va_arg(ap, int);
+			goto process_precision;
+
+		case '.':
+			if (width < 0)
+				width = 0;
+			goto reswitch;
+
+		case '#':
+			altflag = 1;
+			goto reswitch;
+
+		process_precision:
+			if (width < 0)
+				width = precision, precision = -1;
+			goto reswitch;
+
+		// long flag (doubled for long long)
+		case 'l':
+			lflag++;
+			goto reswitch;
+
+		// character
+		case 'c':
+			putch(va_arg(ap, int), putdat);
+			break;
+
+		// error message
+		case 'e':
+			err = va_arg(ap, int);
+			if (err < 0)
+				err = -err;
+			if (err >= MAXERROR || (p = error_string[err]) == NULL)
+				printfmt(putch, putdat, "error %d", err);
+			else
+				printfmt(putch, putdat, "%s", p);
+			break;
+
+		// string
+		case 's':
+			if ((p = va_arg(ap, char *)) == NULL)
+				p = "(null)";
+			if (width > 0 && padc != '-')
+				for (width -= strnlen(p, precision); width > 0; width--)
+					putch(padc, putdat);
+			for (; (ch = *p++) != '\0' && (precision < 0 || --precision >= 0); width--)
+				if (altflag && (ch < ' ' || ch > '~'))
+					putch('?', putdat);
+				else
+					putch(ch, putdat);
+			for (; width > 0; width--)
+				putch(' ', putdat);
+			break;
+
+		// (signed) decimal
+		case 'd':
+			num = getint(&ap, lflag);
+			if ((long long) num < 0) {
+				putch('-', putdat);
+				num = -(long long) num;
+			}
+			base = 10;
+			goto number;
+
+		// unsigned decimal
+		case 'u':
+			num = getuint(&ap, lflag);
+			base = 10;
+			goto number;
+
+		// (unsigned) octal
+		case 'o':
+			num = getuint(&ap,lflag);
+			base = 8;
+			goto number;
+
+		// pointer
+		case 'p':
+			putch('0', putdat);
+			putch('x', putdat);
+			num = (unsigned long long)
+				(uintptr_t) va_arg(ap, void *);
+			base = 16;
+			goto number;
+
+		// (unsigned) hexadecimal
+		case 'x':
+			num = getuint(&ap, lflag);
+			base = 16;
+		number:
+			printnum(putch, putdat, num, base, width, padc);
+			break;
+
+		// escaped '%' character
+		case '%':
+			putch(ch, putdat);
+			break;			
+
+		// unrecognized escape sequence - just print it literally
+		default:
+			putch('%', putdat);
+			for (fmt--; fmt[-1] != '%'; fmt--)
+				/* do nothing */;
+			break;
+		}
+	}
+}
+
+void
+printfmt(void (*putch)(int, void*), void *putdat, const char *fmt, ...)
+{
+	va_list ap;
+
+	va_start(ap, fmt);
+	vprintfmt(putch, putdat, fmt, ap);
+	va_end(ap);
+}
+
+struct sprintbuf {
+	char *buf;
+	char *ebuf;
+	int cnt;
+};
+
+static void
+sprintputch(int ch, struct sprintbuf *b)
+{
+	b->cnt++;
+	if (b->buf < b->ebuf)
+		*b->buf++ = ch;
+}
+
+int
+vsnprintf(char *buf, int n, const char *fmt, va_list ap)
+{
+	struct sprintbuf b = {buf, buf+n-1, 0};
+
+	if (buf == NULL || n < 1)
+		return -E_INVAL;
+
+	// print the string to the buffer
+	vprintfmt((void*)sprintputch, &b, fmt, ap);
+
+	// null terminate the buffer
+	*b.buf = '\0';
+
+	return b.cnt;
+}
+
+int
+snprintf(char *buf, int n, const char *fmt, ...)
+{
+	va_list ap;
+	int rc;
+
+	va_start(ap, fmt);
+	rc = vsnprintf(buf, n, fmt, ap);
+	va_end(ap);
+
+	return rc;
+}
+
+
diff --git a/lib.old/readline.c b/lib.old/readline.c
new file mode 100755
index 0000000..b7030cd
--- /dev/null
+++ b/lib.old/readline.c
@@ -0,0 +1,44 @@
+#include <inc/stdio.h>
+#include <inc/error.h>
+
+#define BUFLEN 1024
+static char buf[BUFLEN];
+
+char *
+readline(const char *prompt)
+{
+	int i, c, echoing;
+
+#if JOS_KERNEL
+	if (prompt != NULL)
+		cprintf("%s", prompt);
+#else
+	if (prompt != NULL)
+		fprintf(1, "%s", prompt);
+#endif
+
+	i = 0;
+	echoing = iscons(0);
+	while (1) {
+		c = getchar();
+		if (c < 0) {
+			if (c != -E_EOF)
+				cprintf("read error: %e\n", c);
+			return NULL;
+		} else if ((c == '\b' || c == '\x7f') && i > 0) {
+			if (echoing)
+				cputchar('\b');
+			i--;
+		} else if (c >= ' ' && i < BUFLEN-1) {
+			if (echoing)
+				cputchar(c);
+			buf[i++] = c;
+		} else if (c == '\n' || c == '\r') {
+			if (echoing)
+				cputchar('\n');
+			buf[i] = 0;
+			return buf;
+		}
+	}
+}
+
diff --git a/lib.old/spawn.c b/lib.old/spawn.c
new file mode 100644
index 0000000..9d0eb07
--- /dev/null
+++ b/lib.old/spawn.c
@@ -0,0 +1,307 @@
+#include <inc/lib.h>
+#include <inc/elf.h>
+
+#define UTEMP2USTACK(addr)	((void*) (addr) + (USTACKTOP - PGSIZE) - UTEMP)
+#define UTEMP2			(UTEMP + PGSIZE)
+#define UTEMP3			(UTEMP2 + PGSIZE)
+
+// Helper functions for spawn.
+static int init_stack(envid_t child, const char **argv, uintptr_t *init_esp);
+static int map_segment(envid_t child, uintptr_t va, size_t memsz,
+		       int fd, size_t filesz, off_t fileoffset, int perm);
+static int copy_shared_pages(envid_t child);
+
+// Spawn a child process from a program image loaded from the file system.
+// prog: the pathname of the program to run.
+// argv: pointer to null-terminated array of pointers to strings,
+// 	 which will be passed to the child as its command-line arguments.
+// Returns child envid on success, < 0 on failure.
+int
+spawn(const char *prog, const char **argv)
+{
+	unsigned char elf_buf[512];
+	struct Trapframe child_tf;
+	envid_t child;
+
+	int fd, i, r;
+	struct Elf *elf;
+	struct Proghdr *ph;
+	int perm;
+
+	// This code follows this procedure:
+	//
+	//   - Open the program file.
+	//
+	//   - Read the ELF header, as you have before, and sanity check its
+	//     magic number.  (Check out your load_icode!)
+	//
+	//   - Use sys_exofork() to create a new environment.
+	//
+	//   - Set child_tf to an initial struct Trapframe for the child.
+	//
+	//   - Call the init_stack() function above to set up
+	//     the initial stack page for the child environment.
+	//
+	//   - Map all of the program's segments that are of p_type
+	//     ELF_PROG_LOAD into the new environment's address space.
+	//     Use the p_flags field in the Proghdr for each segment
+	//     to determine how to map the segment:
+	//
+	//	* If the ELF flags do not include ELF_PROG_FLAG_WRITE,
+	//	  then the segment contains text and read-only data.
+	//	  Use read_map() to read the contents of this segment,
+	//	  and map the pages it returns directly into the child
+	//        so that multiple instances of the same program
+	//	  will share the same copy of the program text.
+	//        Be sure to map the program text read-only in the child.
+	//        Read_map is like read but returns a pointer to the data in
+	//        *blk rather than copying the data into another buffer.
+	//
+	//	* If the ELF segment flags DO include ELF_PROG_FLAG_WRITE,
+	//	  then the segment contains read/write data and bss.
+	//	  As with load_icode() in Lab 3, such an ELF segment
+	//	  occupies p_memsz bytes in memory, but only the FIRST
+	//	  p_filesz bytes of the segment are actually loaded
+	//	  from the executable file - you must clear the rest to zero.
+	//        For each page to be mapped for a read/write segment,
+	//        allocate a page in the parent temporarily at UTEMP,
+	//        read() the appropriate portion of the file into that page
+	//	  and/or use memset() to zero non-loaded portions.
+	//	  (You can avoid calling memset(), if you like, if
+	//	  page_alloc() returns zeroed pages already.)
+	//        Then insert the page mapping into the child.
+	//        Look at init_stack() for inspiration.
+	//        Be sure you understand why you can't use read_map() here.
+	//
+	//     Note: None of the segment addresses or lengths above
+	//     are guaranteed to be page-aligned, so you must deal with
+	//     these non-page-aligned values appropriately.
+	//     The ELF linker does, however, guarantee that no two segments
+	//     will overlap on the same page; and it guarantees that
+	//     PGOFF(ph->p_offset) == PGOFF(ph->p_va).
+	//
+	//   - Call sys_env_set_trapframe(child, &child_tf) to set up the
+	//     correct initial eip and esp values in the child.
+	//
+	//   - Start the child process running with sys_env_set_status().
+
+	if ((r = open(prog, O_RDONLY)) < 0)
+		return r;
+	fd = r;
+
+	// Read elf header
+	elf = (struct Elf*) elf_buf;
+	if (readn(fd, elf_buf, sizeof(elf_buf)) != sizeof(elf_buf)
+	    || elf->e_magic != ELF_MAGIC) {
+		close(fd);
+		cprintf("elf magic %08x want %08x\n", elf->e_magic, ELF_MAGIC);
+		return -E_NOT_EXEC;
+	}
+
+	// Create new child environment
+	if ((r = sys_exofork()) < 0)
+		return r;
+	child = r;
+
+	// Set up trap frame, including initial stack.
+	child_tf = envs[ENVX(child)].env_tf;
+	child_tf.tf_eip = elf->e_entry;
+
+	if ((r = init_stack(child, argv, &child_tf.tf_esp)) < 0)
+		return r;
+
+	// Set up program segments as defined in ELF header.
+	ph = (struct Proghdr*) (elf_buf + elf->e_phoff);
+	for (i = 0; i < elf->e_phnum; i++, ph++) {
+		if (ph->p_type != ELF_PROG_LOAD)
+			continue;
+		perm = PTE_P | PTE_U;
+		if (ph->p_flags & ELF_PROG_FLAG_WRITE)
+			perm |= PTE_W;
+		if ((r = map_segment(child, ph->p_va, ph->p_memsz,
+				     fd, ph->p_filesz, ph->p_offset, perm)) < 0)
+			goto error;
+	}
+	close(fd);
+	fd = -1;
+
+	// Copy shared library state.
+	if ((r = copy_shared_pages(child)) < 0)
+		panic("copy_shared_pages: %e", r);
+
+	child_tf.tf_eflags |= FL_IOPL_3;   // devious: see user/faultio.c
+	if ((r = sys_env_set_trapframe(child, &child_tf)) < 0)
+		panic("sys_env_set_trapframe: %e", r);
+
+	if ((r = sys_env_set_status(child, ENV_RUNNABLE)) < 0)
+		panic("sys_env_set_status: %e", r);
+
+	return child;
+
+error:
+	sys_env_destroy(child);
+	close(fd);
+	return r;
+}
+
+// Spawn, taking command-line arguments array directly on the stack.
+// NOTE: Must have a sentinal of NULL at the end of the args
+// (none of the args may be NULL).
+int
+spawnl(const char *prog, const char *arg0, ...)
+{
+	// We calculate argc by advancing the args until we hit NULL.
+	// The contract of the function guarantees that the last
+	// argument will always be NULL, and that none of the other
+	// arguments will be NULL.
+	int argc=0;
+	va_list vl;
+	va_start(vl, arg0);
+	while(va_arg(vl, void *) != NULL)
+		argc++;
+	va_end(vl);
+
+	// Now that we have the size of the args, do a second pass
+	// and store the values in a VLA, which has the format of argv
+	const char *argv[argc+2];
+	argv[0] = arg0;
+	argv[argc+1] = NULL;
+
+	va_start(vl, arg0);
+	unsigned i;
+	for(i=0;i<argc;i++)
+		argv[i+1] = va_arg(vl, const char *);
+	va_end(vl);
+	return spawn(prog, argv);
+}
+
+
+// Set up the initial stack page for the new child process with envid 'child'
+// using the arguments array pointed to by 'argv',
+// which is a null-terminated array of pointers to null-terminated strings.
+//
+// On success, returns 0 and sets *init_esp
+// to the initial stack pointer with which the child should start.
+// Returns < 0 on failure.
+static int
+init_stack(envid_t child, const char **argv, uintptr_t *init_esp)
+{
+	size_t string_size;
+	int argc, i, r;
+	char *string_store;
+	uintptr_t *argv_store;
+
+	// Count the number of arguments (argc)
+	// and the total amount of space needed for strings (string_size).
+	string_size = 0;
+	for (argc = 0; argv[argc] != 0; argc++)
+		string_size += strlen(argv[argc]) + 1;
+
+	// Determine where to place the strings and the argv array.
+	// Set up pointers into the temporary page 'UTEMP'; we'll map a page
+	// there later, then remap that page into the child environment
+	// at (USTACKTOP - PGSIZE).
+	// strings is the topmost thing on the stack.
+	string_store = (char*) UTEMP + PGSIZE - string_size;
+	// argv is below that.  There's one argument pointer per argument, plus
+	// a null pointer.
+	argv_store = (uintptr_t*) (ROUNDDOWN(string_store, 4) - 4 * (argc + 1));
+
+	// Make sure that argv, strings, and the 2 words that hold 'argc'
+	// and 'argv' themselves will all fit in a single stack page.
+	if ((void*) (argv_store - 2) < (void*) UTEMP)
+		return -E_NO_MEM;
+
+	// Allocate the single stack page at UTEMP.
+	if ((r = sys_page_alloc(0, (void*) UTEMP, PTE_P|PTE_U|PTE_W)) < 0)
+		return r;
+
+
+	//	* Initialize 'argv_store[i]' to point to argument string i,
+	//	  for all 0 <= i < argc.
+	//	  Also, copy the argument strings from 'argv' into the
+	//	  newly-allocated stack page.
+	//
+	//	* Set 'argv_store[argc]' to 0 to null-terminate the args array.
+	//
+	//	* Push two more words onto the child's stack below 'args',
+	//	  containing the argc and argv parameters to be passed
+	//	  to the child's umain() function.
+	//	  argv should be below argc on the stack.
+	//	  (Again, argv should use an address valid in the child's
+	//	  environment.)
+	//
+	//	* Set *init_esp to the initial stack pointer for the child,
+	//	  (Again, use an address valid in the child's environment.)
+	for (i = 0; i < argc; i++) {
+		argv_store[i] = UTEMP2USTACK(string_store);
+		strcpy(string_store, argv[i]);
+		string_store += strlen(argv[i]) + 1;
+	}
+	argv_store[argc] = 0;
+	assert(string_store == (char*)UTEMP + PGSIZE);
+
+	argv_store[-1] = UTEMP2USTACK(argv_store);
+	argv_store[-2] = argc;
+
+	*init_esp = UTEMP2USTACK(&argv_store[-2]);
+
+	// After completing the stack, map it into the child's address space
+	// and unmap it from ours!
+	if ((r = sys_page_map(0, UTEMP, child, (void*) (USTACKTOP - PGSIZE), PTE_P | PTE_U | PTE_W)) < 0)
+		goto error;
+	if ((r = sys_page_unmap(0, UTEMP)) < 0)
+		goto error;
+
+	return 0;
+
+error:
+	sys_page_unmap(0, UTEMP);
+	return r;
+}
+
+static int
+map_segment(envid_t child, uintptr_t va, size_t memsz,
+	int fd, size_t filesz, off_t fileoffset, int perm)
+{
+	int i, r;
+	void *blk;
+
+	//cprintf("map_segment %x+%x\n", va, memsz);
+
+	if ((i = PGOFF(va))) {
+		va -= i;
+		memsz += i;
+		filesz += i;
+		fileoffset -= i;
+	}
+
+	for (i = 0; i < memsz; i += PGSIZE) {
+		if (i >= filesz) {
+			// allocate a blank page
+			if ((r = sys_page_alloc(child, (void*) (va + i), perm)) < 0)
+				return r;
+		} else {
+			// from file
+			if ((r = sys_page_alloc(0, UTEMP, PTE_P|PTE_U|PTE_W)) < 0)
+				return r;
+			if ((r = seek(fd, fileoffset + i)) < 0)
+				return r;
+			if ((r = readn(fd, UTEMP, MIN(PGSIZE, filesz-i))) < 0)
+				return r;
+			if ((r = sys_page_map(0, UTEMP, child, (void*) (va + i), perm)) < 0)
+				panic("spawn: sys_page_map data: %e", r);
+			sys_page_unmap(0, UTEMP);
+		}
+	}
+	return 0;
+}
+
+// Copy the mappings for shared pages into the child address space.
+static int
+copy_shared_pages(envid_t child)
+{
+	// LAB 5: Your code here.
+	return 0;
+}
+
diff --git a/lib.old/string.c b/lib.old/string.c
new file mode 100755
index 0000000..400547f
--- /dev/null
+++ b/lib.old/string.c
@@ -0,0 +1,285 @@
+// Basic string routines.  Not hardware optimized, but not shabby.
+
+#include <inc/string.h>
+
+// Using assembly for memset/memmove
+// makes some difference on real hardware,
+// but it makes an even bigger difference on bochs.
+// Primespipe runs 3x faster this way.
+#define ASM 1
+
+int
+strlen(const char *s)
+{
+	int n;
+
+	for (n = 0; *s != '\0'; s++)
+		n++;
+	return n;
+}
+
+int
+strnlen(const char *s, size_t size)
+{
+	int n;
+
+	for (n = 0; size > 0 && *s != '\0'; s++, size--)
+		n++;
+	return n;
+}
+
+char *
+strcpy(char *dst, const char *src)
+{
+	char *ret;
+
+	ret = dst;
+	while ((*dst++ = *src++) != '\0')
+		/* do nothing */;
+	return ret;
+}
+
+char *
+strcat(char *dst, const char *src)
+{
+	int len = strlen(dst);
+	strcpy(dst + len, src);
+	return dst;
+}
+
+char *
+strncpy(char *dst, const char *src, size_t size) {
+	size_t i;
+	char *ret;
+
+	ret = dst;
+	for (i = 0; i < size; i++) {
+		*dst++ = *src;
+		// If strlen(src) < size, null-pad 'dst' out to 'size' chars
+		if (*src != '\0')
+			src++;
+	}
+	return ret;
+}
+
+size_t
+strlcpy(char *dst, const char *src, size_t size)
+{
+	char *dst_in;
+
+	dst_in = dst;
+	if (size > 0) {
+		while (--size > 0 && *src != '\0')
+			*dst++ = *src++;
+		*dst = '\0';
+	}
+	return dst - dst_in;
+}
+
+int
+strcmp(const char *p, const char *q)
+{
+	while (*p && *p == *q)
+		p++, q++;
+	return (int) ((unsigned char) *p - (unsigned char) *q);
+}
+
+int
+strncmp(const char *p, const char *q, size_t n)
+{
+	while (n > 0 && *p && *p == *q)
+		n--, p++, q++;
+	if (n == 0)
+		return 0;
+	else
+		return (int) ((unsigned char) *p - (unsigned char) *q);
+}
+
+// Return a pointer to the first occurrence of 'c' in 's',
+// or a null pointer if the string has no 'c'.
+char *
+strchr(const char *s, char c)
+{
+	for (; *s; s++)
+		if (*s == c)
+			return (char *) s;
+	return 0;
+}
+
+// Return a pointer to the first occurrence of 'c' in 's',
+// or a pointer to the string-ending null character if the string has no 'c'.
+char *
+strfind(const char *s, char c)
+{
+	for (; *s; s++)
+		if (*s == c)
+			break;
+	return (char *) s;
+}
+
+#if ASM
+void *
+memset(void *v, int c, size_t n)
+{
+	char *p;
+
+	if (n == 0)
+		return v;
+	if ((int)v%4 == 0 && n%4 == 0) {
+		c &= 0xFF;
+		c = (c<<24)|(c<<16)|(c<<8)|c;
+		asm volatile("cld; rep stosl\n"
+			:: "D" (v), "a" (c), "c" (n/4)
+			: "cc", "memory");
+	} else
+		asm volatile("cld; rep stosb\n"
+			:: "D" (v), "a" (c), "c" (n)
+			: "cc", "memory");
+	return v;
+}
+
+void *
+memmove(void *dst, const void *src, size_t n)
+{
+	const char *s;
+	char *d;
+
+	s = src;
+	d = dst;
+	if (s < d && s + n > d) {
+		s += n;
+		d += n;
+		if ((int)s%4 == 0 && (int)d%4 == 0 && n%4 == 0)
+			asm volatile("std; rep movsl\n"
+				:: "D" (d-4), "S" (s-4), "c" (n/4) : "cc", "memory");
+		else
+			asm volatile("std; rep movsb\n"
+				:: "D" (d-1), "S" (s-1), "c" (n) : "cc", "memory");
+		// Some versions of GCC rely on DF being clear
+		asm volatile("cld" ::: "cc");
+	} else {
+		if ((int)s%4 == 0 && (int)d%4 == 0 && n%4 == 0)
+			asm volatile("cld; rep movsl\n"
+				:: "D" (d), "S" (s), "c" (n/4) : "cc", "memory");
+		else
+			asm volatile("cld; rep movsb\n"
+				:: "D" (d), "S" (s), "c" (n) : "cc", "memory");
+	}
+	return dst;
+}
+
+#else
+
+void *
+memset(void *v, int c, size_t n)
+{
+	char *p;
+	int m;
+
+	p = v;
+	m = n;
+	while (--m >= 0)
+		*p++ = c;
+
+	return v;
+}
+
+void *
+memmove(void *dst, const void *src, size_t n)
+{
+	const char *s;
+	char *d;
+
+	s = src;
+	d = dst;
+	if (s < d && s + n > d) {
+		s += n;
+		d += n;
+		while (n-- > 0)
+			*--d = *--s;
+	} else
+		while (n-- > 0)
+			*d++ = *s++;
+
+	return dst;
+}
+#endif
+
+void *
+memcpy(void *dst, const void *src, size_t n)
+{
+	return memmove(dst, src, n);
+}
+
+int
+memcmp(const void *v1, const void *v2, size_t n)
+{
+	const uint8_t *s1 = (const uint8_t *) v1;
+	const uint8_t *s2 = (const uint8_t *) v2;
+
+	while (n-- > 0) {
+		if (*s1 != *s2)
+			return (int) *s1 - (int) *s2;
+		s1++, s2++;
+	}
+
+	return 0;
+}
+
+void *
+memfind(const void *s, int c, size_t n)
+{
+	const void *ends = (const char *) s + n;
+	for (; s < ends; s++)
+		if (*(const unsigned char *) s == (unsigned char) c)
+			break;
+	return (void *) s;
+}
+
+long
+strtol(const char *s, char **endptr, int base)
+{
+	int neg = 0;
+	long val = 0;
+
+	// gobble initial whitespace
+	while (*s == ' ' || *s == '\t')
+		s++;
+
+	// plus/minus sign
+	if (*s == '+')
+		s++;
+	else if (*s == '-')
+		s++, neg = 1;
+
+	// hex or octal base prefix
+	if ((base == 0 || base == 16) && (s[0] == '0' && s[1] == 'x'))
+		s += 2, base = 16;
+	else if (base == 0 && s[0] == '0')
+		s++, base = 8;
+	else if (base == 0)
+		base = 10;
+
+	// digits
+	while (1) {
+		int dig;
+
+		if (*s >= '0' && *s <= '9')
+			dig = *s - '0';
+		else if (*s >= 'a' && *s <= 'z')
+			dig = *s - 'a' + 10;
+		else if (*s >= 'A' && *s <= 'Z')
+			dig = *s - 'A' + 10;
+		else
+			break;
+		if (dig >= base)
+			break;
+		s++, val = (val * base) + dig;
+		// we don't properly detect overflow!
+	}
+
+	if (endptr)
+		*endptr = (char *) s;
+	return (neg ? -val : val);
+}
+
diff --git a/lib.old/syscall.c b/lib.old/syscall.c
new file mode 100755
index 0000000..d8b1987
--- /dev/null
+++ b/lib.old/syscall.c
@@ -0,0 +1,119 @@
+// System call stubs.
+
+#include <inc/syscall.h>
+#include <inc/lib.h>
+
+static inline int32_t
+syscall(int num, int check, uint32_t a1, uint32_t a2, uint32_t a3, uint32_t a4, uint32_t a5)
+{
+	int32_t ret;
+
+	// Generic system call: pass system call number in AX,
+	// up to five parameters in DX, CX, BX, DI, SI.
+	// Interrupt kernel with T_SYSCALL.
+	//
+	// The "volatile" tells the assembler not to optimize
+	// this instruction away just because we don't use the
+	// return value.
+	//
+	// The last clause tells the assembler that this can
+	// potentially change the condition codes and arbitrary
+	// memory locations.
+
+	asm volatile("int %1\n"
+		     : "=a" (ret)
+		     : "i" (T_SYSCALL),
+		       "a" (num),
+		       "d" (a1),
+		       "c" (a2),
+		       "b" (a3),
+		       "D" (a4),
+		       "S" (a5)
+		     : "cc", "memory");
+
+	if(check && ret > 0)
+		panic("syscall %d returned %d (> 0)", num, ret);
+
+	return ret;
+}
+
+void
+sys_cputs(const char *s, size_t len)
+{
+	syscall(SYS_cputs, 0, (uint32_t)s, len, 0, 0, 0);
+}
+
+int
+sys_cgetc(void)
+{
+	return syscall(SYS_cgetc, 0, 0, 0, 0, 0, 0);
+}
+
+int
+sys_env_destroy(envid_t envid)
+{
+	return syscall(SYS_env_destroy, 1, envid, 0, 0, 0, 0);
+}
+
+envid_t
+sys_getenvid(void)
+{
+	 return syscall(SYS_getenvid, 0, 0, 0, 0, 0, 0);
+}
+
+void
+sys_yield(void)
+{
+	syscall(SYS_yield, 0, 0, 0, 0, 0, 0);
+}
+
+int
+sys_page_alloc(envid_t envid, void *va, int perm)
+{
+	return syscall(SYS_page_alloc, 1, envid, (uint32_t) va, perm, 0, 0);
+}
+
+int
+sys_page_map(envid_t srcenv, void *srcva, envid_t dstenv, void *dstva, int perm)
+{
+	return syscall(SYS_page_map, 1, srcenv, (uint32_t) srcva, dstenv, (uint32_t) dstva, perm);
+}
+
+int
+sys_page_unmap(envid_t envid, void *va)
+{
+	return syscall(SYS_page_unmap, 1, envid, (uint32_t) va, 0, 0, 0);
+}
+
+// sys_exofork is inlined in lib.h
+
+int
+sys_env_set_status(envid_t envid, int status)
+{
+	return syscall(SYS_env_set_status, 1, envid, status, 0, 0, 0);
+}
+
+int
+sys_env_set_trapframe(envid_t envid, struct Trapframe *tf)
+{
+	return syscall(SYS_env_set_trapframe, 1, envid, (uint32_t) tf, 0, 0, 0);
+}
+
+int
+sys_env_set_pgfault_upcall(envid_t envid, void *upcall)
+{
+	return syscall(SYS_env_set_pgfault_upcall, 1, envid, (uint32_t) upcall, 0, 0, 0);
+}
+
+int
+sys_ipc_try_send(envid_t envid, uint32_t value, void *srcva, int perm)
+{
+	return syscall(SYS_ipc_try_send, 0, envid, value, (uint32_t) srcva, perm, 0);
+}
+
+int
+sys_ipc_recv(void *dstva)
+{
+	return syscall(SYS_ipc_recv, 1, (uint32_t)dstva, 0, 0, 0, 0);
+}
+
diff --git a/lib.old/wait.c b/lib.old/wait.c
new file mode 100644
index 0000000..0e42135
--- /dev/null
+++ b/lib.old/wait.c
@@ -0,0 +1,13 @@
+#include <inc/lib.h>
+
+// Waits until 'envid' exits.
+void
+wait(envid_t envid)
+{
+	const volatile struct Env *e;
+
+	assert(envid != 0);
+	e = &envs[ENVX(envid)];
+	while (e->env_id == envid && e->env_status != ENV_FREE)
+		sys_yield();
+}
diff --git a/lib/Makefrag b/lib/Makefrag
old mode 100644
new mode 100755
diff --git a/lib/args.c b/lib/args.c
old mode 100644
new mode 100755
diff --git a/lib/console.c b/lib/console.c
old mode 100644
new mode 100755
diff --git a/lib/entry.S b/lib/entry.S
old mode 100644
new mode 100755
diff --git a/lib/exit.c b/lib/exit.c
old mode 100644
new mode 100755
diff --git a/lib/fd.c b/lib/fd.c
old mode 100644
new mode 100755
diff --git a/lib/file.c b/lib/file.c
old mode 100644
new mode 100755
index 39025b2..b693bee
--- a/lib/file.c
+++ b/lib/file.c
@@ -84,7 +84,6 @@ open(const char *path, int mode)
 		fd_close(fd, 0);
 		return r;
 	}
-
 	return fd2num(fd);
 }
 
@@ -141,7 +140,17 @@ devfile_write(struct Fd *fd, const void *buf, size_t n)
 	// remember that write is always allowed to write *fewer*
 	// bytes than requested.
 	// LAB 5: Your code here
-	panic("devfile_write not implemented");
+	
+	if (n > sizeof (fsipcbuf.write.req_buf))
+		n = sizeof (fsipcbuf.write.req_buf);
+
+	fsipcbuf.write.req_fileid = fd->fd_file.id;
+	fsipcbuf.write.req_n = n;
+	memmove(fsipcbuf.write.req_buf,buf,n);
+	int r;
+	if ((r = fsipc(FSREQ_WRITE, NULL)) < 0)
+		return r;
+	return r;
 }
 
 static int
diff --git a/lib/fork.c b/lib/fork.c
old mode 100644
new mode 100755
index 61264da..ee6d613
--- a/lib/fork.c
+++ b/lib/fork.c
@@ -11,30 +11,34 @@
 // Custom page fault handler - if faulting page is copy-on-write,
 // map in our own private writable copy.
 //
-static void
+    static void
 pgfault(struct UTrapframe *utf)
 {
-	void *addr = (void *) utf->utf_fault_va;
-	uint32_t err = utf->utf_err;
-	int r;
-
-	// Check that the faulting access was (1) a write, and (2) to a
-	// copy-on-write page.  If not, panic.
-	// Hint:
-	//   Use the read-only page table mappings at uvpt
-	//   (see <inc/memlayout.h>).
-
-	// LAB 4: Your code here.
-
-	// Allocate a new page, map it at a temporary location (PFTEMP),
-	// copy the data from the old page to the new page, then move the new
-	// page to the old page's address.
-	// Hint:
-	//   You should make three system calls.
-
-	// LAB 4: Your code here.
-
-	panic("pgfault not implemented");
+    void *addr = (void *) utf->utf_fault_va;
+    uint32_t err = utf->utf_err;
+    int r;
+    pte_t pte;
+    // Check that the faulting access was (1) a write, and (2) to a
+    // copy-on-write page.  If not, panic.
+    // Hint:
+    //   Use the read-only page table mappings at uvpt
+    //   (see <inc/memlayout.h>).
+    // LAB 4: Your code here.
+    if (!(utf->utf_err & FEC_WR)) panic("pgfault(): FEC_WR\n");
+    if (!uvpd[((uintptr_t)addr >> 22)]) panic("pgfault(): page not mapped");
+    if (!(pte = uvpt[(uintptr_t)addr >> 12])) panic("pgfault(): page not mapped");
+    if (!(pte & PTE_COW)) panic("pgfault: PTE_COW\n");
+    // Allocate a new page, map it at a temporary location (PFTEMP),
+    // copy the data from the old page to the new page, then move the new
+    // page to the old page's address.
+    // Hint:
+    //   You should make three system calls.
+    // LAB 4: Your code here.
+    sys_page_alloc(0, (void*)PFTEMP, PTE_P | PTE_U | PTE_W);
+    memcpy((void*)PFTEMP, (void*)ROUNDDOWN((uintptr_t)addr, PGSIZE), PGSIZE);
+    sys_page_map(0, (void*)PFTEMP, 0, (void*)ROUNDDOWN((uintptr_t)addr, PGSIZE), PTE_P | PTE_U | PTE_W);
+    sys_page_unmap(0, (void*)PFTEMP);
+    //cprintf("xixi\n");
 }
 
 //
@@ -48,14 +52,32 @@ pgfault(struct UTrapframe *utf)
 // Returns: 0 on success, < 0 on error.
 // It is also OK to panic on error.
 //
-static int
+    static int
 duppage(envid_t envid, unsigned pn)
 {
-	int r;
+    int r;
+
+    // LAB 4: Your code here.
+    int perm = uvpt[pn] & 0xfff;
 
-	// LAB 4: Your code here.
-	panic("duppage not implemented");
-	return 0;
+    if (perm & PTE_SHARE) 
+    {
+		if ((r = sys_page_map(0, (void*)(pn * PGSIZE), envid, (void*)(pn * PGSIZE), perm)))
+	    	return r;
+		return 0;
+    }
+    if (perm & (PTE_W | PTE_COW)) 
+    {
+		if ((r = sys_page_map(0, (void*)(pn * PGSIZE), envid, (void*)(pn * PGSIZE), (perm & ~PTE_W) | PTE_COW)))
+	    	return r;
+		if ((r = sys_page_map(0, (void*)(pn * PGSIZE), 0, (void*)(pn * PGSIZE), (perm & ~PTE_W) | PTE_COW)))
+	    	return r;
+    }
+    else {
+		if ((r = sys_page_map(0, (void*)(pn * PGSIZE), envid, (void*)(pn * PGSIZE), perm)))
+	    	return r;
+    }
+    return 0;
 }
 
 //
@@ -74,17 +96,48 @@ duppage(envid_t envid, unsigned pn)
 //   Neither user exception stack should ever be marked copy-on-write,
 //   so you must allocate a new page for the child's user exception stack.
 //
-envid_t
+    envid_t
 fork(void)
 {
-	// LAB 4: Your code here.
-	panic("fork not implemented");
+    // LAB 4: Your code here.
+    extern void _pgfault_upcall(void);
+    uintptr_t p = 0;
+    envid_t envid;
+    set_pgfault_handler(pgfault);
+
+    envid = sys_exofork();
+    if (envid < 0) 
+        return envid;
+    if (envid == 0) 
+    {
+        thisenv = &envs[ENVX(sys_getenvid())];
+        return 0;
+    }
+    while (p < UTOP) 
+    {
+        if (!uvpd[p >> 22]) 
+        {
+            p += PGSIZE << 10;
+            continue;
+        }
+        if (p != UXSTACKTOP - PGSIZE && uvpt[p >> 12]) 
+            duppage(envid, p >> 12);
+        p += PGSIZE;
+    }
+
+    if (sys_page_alloc(envid, (void*)(UXSTACKTOP - PGSIZE), PTE_P | PTE_U | PTE_W) < 0) 
+        panic("fork(): sys_page_alloc() fails\n");
+    if (sys_env_set_pgfault_upcall(envid, _pgfault_upcall) < 0) 
+        panic("fork(): sys_env_set_pgfault_upcall() fails\n");
+    if (sys_env_set_status(envid, ENV_RUNNABLE) < 0) 
+        panic("fork(): sys_env_set_status() fails\n");
+    return envid;
 }
 
 // Challenge!
-int
+    int
 sfork(void)
 {
-	panic("sfork not implemented");
-	return -E_INVAL;
+    panic("sfork not implemented");
+    return -E_INVAL;
 }
diff --git a/lib/fprintf.c b/lib/fprintf.c
old mode 100644
new mode 100755
diff --git a/lib/ipc.c b/lib/ipc.c
old mode 100644
new mode 100755
index 2e222b9..7e15885
--- a/lib/ipc.c
+++ b/lib/ipc.c
@@ -19,12 +19,25 @@
 //   If 'pg' is null, pass sys_ipc_recv a value that it will understand
 //   as meaning "no page".  (Zero is not the right value, since that's
 //   a perfectly valid place to map a page.)
-int32_t
+    int32_t
 ipc_recv(envid_t *from_env_store, void *pg, int *perm_store)
 {
-	// LAB 4: Your code here.
-	panic("ipc_recv not implemented");
-	return 0;
+    // LAB 4: Your code here.
+    int r;
+    if (!pg) pg = (void*)UTOP;
+    if ((r = sys_ipc_recv(pg)) < 0) 
+    {
+        if (from_env_store) 
+            *from_env_store = 0;
+        if (perm_store) 
+            *perm_store = 0;
+        return r;
+    }
+    if (from_env_store) 
+        *from_env_store = thisenv->env_ipc_from;
+    if (perm_store) 
+        *perm_store = thisenv->env_ipc_perm;
+    return thisenv->env_ipc_value;
 }
 
 // Send 'val' (and 'pg' with 'perm', if 'pg' is nonnull) to 'toenv'.
@@ -35,22 +48,29 @@ ipc_recv(envid_t *from_env_store, void *pg, int *perm_store)
 //   Use sys_yield() to be CPU-friendly.
 //   If 'pg' is null, pass sys_ipc_try_send a value that it will understand
 //   as meaning "no page".  (Zero is not the right value.)
-void
+    void
 ipc_send(envid_t to_env, uint32_t val, void *pg, int perm)
 {
-	// LAB 4: Your code here.
-	panic("ipc_send not implemented");
+    // LAB 4: Your code here.
+    int r;
+    while ((r = sys_ipc_try_send(to_env, val, (pg ? pg : (void*)UTOP), perm))) 
+    {
+        if (r != -E_IPC_NOT_RECV) 
+            panic("ipc_send()\n");
+        sys_yield();
+    }
+
 }
 
 // Find the first environment of the given type.  We'll use this to
 // find special environments.
 // Returns 0 if no such environment exists.
-envid_t
+    envid_t
 ipc_find_env(enum EnvType type)
 {
-	int i;
-	for (i = 0; i < NENV; i++)
-		if (envs[i].env_type == type)
-			return envs[i].env_id;
-	return 0;
+    int i;
+    for (i = 0; i < NENV; i++)
+        if (envs[i].env_type == type)
+            return envs[i].env_id;
+    return 0;
 }
diff --git a/lib/libmain.c b/lib/libmain.c
old mode 100644
new mode 100755
index 8a14b29..a5aa1e1
--- a/lib/libmain.c
+++ b/lib/libmain.c
@@ -13,8 +13,8 @@ libmain(int argc, char **argv)
 {
 	// set thisenv to point at our Env structure in envs[].
 	// LAB 3: Your code here.
-	thisenv = 0;
-
+        thisenv = envs + ENVX(sys_getenvid());
+    
 	// save the name of the program so that panic() can use it
 	if (argc > 0)
 		binaryname = argv[0];
diff --git a/lib/pageref.c b/lib/pageref.c
old mode 100644
new mode 100755
diff --git a/lib/panic.c b/lib/panic.c
old mode 100644
new mode 100755
diff --git a/lib/pfentry.S b/lib/pfentry.S
old mode 100644
new mode 100755
index f40aeeb..e29c0ec
--- a/lib/pfentry.S
+++ b/lib/pfentry.S
@@ -32,51 +32,63 @@
 .text
 .globl _pgfault_upcall
 _pgfault_upcall:
-	// Call the C page fault handler.
-	pushl %esp			// function argument: pointer to UTF
-	movl _pgfault_handler, %eax
-	call *%eax
-	addl $4, %esp			// pop function argument
-	
-	// Now the C page fault handler has returned and you must return
-	// to the trap time state.
-	// Push trap-time %eip onto the trap-time stack.
-	//
-	// Explanation:
-	//   We must prepare the trap-time stack for our eventual return to
-	//   re-execute the instruction that faulted.
-	//   Unfortunately, we can't return directly from the exception stack:
-	//   We can't call 'jmp', since that requires that we load the address
-	//   into a register, and all registers must have their trap-time
-	//   values after the return.
-	//   We can't call 'ret' from the exception stack either, since if we
-	//   did, %esp would have the wrong value.
-	//   So instead, we push the trap-time %eip onto the *trap-time* stack!
-	//   Below we'll switch to that stack and call 'ret', which will
-	//   restore %eip to its pre-fault value.
-	//
-	//   In the case of a recursive fault on the exception stack,
-	//   note that the word we're pushing now will fit in the
-	//   blank word that the kernel reserved for us.
-	//
-	// Throughout the remaining code, think carefully about what
-	// registers are available for intermediate calculations.  You
-	// may find that you have to rearrange your code in non-obvious
-	// ways as registers become unavailable as scratch space.
-	//
-	// LAB 4: Your code here.
+// Call the C page fault handler.
+pushl %esp			// function argument: pointer to UTF
+movl _pgfault_handler, %eax
+call *%eax
+addl $4, %esp			// pop function argument
 
-	// Restore the trap-time registers.  After you do this, you
-	// can no longer modify any general-purpose registers.
-	// LAB 4: Your code here.
+// Now the C page fault handler has returned and you must return
+// to the trap time state.
+// Push trap-time %eip onto the trap-time stack.
+//
+// Explanation:
+//   We must prepare the trap-time stack for our eventual return to
+//   re-execute the instruction that faulted.
+//   Unfortunately, we can't return directly from the exception stack:
+//   We can't call 'jmp', since that requires that we load the address
+//   into a register, and all registers must have their trap-time
+//   values after the return.
+//   We can't call 'ret' from the exception stack either, since if we
+//   did, %esp would have the wrong value.
+//   So instead, we push the trap-time %eip onto the *trap-time* stack!
+//   Below we'll switch to that stack and call 'ret', which will
+//   restore %eip to its pre-fault value.
+//
+//   In the case of a recursive fault on the exception stack,
+//   note that the word we're pushing now will fit in the
+//   blank word that the kernel reserved for us.
+//
+// Throughout the remaining code, think carefully about what
+// registers are available for intermediate calculations.  You
+// may find that you have to rearrange your code in non-obvious
+// ways as registers become unavailable as scratch space.
+//
+// LAB 4: Your code here.
+
+subl $4, 48(%esp)
+    movl 48(%esp), %eax
+    movl 40(%esp), %edx
+movl %edx, (%eax)
+
+    // Restore the trap-time registers.  After you do this, you
+    // can no longer modify any general-purpose registers.
+    // LAB 4: Your code here.
+    addl $8, %esp
+    popal
+
+    // Restore eflags from the stack.  After you do this, you can
+    // no longer use arithmetic operations or anything else that
+    // modifies eflags.
+    // LAB 4: Your code here.
+    addl $4, %esp
+    popfl
 
-	// Restore eflags from the stack.  After you do this, you can
-	// no longer use arithmetic operations or anything else that
-	// modifies eflags.
-	// LAB 4: Your code here.
+    // Switch back to the adjusted trap-time stack.
+    // LAB 4: Your code here.
+    popl %esp
 
-	// Switch back to the adjusted trap-time stack.
-	// LAB 4: Your code here.
+    // Return to re-execute the instruction that faulted.
+    // LAB 4: Your code here.
 
-	// Return to re-execute the instruction that faulted.
-	// LAB 4: Your code here.
+    ret
diff --git a/lib/pgfault.c b/lib/pgfault.c
old mode 100644
new mode 100755
index a975518..a093d1d
--- a/lib/pgfault.c
+++ b/lib/pgfault.c
@@ -21,17 +21,19 @@ void (*_pgfault_handler)(struct UTrapframe *utf);
 // at UXSTACKTOP), and tell the kernel to call the assembly-language
 // _pgfault_upcall routine when a page fault occurs.
 //
-void
+    void
 set_pgfault_handler(void (*handler)(struct UTrapframe *utf))
 {
-	int r;
+    int r;
 
-	if (_pgfault_handler == 0) {
+    if (_pgfault_handler == 0) 
+    {
 		// First time through!
 		// LAB 4: Your code here.
-		panic("set_pgfault_handler not implemented");
-	}
+		sys_page_alloc(0, (void*)(UXSTACKTOP - PGSIZE), PTE_U | PTE_W | PTE_P);
+		sys_env_set_pgfault_upcall(0, (void*)_pgfault_upcall);
+    }
 
-	// Save handler pointer for assembly to call.
-	_pgfault_handler = handler;
+    // Save handler pointer for assembly to call.
+    _pgfault_handler = handler;
 }
diff --git a/lib/pipe.c b/lib/pipe.c
old mode 100644
new mode 100755
diff --git a/lib/printf.c b/lib/printf.c
old mode 100644
new mode 100755
diff --git a/lib/printfmt.c b/lib/printfmt.c
old mode 100644
new mode 100755
index 8cea2f8..25a3280
--- a/lib/printfmt.c
+++ b/lib/printfmt.c
@@ -7,6 +7,7 @@
 #include <inc/string.h>
 #include <inc/stdarg.h>
 #include <inc/error.h>
+#include <inc/color.h>
 
 /*
  * Space or zero padding and a field width are supported for the numeric
@@ -101,6 +102,33 @@ vprintfmt(void (*putch)(int, void*), void *putdat, const char *fmt, va_list ap)
 		while ((ch = *(unsigned char *) fmt++) != '%') {
 			if (ch == '\0')
 				return;
+			else if(ch == '\033'){
+				if((ch = *(unsigned char *) fmt++) != '[') {
+				    putch(ch, putdat);
+				    continue;
+				}
+				BG_COLOR = *(unsigned char *) fmt++;
+				FG_COLOR = *(unsigned char *) fmt++;
+
+				if(BG_COLOR >= '0' && BG_COLOR <= '9')
+				    BG_COLOR -= '0';
+				else if(BG_COLOR >= 'a' && BG_COLOR <= 'f')
+				    BG_COLOR = BG_COLOR - 'a' + 10;
+				else if(BG_COLOR >= 'A' && BG_COLOR <= 'F')
+				    BG_COLOR = BG_COLOR - 'A' + 10;
+				else BG_COLOR = 0;
+
+				if(FG_COLOR >= '0' && FG_COLOR <= '9')
+				    FG_COLOR -= '0';
+				else if(FG_COLOR >= 'a' && FG_COLOR <= 'f')
+				    FG_COLOR = FG_COLOR - 'a' + 10;
+				else if(FG_COLOR >= 'A' && FG_COLOR <= 'F')
+				    FG_COLOR = FG_COLOR - 'A' + 10;
+				else BG_COLOR = 7;
+
+				COLOR = (BG_COLOR << 12) | (FG_COLOR << 8);
+				continue;
+			}	
 			putch(ch, putdat);
 		}
 
@@ -214,11 +242,9 @@ vprintfmt(void (*putch)(int, void*), void *putdat, const char *fmt, va_list ap)
 
 		// (unsigned) octal
 		case 'o':
-			// Replace this with your code.
-			putch('X', putdat);
-			putch('X', putdat);
-			putch('X', putdat);
-			break;
+			num = getuint(&ap,lflag);
+			base = 8;
+			goto number;
 
 		// pointer
 		case 'p':
@@ -240,7 +266,7 @@ vprintfmt(void (*putch)(int, void*), void *putdat, const char *fmt, va_list ap)
 		// escaped '%' character
 		case '%':
 			putch(ch, putdat);
-			break;
+			break;			
 
 		// unrecognized escape sequence - just print it literally
 		default:
diff --git a/lib/readline.c b/lib/readline.c
old mode 100644
new mode 100755
diff --git a/lib/spawn.c b/lib/spawn.c
old mode 100644
new mode 100755
index 9d0eb07..7e556fd
--- a/lib/spawn.c
+++ b/lib/spawn.c
@@ -6,9 +6,9 @@
 #define UTEMP3			(UTEMP2 + PGSIZE)
 
 // Helper functions for spawn.
-static int init_stack(envid_t child, const char **argv, uintptr_t *init_esp);
+static int init_stack(envid_t child, const char **argv, uintptr_t *init_esp, uintptr_t stackbase);
 static int map_segment(envid_t child, uintptr_t va, size_t memsz,
-		       int fd, size_t filesz, off_t fileoffset, int perm);
+	int fd, size_t filesz, off_t fileoffset, int perm);
 static int copy_shared_pages(envid_t child);
 
 // Spawn a child process from a program image loaded from the file system.
@@ -16,166 +16,242 @@ static int copy_shared_pages(envid_t child);
 // argv: pointer to null-terminated array of pointers to strings,
 // 	 which will be passed to the child as its command-line arguments.
 // Returns child envid on success, < 0 on failure.
-int
+    int
 spawn(const char *prog, const char **argv)
 {
-	unsigned char elf_buf[512];
-	struct Trapframe child_tf;
-	envid_t child;
-
-	int fd, i, r;
-	struct Elf *elf;
-	struct Proghdr *ph;
-	int perm;
-
-	// This code follows this procedure:
-	//
-	//   - Open the program file.
-	//
-	//   - Read the ELF header, as you have before, and sanity check its
-	//     magic number.  (Check out your load_icode!)
-	//
-	//   - Use sys_exofork() to create a new environment.
-	//
-	//   - Set child_tf to an initial struct Trapframe for the child.
-	//
-	//   - Call the init_stack() function above to set up
-	//     the initial stack page for the child environment.
-	//
-	//   - Map all of the program's segments that are of p_type
-	//     ELF_PROG_LOAD into the new environment's address space.
-	//     Use the p_flags field in the Proghdr for each segment
-	//     to determine how to map the segment:
-	//
-	//	* If the ELF flags do not include ELF_PROG_FLAG_WRITE,
-	//	  then the segment contains text and read-only data.
-	//	  Use read_map() to read the contents of this segment,
-	//	  and map the pages it returns directly into the child
-	//        so that multiple instances of the same program
-	//	  will share the same copy of the program text.
-	//        Be sure to map the program text read-only in the child.
-	//        Read_map is like read but returns a pointer to the data in
-	//        *blk rather than copying the data into another buffer.
-	//
-	//	* If the ELF segment flags DO include ELF_PROG_FLAG_WRITE,
-	//	  then the segment contains read/write data and bss.
-	//	  As with load_icode() in Lab 3, such an ELF segment
-	//	  occupies p_memsz bytes in memory, but only the FIRST
-	//	  p_filesz bytes of the segment are actually loaded
-	//	  from the executable file - you must clear the rest to zero.
-	//        For each page to be mapped for a read/write segment,
-	//        allocate a page in the parent temporarily at UTEMP,
-	//        read() the appropriate portion of the file into that page
-	//	  and/or use memset() to zero non-loaded portions.
-	//	  (You can avoid calling memset(), if you like, if
-	//	  page_alloc() returns zeroed pages already.)
-	//        Then insert the page mapping into the child.
-	//        Look at init_stack() for inspiration.
-	//        Be sure you understand why you can't use read_map() here.
-	//
-	//     Note: None of the segment addresses or lengths above
-	//     are guaranteed to be page-aligned, so you must deal with
-	//     these non-page-aligned values appropriately.
-	//     The ELF linker does, however, guarantee that no two segments
-	//     will overlap on the same page; and it guarantees that
-	//     PGOFF(ph->p_offset) == PGOFF(ph->p_va).
-	//
-	//   - Call sys_env_set_trapframe(child, &child_tf) to set up the
-	//     correct initial eip and esp values in the child.
-	//
-	//   - Start the child process running with sys_env_set_status().
-
-	if ((r = open(prog, O_RDONLY)) < 0)
-		return r;
-	fd = r;
+    unsigned char elf_buf[512];
+    struct Trapframe child_tf;
+    envid_t child;
+
+    int fd, i, r;
+    struct Elf *elf;
+    struct Proghdr *ph;
+    int perm;
+
+    // This code follows this procedure:
+    //
+    //   - Open the program file.
+    //
+    //   - Read the ELF header, as you have before, and sanity check its
+    //     magic number.  (Check out your load_icode!)
+    //
+    //   - Use sys_exofork() to create a new environment.
+    //
+    //   - Set child_tf to an initial struct Trapframe for the child.
+    //
+    //   - Call the init_stack() function above to set up
+    //     the initial stack page for the child environment.
+    //
+    //   - Map all of the program's segments that are of p_type
+    //     ELF_PROG_LOAD into the new environment's address space.
+    //     Use the p_flags field in the Proghdr for each segment
+    //     to determine how to map the segment:
+    //
+    //	* If the ELF flags do not include ELF_PROG_FLAG_WRITE,
+    //	  then the segment contains text and read-only data.
+    //	  Use read_map() to read the contents of this segment,
+    //	  and map the pages it returns directly into the child
+    //        so that multiple instances of the same program
+    //	  will share the same copy of the program text.
+    //        Be sure to map the program text read-only in the child.
+    //        Read_map is like read but returns a pointer to the data in
+    //        *blk rather than copying the data into another buffer.
+    //
+    //	* If the ELF segment flags DO include ELF_PROG_FLAG_WRITE,
+    //	  then the segment contains read/write data and bss.
+    //	  As with load_icode() in Lab 3, such an ELF segment
+    //	  occupies p_memsz bytes in memory, but only the FIRST
+    //	  p_filesz bytes of the segment are actually loaded
+    //	  from the executable file - you must clear the rest to zero.
+    //        For each page to be mapped for a read/write segment,
+    //        allocate a page in the parent temporarily at UTEMP,
+    //        read() the appropriate portion of the file into that page
+    //	  and/or use memset() to zero non-loaded portions.
+    //	  (You can avoid calling memset(), if you like, if
+    //	  page_alloc() returns zeroed pages already.)
+    //        Then insert the page mapping into the child.
+    //        Look at init_stack() for inspiration.
+    //        Be sure you understand why you can't use read_map() here.
+    //
+    //     Note: None of the segment addresses or lengths above
+    //     are guaranteed to be page-aligned, so you must deal with
+    //     these non-page-aligned values appropriately.
+    //     The ELF linker does, however, guarantee that no two segments
+    //     will overlap on the same page; and it guarantees that
+    //     PGOFF(ph->p_offset) == PGOFF(ph->p_va).
+    //
+    //   - Call sys_env_set_trapframe(child, &child_tf) to set up the
+    //     correct initial eip and esp values in the child.
+    //
+    //   - Start the child process running with sys_env_set_status().
+
+    if ((r = open(prog, O_RDONLY)) < 0)
+	return r;
+    fd = r;
 
-	// Read elf header
-	elf = (struct Elf*) elf_buf;
-	if (readn(fd, elf_buf, sizeof(elf_buf)) != sizeof(elf_buf)
+    // Read elf header
+    elf = (struct Elf*) elf_buf;
+    if (readn(fd, elf_buf, sizeof(elf_buf)) != sizeof(elf_buf)
 	    || elf->e_magic != ELF_MAGIC) {
-		close(fd);
-		cprintf("elf magic %08x want %08x\n", elf->e_magic, ELF_MAGIC);
-		return -E_NOT_EXEC;
-	}
-
-	// Create new child environment
-	if ((r = sys_exofork()) < 0)
-		return r;
-	child = r;
-
-	// Set up trap frame, including initial stack.
-	child_tf = envs[ENVX(child)].env_tf;
-	child_tf.tf_eip = elf->e_entry;
-
-	if ((r = init_stack(child, argv, &child_tf.tf_esp)) < 0)
-		return r;
-
-	// Set up program segments as defined in ELF header.
-	ph = (struct Proghdr*) (elf_buf + elf->e_phoff);
-	for (i = 0; i < elf->e_phnum; i++, ph++) {
-		if (ph->p_type != ELF_PROG_LOAD)
-			continue;
-		perm = PTE_P | PTE_U;
-		if (ph->p_flags & ELF_PROG_FLAG_WRITE)
-			perm |= PTE_W;
-		if ((r = map_segment(child, ph->p_va, ph->p_memsz,
-				     fd, ph->p_filesz, ph->p_offset, perm)) < 0)
-			goto error;
-	}
 	close(fd);
-	fd = -1;
+	cprintf("elf magic %08x want %08x\n", elf->e_magic, ELF_MAGIC);
+	return -E_NOT_EXEC;
+    }
 
-	// Copy shared library state.
-	if ((r = copy_shared_pages(child)) < 0)
-		panic("copy_shared_pages: %e", r);
+    // Create new child environment
+    if ((r = sys_exofork()) < 0)
+	return r;
+    child = r;
 
-	child_tf.tf_eflags |= FL_IOPL_3;   // devious: see user/faultio.c
-	if ((r = sys_env_set_trapframe(child, &child_tf)) < 0)
-		panic("sys_env_set_trapframe: %e", r);
+    // Set up trap frame, including initial stack.
+    child_tf = envs[ENVX(child)].env_tf;
+    child_tf.tf_eip = elf->e_entry;
 
-	if ((r = sys_env_set_status(child, ENV_RUNNABLE)) < 0)
-		panic("sys_env_set_status: %e", r);
+    if ((r = init_stack(child, argv, &child_tf.tf_esp, USTACKTOP - PGSIZE)) < 0)
+	return r;
 
-	return child;
+    // Set up program segments as defined in ELF header.
+    ph = (struct Proghdr*) (elf_buf + elf->e_phoff);
+    for (i = 0; i < elf->e_phnum; i++, ph++) {
+	if (ph->p_type != ELF_PROG_LOAD)
+	    continue;
+	perm = PTE_P | PTE_U;
+	if (ph->p_flags & ELF_PROG_FLAG_WRITE)
+	    perm |= PTE_W;
+	if ((r = map_segment(child, ph->p_va, ph->p_memsz,
+			fd, ph->p_filesz, ph->p_offset, perm)) < 0)
+	    goto error;
+    }
+    close(fd);
+    fd = -1;
+
+    // Copy shared library state.
+    if ((r = copy_shared_pages(child)) < 0)
+	panic("copy_shared_pages: %e", r);
+
+     child_tf.tf_eflags |= FL_IOPL_3;   // devious: see user/faultio.c
+    if ((r = sys_env_set_trapframe(child, &child_tf)) < 0)
+	panic("sys_env_set_trapframe: %e", r);
+
+    if ((r = sys_env_set_status(child, ENV_RUNNABLE)) < 0)
+	panic("sys_env_set_status: %e", r);
+
+    return child;
 
 error:
-	sys_env_destroy(child);
-	close(fd);
-	return r;
+    sys_env_destroy(child);
+    close(fd);
+    return r;
 }
 
+    int 
+exec(const char *prog, const char **argv)
+{
+    unsigned char elf_buf[512];
+
+    int fd, i, r;
+    struct Elf *elf;
+    struct Proghdr *ph;
+    int perm;
+
+    if ((r = open(prog, O_RDONLY)) < 0)
+        return r;
+    fd = r;
+
+    // Read elf header
+    elf = (struct Elf*) elf_buf;
+    if (readn(fd, elf_buf, sizeof(elf_buf)) != sizeof(elf_buf)
+        || elf->e_magic != ELF_MAGIC) 
+    {
+        close(fd);
+        cprintf("elf magic %08x want %08x\n", elf->e_magic, ELF_MAGIC);
+        return -E_NOT_EXEC;
+    }
+
+    // Set up program segments as defined in ELF header.
+    ph = (struct Proghdr*) (elf_buf + elf->e_phoff);
+    for (i = 0; i < elf->e_phnum; i++, ph++) 
+    {
+        if (ph->p_type != ELF_PROG_LOAD)
+            continue;
+        perm = PTE_P | PTE_U;
+        if (ph->p_flags & ELF_PROG_FLAG_WRITE)
+            perm |= PTE_W;
+        if ((r = map_segment(0, ph->p_va + 0x80000000, ph->p_memsz,
+                fd, ph->p_filesz, ph->p_offset, perm)) < 0)
+            goto error;
+    }
+    close(fd);
+    fd = -1;
+    uintptr_t tf_esp;
+    if((r = init_stack(0, argv, &tf_esp, 0x80000000 - PGSIZE)) < 0)
+        return r;
+    cprintf("entry: %x\n", elf->e_entry);
+    if((r = sys_exec(elf->e_entry, tf_esp, (void *)(elf_buf + elf->e_phoff), elf->e_phnum)) < 0)
+        goto error;
+
+    return 0;
+
+error:
+    sys_env_destroy(0);
+    close(fd);
+    return r;
+}
 // Spawn, taking command-line arguments array directly on the stack.
 // NOTE: Must have a sentinal of NULL at the end of the args
 // (none of the args may be NULL).
-int
+    int
 spawnl(const char *prog, const char *arg0, ...)
 {
-	// We calculate argc by advancing the args until we hit NULL.
-	// The contract of the function guarantees that the last
-	// argument will always be NULL, and that none of the other
-	// arguments will be NULL.
-	int argc=0;
-	va_list vl;
-	va_start(vl, arg0);
-	while(va_arg(vl, void *) != NULL)
-		argc++;
-	va_end(vl);
-
-	// Now that we have the size of the args, do a second pass
-	// and store the values in a VLA, which has the format of argv
-	const char *argv[argc+2];
-	argv[0] = arg0;
-	argv[argc+1] = NULL;
-
-	va_start(vl, arg0);
-	unsigned i;
-	for(i=0;i<argc;i++)
-		argv[i+1] = va_arg(vl, const char *);
-	va_end(vl);
-	return spawn(prog, argv);
+    // We calculate argc by advancing the args until we hit NULL.
+    // The contract of the function guarantees that the last
+    // argument will always be NULL, and that none of the other
+    // arguments will be NULL.
+    int argc=0;
+    va_list vl;
+    va_start(vl, arg0);
+    while(va_arg(vl, void *) != NULL)
+	   argc++;
+    va_end(vl);
+
+    // Now that we have the size of the args, do a second pass
+    // and store the values in a VLA, which has the format of argv
+    const char *argv[argc+2];
+    argv[0] = arg0;
+    argv[argc+1] = NULL;
+
+    va_start(vl, arg0);
+    unsigned i;
+    for(i=0;i<argc;i++)
+	argv[i+1] = va_arg(vl, const char *);
+    va_end(vl);
+    return spawn(prog, argv);
 }
 
 
+    int
+execl(const char *prog, const char *arg0, ...)
+{
+    int argc = 0;
+    va_list vl;
+    va_start(vl, arg0);
+    while(va_arg(vl, void *) != NULL)
+        argc++;
+    va_end(vl);
+
+    const char *argv[argc + 2];
+    argv[0] = arg0;
+    argv[argc + 1] = NULL;
+
+    va_start(vl, arg0);
+    unsigned i;
+    for (i = 0; i < argc; ++i)
+    {
+        argv[i + 1] = va_arg(vl, const char *);
+    }
+    va_end(vl);
+    return exec(prog, argv);
+}
 // Set up the initial stack page for the new child process with envid 'child'
 // using the arguments array pointed to by 'argv',
 // which is a null-terminated array of pointers to null-terminated strings.
@@ -183,125 +259,142 @@ spawnl(const char *prog, const char *arg0, ...)
 // On success, returns 0 and sets *init_esp
 // to the initial stack pointer with which the child should start.
 // Returns < 0 on failure.
-static int
-init_stack(envid_t child, const char **argv, uintptr_t *init_esp)
+    static int
+init_stack(envid_t child, const char **argv, uintptr_t *init_esp, uintptr_t stackbase)
 {
-	size_t string_size;
-	int argc, i, r;
-	char *string_store;
-	uintptr_t *argv_store;
-
-	// Count the number of arguments (argc)
-	// and the total amount of space needed for strings (string_size).
-	string_size = 0;
-	for (argc = 0; argv[argc] != 0; argc++)
-		string_size += strlen(argv[argc]) + 1;
-
-	// Determine where to place the strings and the argv array.
-	// Set up pointers into the temporary page 'UTEMP'; we'll map a page
-	// there later, then remap that page into the child environment
-	// at (USTACKTOP - PGSIZE).
-	// strings is the topmost thing on the stack.
-	string_store = (char*) UTEMP + PGSIZE - string_size;
-	// argv is below that.  There's one argument pointer per argument, plus
-	// a null pointer.
-	argv_store = (uintptr_t*) (ROUNDDOWN(string_store, 4) - 4 * (argc + 1));
-
-	// Make sure that argv, strings, and the 2 words that hold 'argc'
-	// and 'argv' themselves will all fit in a single stack page.
-	if ((void*) (argv_store - 2) < (void*) UTEMP)
-		return -E_NO_MEM;
-
-	// Allocate the single stack page at UTEMP.
-	if ((r = sys_page_alloc(0, (void*) UTEMP, PTE_P|PTE_U|PTE_W)) < 0)
-		return r;
-
-
-	//	* Initialize 'argv_store[i]' to point to argument string i,
-	//	  for all 0 <= i < argc.
-	//	  Also, copy the argument strings from 'argv' into the
-	//	  newly-allocated stack page.
-	//
-	//	* Set 'argv_store[argc]' to 0 to null-terminate the args array.
-	//
-	//	* Push two more words onto the child's stack below 'args',
-	//	  containing the argc and argv parameters to be passed
-	//	  to the child's umain() function.
-	//	  argv should be below argc on the stack.
-	//	  (Again, argv should use an address valid in the child's
-	//	  environment.)
-	//
-	//	* Set *init_esp to the initial stack pointer for the child,
-	//	  (Again, use an address valid in the child's environment.)
-	for (i = 0; i < argc; i++) {
-		argv_store[i] = UTEMP2USTACK(string_store);
-		strcpy(string_store, argv[i]);
-		string_store += strlen(argv[i]) + 1;
-	}
-	argv_store[argc] = 0;
-	assert(string_store == (char*)UTEMP + PGSIZE);
-
-	argv_store[-1] = UTEMP2USTACK(argv_store);
-	argv_store[-2] = argc;
-
-	*init_esp = UTEMP2USTACK(&argv_store[-2]);
-
-	// After completing the stack, map it into the child's address space
-	// and unmap it from ours!
-	if ((r = sys_page_map(0, UTEMP, child, (void*) (USTACKTOP - PGSIZE), PTE_P | PTE_U | PTE_W)) < 0)
-		goto error;
-	if ((r = sys_page_unmap(0, UTEMP)) < 0)
-		goto error;
-
-	return 0;
+    size_t string_size;
+    int argc, i, r;
+    char *string_store;
+    uintptr_t *argv_store;
+
+    // Count the number of arguments (argc)
+    // and the total amount of space needed for strings (string_size).
+    string_size = 0;
+    for (argc = 0; argv[argc] != 0; argc++)
+	string_size += strlen(argv[argc]) + 1;
+
+    // Determine where to place the strings and the argv array.
+    // Set up pointers into the temporary page 'UTEMP'; we'll map a page
+    // there later, then remap that page into the child environment
+    // at (USTACKTOP - PGSIZE).
+    // strings is the topmost thing on the stack.
+    string_store = (char*) UTEMP + PGSIZE - string_size;
+    // argv is below that.  There's one argument pointer per argument, plus
+    // a null pointer.
+    argv_store = (uintptr_t*) (ROUNDDOWN(string_store, 4) - 4 * (argc + 1));
+
+    // Make sure that argv, strings, and the 2 words that hold 'argc'
+    // and 'argv' themselves will all fit in a single stack page.
+    if ((void*) (argv_store - 2) < (void*) UTEMP)
+	return -E_NO_MEM;
+
+    // Allocate the single stack page at UTEMP.
+    if ((r = sys_page_alloc(0, (void*) UTEMP, PTE_P|PTE_U|PTE_W)) < 0)
+	return r;
+    
+
+    //	* Initialize 'argv_store[i]' to point to argument string i,
+    //	  for all 0 <= i < argc.
+    //	  Also, copy the argument strings from 'argv' into the
+    //	  newly-allocated stack page.
+    //
+    //	* Set 'argv_store[argc]' to 0 to null-terminate the args array.
+    //
+    //	* Push two more words onto the child's stack below 'args',
+    //	  containing the argc and argv parameters to be passed
+    //	  to the child's umain() function.
+    //	  argv should be below argc on the stack.
+    //	  (Again, argv should use an address valid in the child's
+    //	  environment.)
+    //
+    //	* Set *init_esp to the initial stack pointer for the child,
+    //	  (Again, use an address valid in the child's environment.)
+    for (i = 0; i < argc; i++) {
+	argv_store[i] = UTEMP2USTACK(string_store);
+	strcpy(string_store, argv[i]);
+	string_store += strlen(argv[i]) + 1;
+    }
+    argv_store[argc] = 0;
+    assert(string_store == (char*)UTEMP + PGSIZE);
+
+    argv_store[-1] = UTEMP2USTACK(argv_store);
+    argv_store[-2] = argc;
+
+    *init_esp = UTEMP2USTACK(&argv_store[-2]);
+
+    // After completing the stack, map it into the child's address space
+    // and unmap it from ours!
+    // USTACKTOP - PGSIZE
+    if ((r = sys_page_map(0, UTEMP, child, (void*) stackbase, PTE_P | PTE_U | PTE_W)) < 0)
+	goto error;
+    if ((r = sys_page_unmap(0, UTEMP)) < 0)
+	goto error;
+    
+    return 0;
 
 error:
-	sys_page_unmap(0, UTEMP);
-	return r;
+    sys_page_unmap(0, UTEMP);
+    return r;
 }
 
-static int
+    static int
 map_segment(envid_t child, uintptr_t va, size_t memsz,
 	int fd, size_t filesz, off_t fileoffset, int perm)
 {
-	int i, r;
-	void *blk;
-
-	//cprintf("map_segment %x+%x\n", va, memsz);
-
-	if ((i = PGOFF(va))) {
-		va -= i;
-		memsz += i;
-		filesz += i;
-		fileoffset -= i;
-	}
-
-	for (i = 0; i < memsz; i += PGSIZE) {
-		if (i >= filesz) {
-			// allocate a blank page
-			if ((r = sys_page_alloc(child, (void*) (va + i), perm)) < 0)
-				return r;
-		} else {
-			// from file
-			if ((r = sys_page_alloc(0, UTEMP, PTE_P|PTE_U|PTE_W)) < 0)
-				return r;
-			if ((r = seek(fd, fileoffset + i)) < 0)
-				return r;
-			if ((r = readn(fd, UTEMP, MIN(PGSIZE, filesz-i))) < 0)
-				return r;
-			if ((r = sys_page_map(0, UTEMP, child, (void*) (va + i), perm)) < 0)
-				panic("spawn: sys_page_map data: %e", r);
-			sys_page_unmap(0, UTEMP);
-		}
+    int i, r;
+    void *blk;
+
+    //cprintf("map_segment %x+%x\n", va, memsz);
+
+    if ((i = PGOFF(va))) {
+	va -= i;
+	memsz += i;
+	filesz += i;
+	fileoffset -= i;
+    }
+
+    for (i = 0; i < memsz; i += PGSIZE) {
+	if (i >= filesz) {
+	    // allocate a blank page
+	    if ((r = sys_page_alloc(child, (void*) (va + i), perm)) < 0)
+		return r;
+	} else {
+	    // from file
+	    if ((r = sys_page_alloc(0, UTEMP, PTE_P|PTE_U|PTE_W)) < 0)
+		return r;
+	    if ((r = seek(fd, fileoffset + i)) < 0)
+		return r;
+	    if ((r = readn(fd, UTEMP, MIN(PGSIZE, filesz-i))) < 0)
+		return r;
+	    if ((r = sys_page_map(0, UTEMP, child, (void*) (va + i), perm)) < 0)
+		panic("spawn: sys_page_map data: %e", r);
+	    sys_page_unmap(0, UTEMP);
 	}
-	return 0;
+    }
+    return 0;
 }
 
 // Copy the mappings for shared pages into the child address space.
-static int
+    static int
 copy_shared_pages(envid_t child)
 {
-	// LAB 5: Your code here.
-	return 0;
+    // LAB 5: Your code here.
+    uintptr_t p = 0;
+    while (p < UTOP) 
+    {
+        if (!uvpd[p >> 22]) 
+        {
+            p += PGSIZE << 10;
+            continue;
+        }
+        if (p != UXSTACKTOP - PGSIZE && uvpt[p >> 12]) 
+        {
+	       int perm = uvpt[p >> 12] & 0xfff;
+	       if (perm & PTE_SHARE)
+		      sys_page_map(0, (void*)p, child, (void*)p, perm);
+        }
+        p += PGSIZE;
+    }
+    return 0;
 }
 
diff --git a/lib/string.c b/lib/string.c
old mode 100644
new mode 100755
diff --git a/lib/syscall.c b/lib/syscall.c
old mode 100644
new mode 100755
index d8b1987..efd546b
--- a/lib/syscall.c
+++ b/lib/syscall.c
@@ -117,3 +117,7 @@ sys_ipc_recv(void *dstva)
 	return syscall(SYS_ipc_recv, 1, (uint32_t)dstva, 0, 0, 0, 0);
 }
 
+int sys_exec(uint32_t eip, uint32_t esp, void *v_ph, uint32_t phnum)
+{
+	return syscall(SYS_exec, 1, eip, esp, (uint32_t) v_ph, phnum, 0);
+}
\ No newline at end of file
diff --git a/lib/wait.c b/lib/wait.c
old mode 100644
new mode 100755
diff --git a/user/sh.c b/user/sh.c
index 26f501a..4eee441 100644
--- a/user/sh.c
+++ b/user/sh.c
@@ -55,7 +55,17 @@ again:
 			// then close the original 'fd'.
 
 			// LAB 5: Your code here.
-			panic("< redirection not implemented");
+			if((fd = open(t, O_RDONLY)) < 0)
+			{
+				cprintf("open %s for read: %e", t, fd);
+				exit();
+			}
+			if(fd != 0)
+			{
+				dup(fd, 0);
+				close(fd);
+			}
+			//panic("< redirection not implemented");
 			break;
 
 		case '>':	// Output redirection
